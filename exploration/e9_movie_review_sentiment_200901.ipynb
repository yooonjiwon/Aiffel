{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 영화리뷰 감성 분석\n",
    "[데이터셋 링크](https://github.com/e9t/nsmc)\n",
    "\n",
    "## 데이터 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_table('~/aiffel/sentiment_classification/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    # 데이터 중복 제거\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    # NaN 결측치 제거\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        # 토큰화\n",
    "        temp_X = tokenizer.morphs(sentence) \n",
    "        # Stopwords 제거\n",
    "        temp_X = [word for word in temp_X if not word in stopwords]\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        # Tokenization\n",
    "        temp_X = tokenizer.morphs(sentence)\n",
    "        # Stopwords 제거\n",
    "        temp_X = [word for word in temp_X if not word in stopwords]\n",
    "        X_test.append(temp_X)\n",
    "\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    # 사전 인덱스 스트링으로 변환\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "\n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    \n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "\n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델구성을 위한 데이터 분석 및 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.971024731364448\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.84408055468762\n",
      "pad_sequences maxlen :  41\n",
      "전체 문장의 0.9342629991962691%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 내 문장 길이 분포\n",
    "total_data_text = list(X_train) + list(X_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "# 적절한 최대 문장 길이 지정\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 41)\n"
     ]
    }
   ],
   "source": [
    "# keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가\n",
    "# padding을 문장 뒤,앞 중 어디로 하느냐에 따라 RNN 성능 차이남.\n",
    "      \n",
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                     value=word_to_index[\"<PAD>\"],\n",
    "                                                     padding='post', # 혹은 'pre'\n",
    "                                                     maxlen=maxlen)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                    value=word_to_index[\"<PAD>\"],\n",
    "                                                    padding='post', # 혹은 'pre'\n",
    "                                                    maxlen=maxlen)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델구성 및 validation set 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 50)                13400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 408       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 173,817\n",
      "Trainable params: 173,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "lstm_model = keras.Sequential()\n",
    "lstm_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "lstm_model.add(keras.layers.SpatialDropout1D(0.4))\n",
    "lstm_model.add(keras.layers.LSTM(50, dropout=0.2, recurrent_dropout=0.2))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "lstm_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "lstm_model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 50)                10200     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 408       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 170,617\n",
      "Trainable params: 170,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "gru_model = keras.Sequential()\n",
    "gru_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "gru_model.add(keras.layers.GRU(50))   # 가장 널리 쓰이는 RNN인 gru 레이어를 사용하였습니다. 이때 gru state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "gru_model.add(keras.layers.Dropout(0.3))\n",
    "gru_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "gru_model.add(keras.layers.Dropout(0.3))\n",
    "gru_model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 64)          640000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 64)          28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          7184      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 676,065\n",
      "Trainable params: 676,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 64  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "cnn_model = keras.Sequential()\n",
    "cnn_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "cnn_model.add(keras.layers.Conv1D(64, 7, activation='relu'))\n",
    "cnn_model.add(keras.layers.MaxPooling1D(5))\n",
    "cnn_model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "cnn_model.add(keras.layers.GlobalMaxPooling1D())\n",
    "cnn_model.add(keras.layers.Dropout(0.3))\n",
    "cnn_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "cnn_model.add(keras.layers.Dropout(0.3))\n",
    "cnn_model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,145\n",
      "Trainable params: 160,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "global_l_model = keras.Sequential()\n",
    "global_l_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "global_l_model.add(keras.layers.GlobalMaxPooling1D())\n",
    "global_l_model.add(keras.layers.Dropout(0.3))\n",
    "global_l_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "global_l_model.add(keras.layers.Dropout(0.3))\n",
    "global_l_model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "global_l_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10)                1080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 164,793\n",
      "Trainable params: 164,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_lstm_model = keras.Sequential()\n",
    "cnn_lstm_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "cnn_lstm_model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "cnn_lstm_model.add(keras.layers.MaxPooling1D(5))\n",
    "cnn_lstm_model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "cnn_lstm_model.add(keras.layers.SpatialDropout1D(0.4))\n",
    "cnn_lstm_model.add(keras.layers.LSTM(10, dropout=0.2, recurrent_dropout=0.2))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "cnn_lstm_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "cnn_lstm_model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "cnn_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136182, 41)\n",
      "(136182,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "X_val = X_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = X_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 훈련 개시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "266/266 [==============================] - 19s 71ms/step - loss: 0.5071 - accuracy: 0.7267 - val_loss: 0.3677 - val_accuracy: 0.8385\n",
      "Epoch 2/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.3713 - accuracy: 0.8397 - val_loss: 0.3487 - val_accuracy: 0.8484\n",
      "Epoch 3/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.3476 - accuracy: 0.8535 - val_loss: 0.3467 - val_accuracy: 0.8516\n",
      "Epoch 4/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.3349 - accuracy: 0.8591 - val_loss: 0.3543 - val_accuracy: 0.8476\n",
      "Epoch 5/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.3242 - accuracy: 0.8638 - val_loss: 0.3411 - val_accuracy: 0.8534\n",
      "Epoch 6/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.3180 - accuracy: 0.8660 - val_loss: 0.3431 - val_accuracy: 0.8511\n",
      "Epoch 7/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.3109 - accuracy: 0.8683 - val_loss: 0.3363 - val_accuracy: 0.8539\n",
      "Epoch 8/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.3052 - accuracy: 0.8702 - val_loss: 0.3420 - val_accuracy: 0.8518\n",
      "Epoch 9/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.3006 - accuracy: 0.8720 - val_loss: 0.3394 - val_accuracy: 0.8547\n",
      "Epoch 10/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.2970 - accuracy: 0.8739 - val_loss: 0.3521 - val_accuracy: 0.8532\n",
      "Epoch 11/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.2913 - accuracy: 0.8763 - val_loss: 0.3388 - val_accuracy: 0.8539\n",
      "Epoch 12/30\n",
      "266/266 [==============================] - 19s 71ms/step - loss: 0.2881 - accuracy: 0.8771 - val_loss: 0.3406 - val_accuracy: 0.8576\n",
      "Epoch 13/30\n",
      "266/266 [==============================] - 19s 71ms/step - loss: 0.2844 - accuracy: 0.8784 - val_loss: 0.3377 - val_accuracy: 0.8573\n",
      "Epoch 14/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.2817 - accuracy: 0.8789 - val_loss: 0.3382 - val_accuracy: 0.8549\n",
      "Epoch 15/30\n",
      "266/266 [==============================] - 19s 71ms/step - loss: 0.2764 - accuracy: 0.8820 - val_loss: 0.3453 - val_accuracy: 0.8570\n",
      "Epoch 16/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.2721 - accuracy: 0.8833 - val_loss: 0.3513 - val_accuracy: 0.8552\n",
      "Epoch 17/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.2698 - accuracy: 0.8848 - val_loss: 0.3455 - val_accuracy: 0.8571\n",
      "Epoch 18/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.2669 - accuracy: 0.8861 - val_loss: 0.3381 - val_accuracy: 0.8556\n",
      "Epoch 19/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.2642 - accuracy: 0.8878 - val_loss: 0.3591 - val_accuracy: 0.8540\n",
      "Epoch 20/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.2612 - accuracy: 0.8890 - val_loss: 0.3443 - val_accuracy: 0.8533\n",
      "Epoch 21/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.2579 - accuracy: 0.8903 - val_loss: 0.3515 - val_accuracy: 0.8547\n",
      "Epoch 22/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.2565 - accuracy: 0.8908 - val_loss: 0.3425 - val_accuracy: 0.8562\n",
      "Epoch 23/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.2529 - accuracy: 0.8931 - val_loss: 0.3627 - val_accuracy: 0.8548\n",
      "Epoch 24/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.2524 - accuracy: 0.8932 - val_loss: 0.3642 - val_accuracy: 0.8536\n",
      "Epoch 25/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.2488 - accuracy: 0.8946 - val_loss: 0.3686 - val_accuracy: 0.8520\n",
      "Epoch 26/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.2472 - accuracy: 0.8959 - val_loss: 0.3626 - val_accuracy: 0.8560\n",
      "Epoch 27/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.2455 - accuracy: 0.8968 - val_loss: 0.3592 - val_accuracy: 0.8557\n",
      "Epoch 28/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.2449 - accuracy: 0.8975 - val_loss: 0.3628 - val_accuracy: 0.8516\n",
      "Epoch 29/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.2431 - accuracy: 0.8972 - val_loss: 0.3589 - val_accuracy: 0.8532\n",
      "Epoch 30/30\n",
      "266/266 [==============================] - 19s 70ms/step - loss: 0.2420 - accuracy: 0.8990 - val_loss: 0.3687 - val_accuracy: 0.8549\n"
     ]
    }
   ],
   "source": [
    "lstm_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=30  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "lstm_history = lstm_model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "266/266 [==============================] - 7s 27ms/step - loss: 0.4876 - accuracy: 0.7596 - val_loss: 0.3410 - val_accuracy: 0.8491\n",
      "Epoch 2/10\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.3527 - accuracy: 0.8616 - val_loss: 0.3258 - val_accuracy: 0.8562\n",
      "Epoch 3/10\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.3069 - accuracy: 0.8826 - val_loss: 0.3243 - val_accuracy: 0.8609\n",
      "Epoch 4/10\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.2581 - accuracy: 0.9043 - val_loss: 0.3480 - val_accuracy: 0.8538\n",
      "Epoch 5/10\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.2103 - accuracy: 0.9252 - val_loss: 0.3858 - val_accuracy: 0.8493\n",
      "Epoch 6/10\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.1634 - accuracy: 0.9451 - val_loss: 0.4535 - val_accuracy: 0.8420\n",
      "Epoch 7/10\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.1268 - accuracy: 0.9587 - val_loss: 0.5686 - val_accuracy: 0.8408\n",
      "Epoch 8/10\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.1046 - accuracy: 0.9669 - val_loss: 0.6092 - val_accuracy: 0.8423\n",
      "Epoch 9/10\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0867 - accuracy: 0.9731 - val_loss: 0.7252 - val_accuracy: 0.8391\n",
      "Epoch 10/10\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0763 - accuracy: 0.9767 - val_loss: 0.7780 - val_accuracy: 0.8412\n"
     ]
    }
   ],
   "source": [
    "cnn_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "cnn_history = cnn_model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.6306 - accuracy: 0.6622 - val_loss: 0.4844 - val_accuracy: 0.8155\n",
      "Epoch 2/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4701 - accuracy: 0.8029 - val_loss: 0.3919 - val_accuracy: 0.8356\n",
      "Epoch 3/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4202 - accuracy: 0.8286 - val_loss: 0.3723 - val_accuracy: 0.8403\n",
      "Epoch 4/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3947 - accuracy: 0.8401 - val_loss: 0.3637 - val_accuracy: 0.8417\n",
      "Epoch 5/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3785 - accuracy: 0.8472 - val_loss: 0.3596 - val_accuracy: 0.8462\n",
      "Epoch 6/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3653 - accuracy: 0.8516 - val_loss: 0.3592 - val_accuracy: 0.8456\n",
      "Epoch 7/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3555 - accuracy: 0.8570 - val_loss: 0.3582 - val_accuracy: 0.8456\n",
      "Epoch 8/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3485 - accuracy: 0.8594 - val_loss: 0.3588 - val_accuracy: 0.8456\n",
      "Epoch 9/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3429 - accuracy: 0.8604 - val_loss: 0.3600 - val_accuracy: 0.8454\n",
      "Epoch 10/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3391 - accuracy: 0.8621 - val_loss: 0.3618 - val_accuracy: 0.8447\n",
      "Epoch 11/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3338 - accuracy: 0.8646 - val_loss: 0.3622 - val_accuracy: 0.8473\n",
      "Epoch 12/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3270 - accuracy: 0.8673 - val_loss: 0.3636 - val_accuracy: 0.8437\n",
      "Epoch 13/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3251 - accuracy: 0.8680 - val_loss: 0.3668 - val_accuracy: 0.8422\n",
      "Epoch 14/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3231 - accuracy: 0.8693 - val_loss: 0.3680 - val_accuracy: 0.8431\n",
      "Epoch 15/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3182 - accuracy: 0.8711 - val_loss: 0.3709 - val_accuracy: 0.8421\n",
      "Epoch 16/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3164 - accuracy: 0.8710 - val_loss: 0.3710 - val_accuracy: 0.8423\n",
      "Epoch 17/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3143 - accuracy: 0.8736 - val_loss: 0.3722 - val_accuracy: 0.8410\n",
      "Epoch 18/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3116 - accuracy: 0.8742 - val_loss: 0.3749 - val_accuracy: 0.8420\n",
      "Epoch 19/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3099 - accuracy: 0.8749 - val_loss: 0.3764 - val_accuracy: 0.8417\n",
      "Epoch 20/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3087 - accuracy: 0.8745 - val_loss: 0.3790 - val_accuracy: 0.8410\n"
     ]
    }
   ],
   "source": [
    "global_l_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "global_l_history = global_l_model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "266/266 [==============================] - 7s 27ms/step - loss: 0.5284 - accuracy: 0.7191 - val_loss: 0.3567 - val_accuracy: 0.8445\n",
      "Epoch 2/10\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.3581 - accuracy: 0.8500 - val_loss: 0.3442 - val_accuracy: 0.8507\n",
      "Epoch 3/10\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.3285 - accuracy: 0.8635 - val_loss: 0.3408 - val_accuracy: 0.8532\n",
      "Epoch 4/10\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.3101 - accuracy: 0.8728 - val_loss: 0.3379 - val_accuracy: 0.8554\n",
      "Epoch 5/10\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.2923 - accuracy: 0.8823 - val_loss: 0.3375 - val_accuracy: 0.8515\n",
      "Epoch 6/10\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.2730 - accuracy: 0.8920 - val_loss: 0.3478 - val_accuracy: 0.8540\n",
      "Epoch 7/10\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.2520 - accuracy: 0.9037 - val_loss: 0.3597 - val_accuracy: 0.8507\n",
      "Epoch 8/10\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.2280 - accuracy: 0.9163 - val_loss: 0.3818 - val_accuracy: 0.8494\n",
      "Epoch 9/10\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.2042 - accuracy: 0.9276 - val_loss: 0.4056 - val_accuracy: 0.8452\n",
      "Epoch 10/10\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.1819 - accuracy: 0.9383 - val_loss: 0.4285 - val_accuracy: 0.8428\n"
     ]
    }
   ],
   "source": [
    "cnn_lstm_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "cnn_lstm_history = cnn_lstm_model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.6226 - accuracy: 0.5943 - val_loss: 0.3893 - val_accuracy: 0.8317\n",
      "Epoch 2/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.3799 - accuracy: 0.8435 - val_loss: 0.3511 - val_accuracy: 0.8456\n",
      "Epoch 3/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.3506 - accuracy: 0.8591 - val_loss: 0.3519 - val_accuracy: 0.8496\n",
      "Epoch 4/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.3372 - accuracy: 0.8657 - val_loss: 0.3457 - val_accuracy: 0.8497\n",
      "Epoch 5/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.3292 - accuracy: 0.8677 - val_loss: 0.3366 - val_accuracy: 0.8519\n",
      "Epoch 6/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.3194 - accuracy: 0.8730 - val_loss: 0.3397 - val_accuracy: 0.8518\n",
      "Epoch 7/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.3084 - accuracy: 0.8769 - val_loss: 0.3397 - val_accuracy: 0.8568\n",
      "Epoch 8/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2985 - accuracy: 0.8809 - val_loss: 0.3388 - val_accuracy: 0.8563\n",
      "Epoch 9/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2814 - accuracy: 0.8888 - val_loss: 0.3597 - val_accuracy: 0.8572\n",
      "Epoch 10/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2692 - accuracy: 0.8945 - val_loss: 0.3388 - val_accuracy: 0.8586\n",
      "Epoch 11/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2585 - accuracy: 0.8988 - val_loss: 0.3497 - val_accuracy: 0.8568\n",
      "Epoch 12/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2501 - accuracy: 0.9035 - val_loss: 0.3703 - val_accuracy: 0.8534\n",
      "Epoch 13/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2409 - accuracy: 0.9067 - val_loss: 0.3635 - val_accuracy: 0.8513\n",
      "Epoch 14/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2328 - accuracy: 0.9103 - val_loss: 0.3889 - val_accuracy: 0.8510\n",
      "Epoch 15/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2262 - accuracy: 0.9139 - val_loss: 0.4088 - val_accuracy: 0.8509\n",
      "Epoch 16/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2221 - accuracy: 0.9151 - val_loss: 0.4083 - val_accuracy: 0.8499\n",
      "Epoch 17/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2138 - accuracy: 0.9182 - val_loss: 0.4257 - val_accuracy: 0.8445\n",
      "Epoch 18/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2096 - accuracy: 0.9192 - val_loss: 0.4844 - val_accuracy: 0.8481\n",
      "Epoch 19/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2044 - accuracy: 0.9221 - val_loss: 0.4895 - val_accuracy: 0.8473\n",
      "Epoch 20/20\n",
      "266/266 [==============================] - 1s 5ms/step - loss: 0.2017 - accuracy: 0.9237 - val_loss: 0.4520 - val_accuracy: 0.8452\n"
     ]
    }
   ],
   "source": [
    "gru_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "gru_history = gru_model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss, Accuracy 그래프 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 12s - loss: 0.3810 - accuracy: 0.8514\n",
      "1537/1537 - 3s - loss: 0.7832 - accuracy: 0.8386\n",
      "1537/1537 - 1s - loss: 0.3867 - accuracy: 0.8386\n",
      "1537/1537 - 4s - loss: 0.4344 - accuracy: 0.8410\n",
      "1537/1537 - 2s - loss: 0.4780 - accuracy: 0.8391\n",
      "LSTM:  [0.38103875517845154, 0.851394534111023]\n",
      "CNN:  [0.783225417137146, 0.8385580778121948]\n",
      "GlobalMaxPooling1D() 레이어 하나만:  [0.38669446110725403, 0.8385784029960632]\n",
      "CNN-LSTM:  [0.43440237641334534, 0.8409585356712341]\n",
      "gru network:  [0.47800058126449585, 0.8391073346138]\n"
     ]
    }
   ],
   "source": [
    "lstm_results = lstm_model.evaluate(X_test,  y_test, verbose=2)\n",
    "cnn_results = cnn_model.evaluate(X_test,  y_test, verbose=2)\n",
    "global_l_results = global_l_model.evaluate(X_test,  y_test, verbose=2)\n",
    "cnn_lstm_results = cnn_lstm_model.evaluate(X_test,  y_test, verbose=2)\n",
    "gru_results = gru_model.evaluate(X_test,  y_test, verbose=2)\n",
    "# feed_results = feed_model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(\"LSTM: \",lstm_results)\n",
    "print(\"CNN: \",cnn_results)\n",
    "print(\"GlobalMaxPooling1D() 레이어 하나만: \",global_l_results)\n",
    "print(\"CNN-LSTM: \",cnn_lstm_results)\n",
    "print(\"gru network: \",gru_results)\n",
    "# print(\"transformer: \",cnn_lstm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0036/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47112 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/aiffel0036/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51060 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/aiffel0036/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50612 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/aiffel0036/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54616 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/aiffel0036/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45208 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/aiffel0036/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47564 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/aiffel0036/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47112 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/aiffel0036/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51060 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/aiffel0036/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50612 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/aiffel0036/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54616 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/aiffel0036/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45208 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/aiffel0036/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47564 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABP4AAALJCAYAAAAkr+3vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXiV5Z3/8fdNEggh7GETEJBNWcLqXnGtG9St2qq1Sm31132sU0c7nbZOl7lmpv46jl3012nHpbVFa93BDfdqawVEkFVAQGQLeyCEbPfvjydAQHZyeHKS9+u6znXOec6T53xPDiR3Puf+PneIMSJJkiRJkiSpcWmWdgGSJEmSJEmS6p/BnyRJkiRJktQIGfxJkiRJkiRJjZDBnyRJkiRJktQIGfxJkiRJkiRJjZDBnyRJkiRJktQIGfxJapRCCItDCOekXYckSZIkSWkx+JPUJIUQeocQYgghN+1aJEmSlN1CCFeHEKaEEDaHEFaEEJ4JIXwihHB77Zjzijr75tZu6117/77a+yfU2adfCCEe+VciqbEx+JMkSZIk6RCFEG4G7gT+DegCHA38Cri4dpd1wA9DCDn7OMw64MeZrFNS02TwJ6lRCyGcUPvp66YQwqoQws9qH3qt9npD7SezJ4cQxocQ3ggh/FcIYUMIYVEI4ZTa7R+GEFaHEK5L67VIkiSpYQkhtAV+CHwtxvhojHFLjLEyxvhUjPGW2t2eBSqAa/ZxqPuB4hDC6RkuWVITY/AnqbH7b+C/Y4xtgL7Aw7Xbx9Ret4sxFsYY/1p7/0RgBtAR+AMwATge6EcyWPtFCKHwSBUvSZKkBu1kIB94bB/7ROB7wA9CCHl72aeMZMbgT+q3PElNncGfpMauEugXQiiKMW6OMf5tP/t/EGO8N8ZYDTwE9AR+GGPcFmN8nuTT2n4ZrlmSJEnZoSOwJsZYta+dYoxPAiXAl/ax2/8Djg4hXFCP9Ulq4gz+JDV2XwQGAHNDCG+HEMbtZ/9VdW5vBYgx7r7NGX+SJEkCWAsUHeCCcf8CfJdkhuDHxBi3AT+qvYR6q1BSk2bwJ6lRizG+H2O8CugM/AfwSAihFUnLhSRJknQ4/gqUA5fsb8cY4wvAAuCr+9jtXqAtcGm9VCepyTuQTyUkKWuFEK4BnosxloQQNtRuriZptagBjgHmp1WfJEmSsleMcWMI4fvAL0MIVcDzJKeaOQc4k+TcfXV9F3hiH8erCiHcDtyVmYolNTXO+JPU2J0PzAohbCZZ6OPKGGN5jLGM5OTJb9Su4HtSqlVKkiQpK8UYfwbcTNLKWwJ8CHwdeHwP+74B/H0/h/wjsKKey5TURIUY7XaTJEmSJEmSGhtn/EmSJEmSJEmNkMGfJEmSJEmS1AgZ/EmSJEmSJEmNkMGfJEmSJEmS1Ajlpl3AwSoqKoq9e/dOuwxJkqT9mjp16poYY6e069ChcdwpSZKyxd7GnVkX/PXu3ZspU6akXYYkSdJ+hRCWpF2DDp3jTkmSlC32Nu7MaKtvCOH8EMK8EMKCEMJte3i8bQjhqRDCuyGEWSGEL2SyHkmSJEmSJKmpyFjwF0LIAX4JXAAMAq4KIQzabbevAbNjjMOAM4D/G0JonqmaJEmSJEmSpKYikzP+TgAWxBgXxRgrgAnAxbvtE4HWIYQAFALrgKoM1iRJkiRJkiQ1CZk8x1934MM695cBJ+62zy+AJ4HlQGvgszHGmgzWJElS1qisrGTZsmWUl5enXYr2Iz8/nx49epCXl5d2KZIkSQfNcWf2ONhxZyaDv7CHbXG3++cB04GzgL7ACyGE12OMm3Y5UAg3AjcCHH300RkoVZKkhmfZsmW0bt2a3r17k0yOV0MUY2Tt2rUsW7aMPn36pF2ODpPjTklSU+S4Mzscyrgzk62+y4Cede73IJnZV9cXgEdjYgHwAXDs7geKMf46xjg6xji6U6ePrUwsSVKjVF5eTseOHR18NXAhBDp27Ogn5I2E405JUlPkuDM7HMq4M5PB39tA/xBCn9oFO64kaeutaylwNkAIoQswEFiUwZokScoqDr6yg++TJEnKdo5nssPBvk8Za/WNMVaFEL4OPAfkAP8bY5wVQvhy7eP3AD8C7gshzCRpDb41xrgmUzVJkiRJkiRJTUUmZ/wRY5wUYxwQY+wbY/xJ7bZ7akM/YozLY4znxhiHxhiHxBh/n8l6JEnSgVu7di3Dhw9n+PDhdO3ale7du++4X1FRsc+vnTJlCt/85jcP6vl69+7NmjV+/idJktTUOO7MnEwu7iFJkrJYx44dmT59OgC33347hYWFfPvb397xeFVVFbm5ex5KjB49mtGjRx+ROiVJkpTdHHdmTkZn/EmSpMZl/Pjx3HzzzZx55pnceuut/P3vf+eUU05hxIgRnHLKKcybNw+AV155hXHjxgHJ4O3666/njDPO4JhjjuGuu+7a7/P87Gc/Y8iQIQwZMoQ777wTgC1btjB27FiGDRvGkCFDeOihhwC47bbbGDRoEMXFxbsMECVJe1BTnXYFknRAHHfWD2f8SZKUBf71qVnMXr6pXo856Kg2/OBTgw/66+bPn8/kyZPJyclh06ZNvPbaa+Tm5jJ58mT++Z//mT//+c8f+5q5c+fy8ssvU1paysCBA/nKV75CXl7eHo8/depU7r33Xt566y1ijJx44omcfvrpLFq0iKOOOoqJEycCsHHjRtatW8djjz3G3LlzCSGwYcOGg349ktRkbFwGv7sULrwDjjk97WokNVCOOxvXuNMZf5Ik6aBcccUV5OTkAMkg6IorrmDIkCF861vfYtasWXv8mrFjx9KiRQuKioro3Lkzq1at2uvx//KXv3DppZfSqlUrCgsLueyyy3j99dcZOnQokydP5tZbb+X111+nbdu2tGnThvz8fL70pS/x6KOPUlBQkJHXLElZr3wT/OGzsGkFtCpKuxpJOiCOOw+fM/4kScoCh/IJaaa0atVqx+3vfe97nHnmmTz22GMsXryYM844Y49f06JFix23c3JyqKqq2uvxY4x73D5gwACmTp3KpEmT+M53vsO5557L97//ff7+97/z4osvMmHCBH7xi1/w0ksvHdoLk6TGqroKHvkCrJ4Dn/sTdGk4v1MkNTyOOxvXuNMZf5Ik6ZBt3LiR7t27A3DffffVyzHHjBnD448/TllZGVu2bOGxxx7jtNNOY/ny5RQUFHDNNdfw7W9/m2nTprF582Y2btzIhRdeyJ133rnjpNCSpFoxwjO3wILJMO5n0O/stCuSpEPiuPPQOONPkiQdsn/6p3/iuuuu42c/+xlnnXVWvRxz5MiRjB8/nhNOOAGAL33pS4wYMYLnnnuOW265hWbNmpGXl8fdd99NaWkpF198MeXl5cQY+a//+q96qUGSGo2//gKm/C+cehOMGp92NZJ0yBx3Hpqwt2mNDdXo0aPjlClT0i5DkqSMmzNnDscdd1zaZegA7en9CiFMjTGOTqkkHSbHncp6s5+Ah6+DQRfB5fdBMxu+JO2Z487scjDjTn/yS5IkSVJjs2wKPHoj9BgNl/4/Qz9JaqL86S9JkiRJjcn6xfDHK6GwC1z5R8hrmXZFkqSUeI4/SZIkSWostm6ABz8D1RUwfiIUdkq7IklSigz+JEmSJKkxqKqAhz8P6xbB5x+DTgPTrkiSlDKDP0mSJEnKdjHC09+CD16DS+6GPqelXZEkqQHwHH+SJEmSlO1evwOm/x5OvxWGX512NZKkBsLgT5Ik7dEZZ5zBc889t8u2O++8k69+9av7/JopU6YAcOGFF7Jhw4aP7XP77bdzxx137PO5H3/8cWbPnr3j/ve//30mT558MOXv0SuvvMK4ceMO+ziS1KDMfARe+jEM/Qyc8Z20q5Gkg+a4M3MM/iRJ0h5dddVVTJgwYZdtEyZM4Kqrrjqgr580aRLt2rU7pOfefQD2wx/+kHPOOeeQjiVJjdqSv8LjX4GjT4GLfwEhpF2RJB00x52ZY/AnSZL26PLLL+fpp59m27ZtACxevJjly5fziU98gq985SuMHj2awYMH84Mf/GCPX9+7d2/WrFkDwE9+8hMGDhzIOeecw7x583bs8z//8z8cf/zxDBs2jE9/+tOUlZXx5ptv8uSTT3LLLbcwfPhwFi5cyPjx43nkkUcAePHFFxkxYgRDhw7l+uuv31Ff7969+cEPfsDIkSMZOnQoc+fO3efrW7duHZdccgnFxcWcdNJJzJgxA4BXX32V4cOHM3z4cEaMGEFpaSkrVqxgzJgxDB8+nCFDhvD6668f3jdXkurD2oUw4Wpo2xOufBByW6RdkSQdEsedmRt3uriHJEnZ4JnbYOXM+j1m16Fwwb/v9eGOHTtywgkn8Oyzz3LxxRczYcIEPvvZzxJC4Cc/+QkdOnSgurqas88+mxkzZlBcXLzH40ydOpUJEybwzjvvUFVVxciRIxk1ahQAl112GTfccAMA//Iv/8Jvf/tbvvGNb3DRRRcxbtw4Lr/88l2OVV5ezvjx43nxxRcZMGAA1157LXfffTc33XQTAEVFRUybNo1f/epX3HHHHfzmN7/Z6+v7wQ9+wIgRI3j88cd56aWXuPbaa5k+fTp33HEHv/zlLzn11FPZvHkz+fn5/PrXv+a8887ju9/9LtXV1ZSVlR3Ut1qS6l3ZOnjwiuT25/4EBR3SrUdS4+G4E2g8405n/EmSpL2q23ZRt93i4YcfZuTIkYwYMYJZs2bt0h6xu9dff51LL72UgoIC2rRpw0UXXbTjsffee4/TTjuNoUOH8uCDDzJr1qx91jNv3jz69OnDgAEDALjuuut47bXXdjx+2WWXATBq1CgWL168z2P95S9/4fOf/zwAZ511FmvXrmXjxo2ceuqp3Hzzzdx1111s2LCB3Nxcjj/+eO69915uv/12Zs6cSevWrfd5bEnKqKptMOFzsPFDuOqP0LFv2hVJ0mFz3JmZcacz/iRJygb7+IQ0ky655BJuvvlmpk2bxtatWxk5ciQffPABd9xxB2+//Tbt27dn/PjxlJeX7/M4YS/nnBo/fjyPP/44w4YN47777uOVV17Z53FijPt8vEWLpM0tJyeHqqqqgz5WCIHbbruNsWPHMmnSJE466SQmT57MmDFjeO2115g4cSKf//znueWWW7j22mv3eXxJyogY4YmvwdI34dO/haNPSrsiSY2N406g8Yw7nfEnSZL2qrCwkDPOOIPrr79+x6eumzZtolWrVrRt25ZVq1bxzDPP7PMYY8aM4bHHHmPr1q2Ulpby1FNP7XistLSUbt26UVlZyYMPPrhje+vWrSktLf3YsY499lgWL17MggULAPjd737H6aeffkivbcyYMTue85VXXqGoqIg2bdqwcOFChg4dyq233sro0aOZO3cuS5YsoXPnztxwww188YtfZNq0aYf0nJJ02F7+N5j5JzjrezD08v3vL0lZwnFnZsadzviTJEn7dNVVV3HZZZftaL0YNmwYI0aMYPDgwRxzzDGceuqp+/z6kSNH8tnPfpbhw4fTq1cvTjvttB2P/ehHP+LEE0+kV69eDB06dMeg68orr+SGG27grrvu2nFyZYD8/HzuvfderrjiCqqqqjj++OP58pe/fEiv6/bbb+cLX/gCxcXFFBQUcP/99wNw55138vLLL5OTk8OgQYO44IILmDBhAj/96U/Jy8ujsLCQBx544JCeU5IOy/Q/wGv/CSOugdP+Me1qJKneOe6s/3Fn2N/UxYZm9OjRccqUKWmXIUlSxs2ZM4fjjjsu7TJ0gPb0foUQpsYYR6dUkg6T4041KIv/Ag9cAr1OgWv+DDl5aVckqRFx3JldDmbcaauvJEmSJDV0z30X2naHzzxg6CdJOmAGf5IkSZLUkK14F1ZMh5O+Ci3bpV2NJCmLGPxJktSAZdspOZoq3ydJGTXtAchpAcWfSbsSSY2Y45nscLDvk8GfJEkNVH5+PmvXrnUQ1sDFGFm7di35+flplyKpMaoogxl/gkEXQ8v2aVcjqZFy3JkdDmXc6aq+kiQ1UD169GDZsmWUlJSkXYr2Iz8/nx49eqRdhqTGaPYTsG0jjLou7UokNWKOO7PHwY47Df4kSWqg8vLy6NOnT9plSJLSNO1+6NAXep2adiWSGjHHnY2Xrb6SJEmS1BCVzIOlf4WR10IIaVcjScpCGQ3+QgjnhxDmhRAWhBBu28Pjt4QQptde3gshVIcQOmSyJkmSJEnKCtMegGa5MPzqtCuRJGWpjAV/IYQc4JfABcAg4KoQwqC6+8QYfxpjHB5jHA58B3g1xrguUzVJkiRJUlao2gbv/hEGXgCFndOuRpKUpTI54+8EYEGMcVGMsQKYAFy8j/2vAv6YwXokSZIkKTvMmwRla2Gki3pIkg5dJoO/7sCHde4vq932MSGEAuB84M97efzGEMKUEMIUV5iRJElSpjjuVIMx9X5o2xP6npV2JZKkLJbJ4G9PZ5+Ne9n3U8Abe2vzjTH+OsY4OsY4ulOnTvVWoCRJklSX4041COsXw6KXYcQ10Cwn7WokSVksk8HfMqBnnfs9gOV72fdKbPOVJEmSJHjn90CA4Z9LuxJJUpbLZPD3NtA/hNAnhNCcJNx7cvedQghtgdOBJzJYiyRJkiQ1fNVV8M6D0O8caNdz//tLkrQPGQv+YoxVwNeB54A5wMMxxlkhhC+HEL5cZ9dLgedjjFsyVYskSZIkZYUFk6F0OYy8Nu1KJEmNQG4mDx5jnARM2m3bPbvdvw+4L5N1SJIkSVJWmPYAtOoEAy9IuxJJUiOQyVZfSZIkSdKBKl0J85+F4VdDTl7a1UiSGgGDP0mSJElqCKY/CLEaRl6XdiWSpEbC4E+SJEmS0lZTk7T59voEdOybdjWSpEbC4E+SJEmS0rb4dVi/GEY520+SVH8M/iRJkiQpbdPuh/y2cNyn0q5EktSIGPxJkiRJUprK1sGcp6D4SshrmXY1kqRGxOBPkiRJktL07gSoroCR16ZdiSSpkTH4kyRJkqS0xJgs6tF9FHQdknY1kqRGxuBPkiRJktKy7G0omeNsP0lSRhj8SZIkSVJapt0Pea1gyKfTrkSS1AgZ/EmSJElSGso3wXuPwpDLoEXrtKuRJDVCBn+SJEmSlIb3/gyVZTBqfNqVSJIaKYM/SZIkSUrDtPuh8+BkYQ9JkjLA4E+SJEmSjrQVM2D5O8miHiGkXY0kqZEy+JMkSZKkI23aA5DTAoo/k3YlkqRGzOBPkiRJko6kijKY8TAMuggKOqRdjSSpETP4kyRJkqQjac6TsG0jjLwu7UokSY2cwZ8kSZIkHUlT74cOx0DvT6RdiSSpkTP4kyRJkqQjZc37sPRNF/WQJB0RBn+SJEmSdKRMux+a5cKwq9OuRJLUBBj8SZIkSdKRUFUB0/8IA86H1l3SrkaS1AQY/EmSJEnSkTBvEpStcVEPSdIRY/AnSZIkSUfCtAegTXfod3balUiSmgiDP0mSJEnKtPVLYOFLMOIaaJaTdjWSpCbC4E+SJEmSMm36g8n1iGvSrUOS1KQY/EmSJElSJtVUwzu/h75nQbuj065GktSEGPxJkiRJUiYteBE2fQSjXNRDknRkGfxJkiRJUiZNux8KimDABWlXIklqYgz+JEmSJClTlrwJ856B4VdDbvO0q5EkNTEZDf5CCOeHEOaFEBaEEG7byz5nhBCmhxBmhRBezWQ9kiRJknTEzH4CHrgEOhwDJ38t7WokSU1QbqYOHELIAX4JfBJYBrwdQngyxji7zj7tgF8B58cYl4YQOmeqHkmSJEk6Yt76NTzzT9DjeLj6ISjokHZFkqQmKJMz/k4AFsQYF8UYK4AJwMW77XM18GiMcSlAjHF1BuuRJEmSpMyqqYEXfgDP3AIDL4RrnzD0kySlJpPBX3fgwzr3l9Vuq2sA0D6E8EoIYWoI4do9HSiEcGMIYUoIYUpJSUmGypUkSVJT57hTh6WqAh7/MrxxJ4y+Hj77O2hekHZVkqQmLJPBX9jDtrjb/VxgFDAWOA/4XghhwMe+KMZfxxhHxxhHd+rUqf4rlSRJknDcqcNQvgn+cAXMeAjO+h6M/Rk0y0m7KklSE5exc/yRzPDrWed+D2D5HvZZE2PcAmwJIbwGDAPmZ7AuSZIkSao/pSvhwcth1Wy4+Fcw4nNpVyRJEpDZGX9vA/1DCH1CCM2BK4End9vnCeC0EEJuCKEAOBGYk8GaJEmSJKn+lMyH33wS1i6Cqx829JMkNSgZm/EXY6wKIXwdeA7IAf43xjgrhPDl2sfviTHOCSE8C8wAaoDfxBjfy1RNkiRJklRvlr4Ff/wsNMuF8U9D95FpVyRJ0i4y2epLjHESMGm3bffsdv+nwE8zWYckSZIk1au5E+GR66HNUXDNo9ChT9oVSZL0MZls9ZUkSZKkxuft38JD10CXwfDFFwz9JEkNVkZn/EmSJElSoxEjvPRjeP0O6H8eXHEvNG+VdlWSJO2VwZ8kSZIk7U91JTz1DzD9QRh5LYz9L8jxzylJUsPmbypJkiRJ2pdtm+FP18GCyXDGd+D0WyGEtKuSJGm/DP4kSZIkaW82r4YHr4CVM+FTd8Go69KuSJKkA2bwJ0mSJEl7sm4R/O5SKF0FV/4BBp6fdkWSJB0Ugz9JkiRJ2pOnvwVbN8D4p6HH6LSrkSTpoDVLuwBJkiRJanDWLYJFr8DJXzP0kyRlLYM/SZIkSdrdtN9BaAbDP5d2JZIkHTKDP0mSJEmqq7oS3vk99D8X2nZPuxpJkg6ZwZ8kSZIk1TX/WdiyGkaNT7sSSZIOi8GfJEmSJNU19X5o3Q36fTLtSiRJOiwGf5IkSZK03YYPYcFkGHEN5OSmXY0kSYfF4E+SJEmStnvn98n1iM+nW4ckSfXA4E+SJEmSAGqq4Z3fQd+zoH2vtKuRJOmwGfxJkiRJEiQtvps+glHXpV2JJEn1wuBPkiRJkiBZ1KNVJxhwQdqVSJJULwz+JEmSJGnTCpj/LAy/GnKbp12NJEn1wuBPkiRJkqb/HmI1jLTNV5LUeBj8SZIkSWraampg2u+g92nQsW/a1UiSVG8M/iRJkiQ1bR+8AhuWwKjxaVciSVK9MviTJEmS1LRNvR9atodjx6VdiSRJ9crgT5IkSVLTtbkE5k6EYVdDXn7a1UiSVK8M/iRJkiQ1Xe/+AWoqYZSLekiSGh+DP0mSJElNU4ww7QHoeRJ0Gph2NZIk1TuDP0mSJElN05I3YO0CZ/tJkhotgz9JkiRJTdPU+6FFWxh0SdqVSJKUEQZ/kiRJkpqesnUw+wko/gw0L0i7GkmSMsLgT5IkSVLTM+MhqN5mm68kqVHLaPAXQjg/hDAvhLAghHDbHh4/I4SwMYQwvfby/UzWcyDmrSzlinveZM6KTWmXIkmSJCkTYkzafI8aCV2Hpl2NJEkZk5upA4cQcoBfAp8ElgFvhxCejDHO3m3X12OM4zJVx8EqKmzO1CXrmThjBcd1a5N2OZIkSZLq27K3oWQOfOqutCuRJCmjMjnj7wRgQYxxUYyxApgAXJzB56sXHQtbcErfIibOXEGMMe1yJEmSJNW3qfdB80IY8um0K5EkKaMyGfx1Bz6sc39Z7bbdnRxCeDeE8EwIYXAG6zlgY4u78cGaLcy23VeSJElqXMo3wnuPJqFfi8K0q5EkKaMyGfyFPWzbfQrdNKBXjHEY8HPg8T0eKIQbQwhTQghTSkpK6rnMjztvcFdymgUmzliR8eeSJElSw3Gkx51Kwcw/QdVWF/WQJDUJmQz+lgE969zvASyvu0OMcVOMcXPt7UlAXgihaPcDxRh/HWMcHWMc3alTpwyWnOjQqjmn9O3IJNt9JUmSmpQjPe7UERZj0ubbdWiysIckSY1cJoO/t4H+IYQ+IYTmwJXAk3V3CCF0DSGE2tsn1NazNoM1HbCxQ7uxeG0Zs5bb7itJkiQ1CsvfgZUzYeR1EPbUoCRJUuOSseAvxlgFfB14DpgDPBxjnBVC+HII4cu1u10OvBdCeBe4C7gyNpApdjvafWfa7itJkqT6t25LBW8tahCfeTcd0+6H3JZQ/Jm0K5Ek6YjI5Iw/YoyTYowDYox9Y4w/qd12T4zxntrbv4gxDo4xDosxnhRjfDOT9RyM9q2ac2q/IibOsN1XkiRJ9e/HE2dz4++mUlFVk3YpTcO2zTDzERh8KeS3TbsaSZKOiIwGf9lu3NBuLF1Xxnsf2e4rSZKk+jWuuBsbt1byxsI1aZfSNMx6FCo2w6jxaVciSdIRY/C3D+cO7kJus8DTM5fvf2dJkiTpIHyiXyda5+fy9LueWuaImHo/dDoWep6QdiWSJB0xBn/70K4gafd1dV9JkiTVt+a5zThvcFeen72SbVXVaZfTuK18Dz6a4qIekqQmx+BvP8YWd+PDdVuZ+dHGtEuRJElSIzOuuBul5VW8Pt9234yadj/kNIdhV6ZdiSRJR5TB336cN6greTmBiTNswZAkSVL9OrVfEe0K8pg407FmxlRuhRkPwaCLoaBD2tVIknREGfztR9uCPD7Rr4inXd1XkiRJ9SwvpxnnD+7KC7NXUV5pu29GzH4Cyjcmbb6SJDUxBn8HYGzxUXy0YSvvLrPdV5IkSfVrbHE3Nm+r4tX5JWmX0jhNvQ869IXen0i7EkmSjjiDvwPwyUFdatt9Xd1XkiRJ9evkYzrSoVVzTy2TCSXzYOlfYeS1LuohSWqSDP4OQNuWeZzWvxOTZq603VeSJEn1KjenGecP6crkOavYWmG7b72a9gA0y4Phn0u7EkmSUmHwd4DGDu3GRxu2Mv3DDWmXIkmSpEZm3NBulFVU88q81WmX0nhUbYPpf4BjL4TCTmlXI0lSKgz+DtA5g7rQPKeZLRiSJEmqdyce05GiwuY87Viz/sx5Crauc1EPSVKTZvB3gNq2zGPMgCImzVxBTY3tvpIkSao/Oc0CFwzpxotzV1FWUZV2OY3DtPuh3dFwzJlpVyJJUmoM/g7C2OJuLN9Yzju2+0qSJKmejS3uRnllDS/Ntd33sC2bCh+8BiOuhWb+ySNJarr8LXgQzj7Odl9JkiRlxvG9O9C5dQueftex5mGpLIfHvwJtusOJN6ZdjSRJqTqg4C+E0CqE0Kz29oAQwkUhhLzMltbwtMnPY8yATrb7SitnE1sAACAASURBVJIkZaGGPqbNaRa4cGg3Xp63ms3bbPc9ZC//BNbMg4t+Dvlt065GkqRUHeiMv9eA/BBCd+BF4AvAfZkqqiEbV9yNlZvKeefD9WmXIkmSpIPT4Me044q7sa2qhhfnrEq7lOy09C148+cwajz0OzvtaiRJSt2BBn8hxlgGXAb8PMZ4KTAoc2U1XGcf15nmuc1ccU2SJCn7NPgx7cij29O1Tb5jzUNRUZa0+LbtCef+OO1qJElqEA44+AshnAx8DphYuy03MyU1bK3z8zjDdl9JkqRs1ODHtM1q231fnVfCpvLKtMvJLi/9CNYthIt/AS1ap12NJEkNwoEGfzcB3wEeizHOCiEcA7ycubIatrHF3Vi1aRtTl9ruK0mSlEWyYkw7blg3KqprmDzbdt8DtvgN+NvdcPwNcMzpaVcjSVKDcUCfcMYYXwVeBag9IfKaGOM3M1lYQ3b2cV1onpus7nt87w5plyNJkqQDkC1j2hE929G9XUuenrGCy0b2SLuchq9iCzzxVWjfC865Pe1qJElqUA50Vd8/hBDahBBaAbOBeSGEWzJbWsNV2CKXMwcm7b7VtvtKkiRlhWwZ04YQGFvcjdffL2Fjme2++zX5dli/BC65G1oUpl2NJEkNyoG2+g6KMW4CLgEmAUcDn89YVVlgbPFRrC7dxpTF69IuRZIkSQcma8a0Y4d2o7I68vzslWmX0rAtehX+/ms46SvQ65S0q5EkqcE50OAvL4SQRzJIeiLGWAk06aluZx/bmRa5zZg00xXXJEmSskTWjGmLe7SlZ4eWru67L9tK4YmvQ4e+cNb30q5GkqQG6UCDv/8HLAZaAa+FEHoBmzJVVDZo1SKXs47tzKT3VtruK0mSlB2yZkwbQmDs0KN4Y8Ea1m+pSLuchun578GmZUmLb/OCtKuRJKlBOqDgL8Z4V4yxe4zxwphYApyZ4doavAuHdqOkdBtv2+4rSZLU4GXbmHZccTeqaiLPzbLd92MWvAhT74WTvw5Hn5h2NZIkNVgHurhH2xDCz0IIU2ov/5fkk9Im7axjO5Ofl6zuK0mSpIYt28a0g49qQ++OBUz01DK7Kt8IT34DigbAmd9NuxpJkhq0A231/V+gFPhM7WUTcG+misoW29t9n3nP1X0lSZKyQFaNabev7vvmwrWs3bwt7XIajuf+GUpXwCX3QF5+2tVIktSgHWjw1zfG+IMY46Lay78Cx2SysGwxduhRrNlcwVsfrE27FEmSJO1b1o1pxw49iuqayLO2+ybmPw/v/B5OvQl6jEq7GkmSGrwDDf62hhA+sf1OCOFUYGtmSsouZx7biZZ5Oa7uK0mS1PBl3Zj2uG6tOaZTK55+17EmW9fDU9+EzoPgjNvSrkaSpKxwoMHfl4FfhhAWhxAWA78A/k/GqsoiBc1zOeu4zjz73kqqqmvSLkeSJEl7l3Vj2hAC44Z2460P1rK6tDztctL1zG2weXWyim9ui7SrkSQpKxzoqr7vxhiHAcVAcYxxBHDW/r4uhHB+CGFeCGFBCGGvH8uFEI4PIVSHEC4/4MobkLFDu7FmcwV//8DVfSVJkhqqQx3Tpm3csKOoifDce0243XfuRJgxAcZ8G44annY1kiRljQOd8QdAjHFTjHFT7d2b97VvCCEH+CVwATAIuCqEMGgv+/0H8NzB1NKQnDmwMy3zcnjadl9JkqQG72DGtA3BgC6t6d+5kKdmNNGxZtk6eOom6DoUTvt22tVIkpRVDir4203Yz+MnAAtqT5xcAUwALt7Dft8A/gysPoxaUtWyeQ5n2+4rSZKUjfY3pm0QxhUfxduL17FqUxNs9510S3J+v0vuhtzmaVcjSVJWOZzgL+7n8e7Ah3XuL6vdtkMIoTtwKXDPvg4UQrgxhDAlhDClpKTkUGrNuHHF3Vi3pYK/LbLdV5IkKYvsMqZtqOPOscVdiZGmt6Dc7CfgvUfg9FuTGX+SJOmg7DP4CyGUhhA27eFSChy1n2Pv6dPT3cPCO4FbY4zV+zpQjPHXMcbRMcbRnTp12s/TpuOMgZ0paJ7DxJnL0y5FkiRJdRzMmLahjjv7dW7NsV1bM7EptftuLoGnvwXdhsMnbkq7GkmSstI+g78YY+sYY5s9XFrHGHP3c+xlQM8693sAu6dio4EJtauqXQ78KoRwyUG+hgYhPy+Hc47rYruvJElSA3OYY9oGY1xxN6YsWc/yDVvTLiXzYoSJN8O2Urj0HsjJS7siSZKy0uG0+u7P20D/EEKfEEJz4Ergybo7xBj7xBh7xxh7A48AX40xPp7BmjLqwqHdWF9WyV8XrU27FEmSJDUyY4uTyYlNot131qMw50k485+h83FpVyNJUtbKWPAXY6wCvk6yWu8c4OEY46wQwpdDCF/O1POm6YyBnWjVPKdptWBIkiTpiOhT1IrBR7Xh6cY+1ixdBRP/EbqPhpO/kXY1kiRltUzO+CPGOCnGOCDG2DfG+JPabffEGD+2mEeMcXyM8ZFM1pNp+Xk5nDOoC8/OWkml7b6SJEmqZ2OLuzH9ww18uK4s7VIyY9MK+ONnoaIsWcU3J2s6sSVJapAyGvw1RWOHdmNDWSVvLrTdV5IkSfVr3NCk3feZ9xrhrL+PpsL/nAkl8+Ez90OnAWlXJElS1jP4q2djBnSisEUuE2e4uq8kSZLq19EdCyju0bbxtfu+92e490JolgdffB4GXpB2RZIkNQoGf/UsPy+HTw7qwnOzVtnuK0mSpHo3dmg3ZizbyNK1jaDdt6YGXvoJPHI9HDUCbnwZug5JuypJkhoNg78MuHBoNzZureSNBWvSLkWSJEmNzNjibgA8PTPLO0wqtsCfroXX/hNGXAPXPgmtitKuSpKkRsXgLwNO619E6xa5PPjWUsorq9MuR5IkSY1Ij/YFDO/ZjonZ3O674UP43/Ng7kQ479/gol9AbvO0q5IkqdFxmazdxQgfvgU9T4QQDukQ+Xk5fO6kXtzz6kLOvOMVvnl2fy4f1YO8HHNWSdJeVGyB0pWweTVsXgmlq2BbKbTtDu17Q7te0LobNPN3yWHZshY+mgLLpiTthIMuTrsi6ZCMK+7GjyfO4YM1W+hT1Crtcg7Oh3+HCZ+DqnK4+mHo/8m0K5IkqdEy+NvdsreTTx879oPjvwTDroKW7Q76MLddcCxj+hfx0+fn8Z1HZ3LPqwv51jkD+NSwo8hpdmiBoiQpy8QIW9fXBnq1oV7pSti8auf15lVJyFdRuv/j5TRPAsD2vZIwcHsg2L53si2/bYZfUJap2gYrZuwM+j6aAusXJ4+FZnDSVw3+lLUuHJoEfxNnLOfrZ/VPu5wD9+4EePIb0KY7jH8aOg1MuyJJkhq1EGNMu4aDMnr06DhlypTMPUHVNpj1OLz9P0kImFcAQ6+AE26ArkMP+nAxRl6au5qfPjePuStLGdClkJs/OZDzBnchHOKMQklShlRuhaV/g8qyZCZK1bb9XFfUXu/hsa3rk1CvuuLjz9O8EAq7JJfWXaCwa+319m1dk23NW8Gmj2D9B7B+SRJabai9Xr8YyjfuetyW7XcLA3sngWDrbsljLTsc+Va6yq1Qtha2rEmuc1tAq07JJb9d/c1gjBHWLdoZ8C2bAitnQk1l8nib7tB9FPQYDd1Hw1HDk+9vhoUQpsYYR2f8iZQRGR93HqZP3/0mW7ZV8exNY9IuZf9qquHFH8Ibd0KfMXDF/VDQIe2qJElqNPY27jT425fl0+Ht38DMR6BqK/Q8KZkFOOjig/7DqaYmMnHmCv7rhfksWrOF4h5t+cdzBzKmf5EBoCSlrXRV8vN+ym+TcGpfcppDToskwMrN38t1iyRo2xHiddn1dovC+ql76/o9BILb7y/dGXrV1bwwCQALaoPAgg67XrdsX2db7T75bZPTX1RXQtm65Hu0y2X7tjUf31a5j1VHQ05yIv9WnaCg485AcPu2HZfax5oX7jwNR9k6+GjqzqDvo6nJ9wMgrxV0H7lr0NemW/18zw+SwV92a+jB371vfMC/PjWbyTefTr/O9fRzJRO2lcKfb4D5z8Do6+GC/4ScvLSrkiSpUTH4Oxxb18M7DyZ/EK5blPzxMfI6GP0FaNvjoA5VVV3Do+98xH9Pfp+PNmzlhN4d+PZ5Azmhj594SjpCNq2Av/0KFr4EvU6B4y5KrpvlpF3ZkbdqNvz1lzDz4WRm3oALkp/trbvuOdTLaZE959irqYbSFUkIuHk1bF0HZetrr9d9/Lp8I7CXMUHISWbA76sduUWbJDAs6AgFRbXX2+933Hm/uiKZ/belZA/Xtbf39jy5+cnv4NAsCTohud3pOOgxKgn4eoyGTsc2mH/PBn/ZraEHfys3lnPyv7/ITWcP4B/OaaDtvusXwx+vgpJ5cMF/JF00kiSp3hn81YeaGlj0Evz9NzD/2WTWwcALk1mAx5xxUIuBbKuq5qG3P+TnLy2gpHQbYwZ04pZzBzK0RwbOz7T9PXZmodS0lcyDN++Cdx+CWA09ToAV7yYzmguK4NixMOgi6HN6456JESMsfDEJ/Ba+BLktYfjVyfneivqlXV16aqqT8G9PoeDWdVBRtnM2YKuiXQO9+m4hrixPZg9+LBSsvV+1DboV17bsjqi/GZQZYPCX3Rp68AfwmXv+yvqyCl64+fS0S/m4xW/AQ9ckv3OuuB/6npl2RZIkNVoGf/Vt/RKYei9MeyBpZTrExUC2VlTzwF8Xc/erC9lQVsn5g7ty87kDGNCl9cHXFCNsWg4lc2D1XCjZfpmXtKb1OydZNa3vWZ5TpaHZsjYJZn1flAlL/wZv/DfMm5SEXCM/Dyd/LTn/W8UWeP8FmPMkzH8OKjYnbZ0DL0xmAvY9C/Ly034F9aOyPJnZ99dfJT8nC7vACTcmbWf+31OGGPxltwYz7tyHB/66mO8/MYvnbhrDwK6HMH7MlGkPwNM3J79rrn4IOvZNuyJJkho1g79MqSyH2Y/D3/8nOcdQXgEUfyYJAQ9iMZDS8kp++5cP+M3rH7CloopLhnfnpnP606vjHk48HmPSvrV6zs5wb3VtwLetzoneC4qg83FJy1P5RlgwOZm1EZolM336fxL6n5vU6WzAI6u6Mlk8ZsFkWPAirJgOhOR8VAPOS96brsOyp6WwMakoS86Ntn3xhLrnTgs5yUIJ7Y7eubJqu9r7DW3GUU1NMjP5jTvhw7eSGVkn3JhcWnXc89dUlicz4OY8mYSE5RuTc6oNOC8JAft/8vAXQ6jcCmsXwpr5sOb92uv5SStqpwHQbXiy6EK34dC+T/38H9iyBt7+bbJo05YS6DI0CT6HXJa08EoZZPCX3RrcuHMPSkq3cdp/vkSfokL+8KUTad/qCC/gs7vqKnjhe8kpJfqeBZffe1AfikuSpENj8HckLH+nzmIg5dC2J7RonfyhnFeQ/AHdvCC537ywdlurnZe8AkpjCx6fvYFHZ65nU3ULzi3uwcU9y+kfPiJnTZ2Qb5eAr2NyfqPOxyYh3/awr1XRrvXVVMNH0+D955PLiunJ9tbdamcDnpu0LOe3OVLfsaZlw9Ik5FswGT54DbZtSoKknidCv7OSoOb955MT1BOT2Uj9PgkDzoVjzvR9qS81NVC6fOcCCLuHe5tX7bp/XqudK6PWVCf7bVj68QULCjruDAF3BIK14WDbnkdu1lzVNpjxcNLSu2Z+Us/J34ARnzu40K6qAha/BrOfhLkTk7bL3JbQ7+xkgaMB5yUzA/ckxiRs2x7q1Q34Nixl53nkArTrCUUDkvO2rZ4Dq2fvXAW3RRvoWrwzCOw2LJldfaBhYMm8pJ333QlQvQ36n5cEfn3G+GGHjhiDv+zWoMeddbw2v4QvPTCFfp0KeTDN8G/tQpj07eRDpBO/Auf+GHJy06lFkqQmxuDvSCpbB9P/ACtnJG10lWXJdd1LZVnSUncQNjdrQ1m7/hT0GEJhj6FJuNfpWCjsdGh1lq5KQqj3n08GaNs2QbM86HVyEjj1Pxc6DfQP5ENVuRWWvLEz7FszP9netmcSnvQ9G445/ePhyeaS5Pxj859Lrss3QrNcOPrk5D0ZcF4SlPi+7F1NDWxaVid0en9nuLdh6c5gCZIZsG16JAFd+161IV+f2tCudxKg7/693h5sbVhSGxgu2Xns9Utg44e7PgdAYdedxy/qD0UDk/+/HfrUz/n0yjfClHvhb3fD5pXJTN5Tb4JBlxz+H13VVbD0zSQEnPNUcvyc5skHBcddlISeuwd85Rt2fn1uy+TceUUDai/9k+sOfZMPQ+qqqkjacJdPT84/uGI6rHwvCe4g+dCka3ESAm4PBIv671zIIUb44FV48xew4IVkMYhhVyXn7+s04PC+D9IhMPjLblkx7qz16vwSbnhgCv07J+Ffu4IjGP5tXAav/ie88/vk98MF/w6jxh+555ckSQZ/DVJNTXJS/YraELBuIFiRhIVby8uYuaUdL5S0Z+LCKpZvSv747d+5kNMHdGLMgE6c0KcD+XmHuXphdSV8+Pfa2YAvwOpZyfZ2RydhU/9zofdpSVvcLuHl9tvbQ82yXW9XbK7dr87tvIJk1k5R/+S6Y/+9tx5mQk1NElxsWJrMzGzRGlq0TWbUtWidBAWHEqrFmAQe24O+JW8kx8/Nh16nJrMq+519cKFddRUsq31f5j+/2/tyXvK+9DkN8loefL2NQUUZrF2wM3Rauz14WpD839ouv20S5m2fude+985Lmx71uygB7Pw3tnsguGEJrPsgCSW3a5aXnPeoaEAStHc6dmc4diDv66YV8NbdSei3bVMSxp36D8ks0UyEwzU1SZv67CeSluCNH+58rLDLrsHe9us2PQ6vZbe6Mpm9t6I2DFw+HVbO3Pke5xUkQWeXIUlb86r3oFXnnefvO5I/X6TdGPxlt4yPOyvLk7FVPf28fmXeam58YCoDuhby4BdPom1Bhhdq2rwaXv8ZTPltcn/UF+C0f4TWXTL7vJIk6WMM/hqBGCMLVm/m1fklvDq/hLc+WEdFVQ35ec046ZiOnD6gE6cP6ESfolaEwx1Ably2MwRc9EptW2NgZ4veAcor2LWlOa8AtpXCukVQU7lzv5btd4aARbXXHftBh2MOvkWybrC3YenO4GXH5cNdn3t3zfJ2hoAt2iSX/NrrFq13u107W2/x60ngtz0EKRqwM+jrdWr9BXMbPkxmMdV9X3Lzk9bF7a3azXKSPyQqtyaPV5Un15Vb61y2b6+9XVlnn6qtSQtyftvknDz5betc2tVe2u56yWQba4xJ++2O2WR1rjcurbNjSEK97bPKOtaZYbanWXtp2rZ558y4krlQMh/WzEv+X8Sa2p1qX8/2ILDTsUkwWDQg+Te4+wq9gy+FU76ZzII7UmJMZjZXVSQh35E8h1NNdfL92x4ErqgNA9v3Tmb3Db3c8/epQTD4y24ZH3dO/leY9WjyM3zQJcls5sP8ffXy3NX8n99NZWDX1vz+SyfStmUGwr+t6+HNnyezzKu2wfCr4PRbkw8mJUlSKgz+GqGtFdX87YO1vDqvhNfml7BozRYAenZoWRsCdubkvh0pbHGYbX5V25LZa0v/lgRC289TmLf9/IQFu97efv7CvIK9z/KprkpCmzULamdpvZ/M3Fq7IFm4ZIeQDCJ3mSHYL9m2pWTPwd7GZR9vs2zVuXZBhrqXXkkgt600mSlVvnHn7W2lUL5pt9sbd96O1bsev0WbJHzbHvYdiYFvZXnyvrz/fNIWvP6DgzxAqH2fWtZe5ye3c1smr698I2zdkLRs7v793F1u/sfDwBatk2AoVidhbKypvV1d57pm5/26t2vq7Lt5VfI+bJfXarcZZXXaRrN99dmqbcn5kUrm1oaC85LL2vd3fQ8KuyTfl9yWMOKa5Lx1HfqkV3dDEWPDCnglDP6yXcbHnbOfhKn3wqJXk9977fskIeDgSw9r8bWX5q7i//xuKoO6teGBL9Zj+LdtczLL/M2fJ+OEIZ+GM/45+dBWkiSlyuCvCVi6toxX3y/h1XklvLlwDWUV1eTlBEb1as8n+hVxfO8ODOvZ7vDbgjNtW2ltCLiwTvvm+8n9yi17/ppWnXaGeXWDvXZHQ9seHz+P2OGIMZkdtz0ErN6WzMaqj/O0HY41C+DD2nA2r2WdS0ESzO0S8BUk5+A50D8oKsuTAX75xiQI3NPtrXW314akIST1NMtJzqUXmtXezqlz3Sy5/thjtfcLOibnw9vRNnpU0wt3qquSgLtkXjIzsGR+Mhvw+C99fBEfSQ2KwV92O2Ljzi1rYe7TMOuxZAGwWJ10PWwPAbsMOejffZNnr+IrD05l0FFt+d0XT6BN/mGMUyrLYcr/wuv/N1nsaeCFcOZ3oeuQQz+mJEmqVwZ/TUxFVQ1TlqxL2oLnlTB3ZSkAeTmBId3bcnzvDozq1Z7RvdrTsTBL2uFiTGYDrnk/mdVXWDuLr23P+g32JEmqJwZ/2S2VceeWtTD3qTohYE3S7TDoktoQcPABh4AvzF7FVx+cyuDa8K/1wYZ/1ZUw/cFk4Y5NH0Gf0+Gs70HP4w/hhUmSpEwy+GviNpRVMHXJet5evJ4pi9cxY9lGKqqTc4kd06kVx/fqwKje7Tm+dwd6dyw4/HMESpIkg78sl/q4c8uaZDX1WY8l5xOONcl5kAdfCoMvgc6D9hsCPjdrJV97cBrFPdpy//UHGP7VVMN7f4aX/y05lUiP45PA75jT6+mFSZKk+mbwp12UV1bz3kcbdwSBU5asZ+PWZMGLosLmjO7VgdG92zO6dwcGH9WGvJzDWJFTkqQmyuAvuzWocefmkmQ19dmPw+K/JCFg0YDahUEuTrogcltCzsfP7fzseyv5+h+mMaxnO+6//oS9n/85Rpg7EV7+CayeDV2Gwln/AgPOa3qn2ZAkKcsY/GmfamoiC0s27xIELl1XBkB+XjNG9GzPqF7t6du5FUd3aEWvjgV0bNXcmYGSJO2DwV92a7Djzs2rkxBw1uPJQl87VoQnOVdubn6ysnley+Q6N58Nlc2Yv7aKFvktGXx0F3Kb5+/yOLkt4IPXYfm0ZFbhmf+ctBfvbaE2SZLUoBj86aCt2lTOlMXrmbJkHVMWr2fW8o3U1PnnUtgil54dCujVoYBeRQX0qg0Ej+5QwFHtWpLTzFBQktS0Gfxlt6wYd5auggUvwNb1UFWerBBfuTW5riqvc9nGmg2bWLpqLe2a19C7bQ7Nqsvr7LcNWneFMbdA8ZV7nDkoSZIarr2NO/2Nrr3q0iafscXdGFvcDUjag5etL2PJ2uSydF0ZS9ZuYf7qUl6au3rHOQMhWUSkR/skBNweBvbquDMYbPArC0uSJGWD1l1gxDUHtGsR8NaMFVwx4R1GFbXn3huPp9Xe2n4lSVKj4G96HbD8vBz6dW5Nv86tP/ZYdU1k5aZylqzZwpJ124PBLSxZW8a0Jesp3Va1Y98QoEf7lvTtVFjn0oq+nQttH5YkScqgscXdqImRf5jwDtff9zb3fuF4Cpr7J4EkSY2Vv+VVL3KaBbq3a0n3di05ZbfHYoysL6tkydotLF1XxgdrtrCwZAsLV2/mb4vWUl65c6Zg25Z5HNOp1ccCwaM7FLjAiCRJUj341LCjqImRbz00PQn/xp9Ay+Z2Y0iS1BgZ/CnjQgh0aNWcDq2aM+Lo9rs8VlMTWb5x644gcGFJcnl1fgmPTF22Y7/cZoFeHQuSMLBzIccUteLoDgX06FBAl9YtyDUUlCRJOmAXD+8OwLcems4X73+b3153vOGfJEmNkMGfUtWsWXIuwB7tCzh9QKddHttUXsmi3QLBhSVbeGnuaqrqrDKS2yzQrV0+PdoV0KN9y9rjtUwuBoOSJEl7dPHw7tTEyM0Pv8uXHkjCP8/DLElS45LR4C+EcD7w30AO8JsY47/v9vjFwI+AGqAKuCnG+JdM1qTs0SY/j+E92zG8Z7tdtldW17Bs/VaWrS/b7Xorr71fwqpN23bZf1/B4FHtWtKpdQsHuZIkqUm6dEQPamrg24+8yw0PTOE3142mRa7jIkmSGouMBX8hhBzgl8AngWXA2yGEJ2OMs+vs9iLwZIwxhhCKgYeBYzNVkxqHvJxm/H/27jw8qvLu//jnO0v2hAABRHYVUGQngHUBtLZ1qzsqVSm4VfuoT3/WBdtabfv4tFVrrVVrcYG6FfuoWLUuLSqKGxIQFxQUFWWTPSRknUnu3x/nJAxhEkhgmGTyfl3XXHP2850TrXc/5z736VeQrX4F2XHXV0VrtKa4sj4QXB0TDs77bKPWlVbKuR336ZAZVre8dHXLy1DX3Ax1zUtXt1x/Pi9DXXPT1TUvnYYwAABIOWeM6qla53TNEx/oyr+/p7t/MJKnJQAASBGJ7PE3RtJy59wXkmRmsySdIqk++HPObYvZPltSgzgGaL70UHCXweDa4kqt3FKub7ZWan1pldaVVPqfKn2+fqPWl1bt8DhxnY5ZYXXLy1AXPxTslpeurrkZ6pSdps7Zaeroj2XYMStNaSEazAAAoG2YWNhLpZVR/fq5jzXtqQ91yxlDFQhYsssCAAB7KJHBXw9JK2PmV0ka23AjMztN0m8ldZV0YgLrASR5wWDfgmz1bSQYlLyXjmwpr9a6kiqtK63U+pJKrfen15VUaX1JpT5bt00btlWpJk5AKEm56aH6ILAuDOyc4313yg6rU3a6OmWHveXZ6crLDMmMBjYAAEiOC47sp60VEf3p5c+UlxHWDScdQtsEAIA2LpHBX7xWwk4JiXNutqTZZjZO3nh/x+50ILNLJF0iSb17997LZQI7CwRMnXPS1TknXYOU1+h2NbVOm8uqtaW8Wpu2ed+by7Z/6ubXlVRq6doSbSqrVlW0Nu6x0kMB9WgwBmGPfG++V8dMFeSkc+cdAIAEa+/tzp8c219bKyJ68M0v1SEzrP8+tn+ySwIAAHsgkcHfKkm9YuZ7SlrT2MbOudfN7EAzK3DObWywbrqk6ZJUWFjI48BohEfUoAAAIABJREFUNYIBU5fcdHXJTZe67d4+5dVRLxQsi2hTWVV9aLi+tKp+LMKPVm/V5rLqHfZLCwXUMz9zp3Cw7oUlXQgGAQDYY+293Wlm+uVJg1RaGdUf53yqvMyQph7RL9llAQCAFkpk8LdAUn8z6ydptaRzJP0gdgMzO0jS5/7LPUZKSpO0KYE1AUmXlRZSVlpIPTs2vV15ddR/McmOby5etaVc/1n7jTZuaxAMBgPqnu+NN5ifGVZ+Vpo6ZIaVnxWun8/P8r/95bkZYQUJCwEAQIxAwPT7M4aotDKiXz37sfIywjpjVM9klwUAAFogYcGfcy5qZpdLeklSUNKDzrklZnapv/5eSWdImmxmEUkVks52ruH7VoH2KSstpP7dctW/W27c9eXVUa0prtBKPxBcvaVCq4srVFxerU1l1fp8Q5m2lFertDLa6DnMpLyMncNBbxzCtPqXlnTK9sYn7Jydrg6ZYXoWAgCQ4kLBgO6cNEIXzFyga5/8QLkZIX330P2SXRYAAGgma2s5W2FhoSsqKkp2GUCbEa2pVUllVMXl1SquiGhreUTFFdUqLo/4H295cXnE/67WlrJqlTQSGAYDpo5Z4ZhgMH37dE7aDsvzMkPKSQ8pOy1EWAigXTKzhc65wmTXgZah3Sltq4rq3Pvn65M1JZo5dbQOP6gg2SUBAIA4Gmt3JvJRXwCtQCgYqA/jmiNSU6stZdXauM17Qcmmsqr6l5ZsKqvW5m3esk++KdHmMi9IbIyZlJMeUl5GWLkZIf8TVk769uncjJDyYqa9dWEV5KapIJvxCwEASIac9JD+NnW0zvrr27rooSI9dvFhGt4rP9llAQCA3UTwByCucDCgrnkZ6pqXsVvbR2tqtaU84gWD26q02X/MuLQy4n9HVVIZ0TZ/en1ppT7fEK3fJlLTeO/jcNDUvUOm9s/P0P753tuO98/PVPcOGfXT2en8zxkAAImQn5Wmhy8cq4n3vq0pM97V45d8SwP3iz8UCQAAaF34f8oA9opQMLD9Dcdq3v8ZcM6pKlq7QzBYFwhu2FalNcWVWlNcoTXFFXrn8036pqRStQ1ywg6ZYe2fn6n9O3jhoPfxgsHu+ZnqkpOutFBg7/1gAADakW55GXrkwrE68963dP4D8/XEpYerd+esZJcFAAB2geAPQNKZmTLCQWWEg+q6G5lhtKZW60urtKbYe6FJXTC4dmuFVhdXquirLdpasfOjx/lZYXX1w8muuRleUJmTrq553nfd8rzMkMx4tBgAgFi9O2fp4QvH6qy/vq3zHpivJy791m4/GQAAAJKD4A9AmxMKBup79TU2Yv62qqjW+sHg2q2V2lBapfWl3veG0iotWLFZ60urVB2t3WnftFCgPgj0wkDvu2NWmrLSgt4LS9JDyk4Pet9p2+fTQ8HE/ngAAJJo4H65mjl1tM69f77Of+BdPf6jw5Sf1bxxhAEAwL5D8AcgJeWkh9S/W676d2u8C6FzTqVVUa0vqdoxGNxWpQ0l3vfKzeVa+NUWbS6r3q3zhoMWEwYGd5que8lJh8yw8jJjp/1v/+UmvMwEANBajejdUfdNLtTUGQs0ZcYCPXrRWMbaBQCgleK/0ADaLTNTXoYXth3UNafJbSM1tSqpiKi8ukbbqqIqq4pqW1V0h/myqqjKqmvq15XFrF9fWqmyKm+6tDKy0xiFO9blBZd1QWBdSFg3n5cZ3uENyNvfirz9rcmhIOMZAgAS54iDCnTnpBH68aMLdcnDRXpwymh6vQMA0AoR/AHAbggHA+qck67Oe+FYtbVOZdVRba2IqKTC/66M+PP+pzJaP7+1IqIvN5bVb18RqdnlOTLDwfoQMF4wmJvhhYcdsrxg0fuk1U/zIhQAwK4cN3g/3XLmMF39f+/ryr+/p7t/MJIbTwAAtDIEfwCwjwUC5odxYalj8/evjtaqtDKyw9uPS/zv2GWllVGVVnnfJZVRrS6uqF9XGdl5bMNYmeGgOmSGlZ+1/THkuk9+Zrg+MMzz5ztmpSk/y/tNQR5TBoB248xRPVVSEdGvn/tY0576ULecMZThKgAAaEUI/gCgjUkL+b0Pc9JbfIxITa1K/V6FWysiKi6v3qGHYXF5pH7d1oqIVm4u10f+dHl14z0OzRQTDqapY5Y3ne8Hg/mZYXXMTvNDxbr1aYxrCABt2AVH9tPWioj+9PJnyssI64aTDpEZ/5sOAEBrQPAHAO1QOBhQp+w0dcpu/psYq6O19Y8mF5d7YeGW8moVl0dU7IeIddOby6r1xYYyFZdXq6Qy2uRx00IBpYcCSg8F/e+Atyy8fb5ufVrsfDiotKA3nZsRUkf/d9V9OmalKSPMuFMAkEg/Oba/tlZE9OCbXyonI6SrvjMg2SUBAAAR/AEAmiktFFBBTroKmtnjMFpTq5LKqIrLq7WlPKKtFV5AuMUPD6uitaqK1njfEW+6Olpbv3xbVVSby7bPe9vUqjpaq8pojVwTL0zJTgvWB4Ids9LUOTtth4CwY9b26Q6ZYYUCpkDAFAyYgmYyU/00PRMBYGdmpl+eNEjbqqK68+XPlJ0W1I/GH5jssgAAaPcI/gAA+0RoD3oZ7opzTpEap9JKr/fh5rKINpdVaXNZ3fz2z5byai1fv01byqubfGy5KcGAKWBSwGyHQDBgdetMOekxvQ+z6oLG8A4hYyc/gMxND/FYHIA2LxAw/f6MoaqI1Oi3LyxVVlpQ53+rb7LLAgCgXSP4AwC0eWamtJA1e+zDykiNtpRXa9O26vqAsKQiomitU02tU61zqnXypmudalzMt/Pe0FwTs7zWqX66tCqqLWXVWrm5XB+sKtbmsmpFauJ3SwwFzAsGs2IDQW/8w8y0oDLCQWWEA8oMb5/OqJsOBf1ttq9PDwUIEgEkRTBg+uNZw1VZXaMb/rlEmWkhnTmqZ7LLAgCg3SL4AwC0WxnhoLp3yFT3DpkJP5dzTmXVNdpSVq1NZdXaEtMDMfZ7c1m1ln5Toi3l3niJtU08wtyU+nAw1CAobGR5ejjgL4tdvn1ZeiigYMAUCno9GkOBgAIBKRQIKBiQgoGAgmYKBr0ekMGYR6Vjl4WDRigJpLi0UEB3nztSF/5tga594n1lpQV1wpDuyS4LAIB2ieAPAIB9wPzHf3PSQ+rVKWu39nHOqbqmVpWRWlVGalQZqVFFpKZ+viJSo6o4y3bYvrpGldHt81WRWm0uq/bnty+v9MdLTDQzKTMc9D5pjXw3XNZgeYb/QpdwMKBw0BQOBXacD3ovhgkFdlwXZHxGYJ/JCAd13+RCTX7gXV359/eUEQ7omIO7JbssAADaHYI/AABaKTPz33IcVIfMcMLPV1vrVFUXEka9YLCq7jtSU/9Yc9R/9HmHb+cUrfHW19TG+fjL64LKikiNyqu3h5Plfm/INQ2XR5p+cUtzBMx7o3VaMKBwKKCJhT11/fGH7J2DA9hJVlpID04drR/c944ufWSRZk4ZrcMPKkh2WQAAtCsEfwAAQJI3MH9dD7vWwjkvjKyo3h4YVlTXKFJTq2itUyRaq+qaWkVqnCI1tYrUeD0Xd5ivqVUk6hSt3T4dqanVoO55yf55QMrLywjroQvG6pzpb+uih4r08IVjNKpPp2SXBQBAu0HwBwAAWi0zqx+HsGOyiwHQIp2y0/TIhWN11l/f1pQZC/T3iw/T4B4dkl0WAADtQiDZBQAAAABIbV3zMvToxYcpLyOs8x+Yr0/XlSa7JAAA2gWCPwAAAAAJ1yM/U49eNFahYEDn3T9fKzaWJbskAABSHsEfAAAAgH2ib0G2Hr1orCI1tTr3/vlaXVyR7JIAAEhpBH8AAAAA9pkB3XL18IVjVVIZ0Xn3z9f60spklwQAQMoi+AMAAACwTw3u0UEzp47WupJKnXf/fG0pq052SQAApCSCPwAAAAD73Kg+nXT/5EKt2FSuyQ++q5LKSLJLAgAg5RD8AQAAAEiKww8q0L3njdQna0t0wYwFKq+OJrskAABSCsEfAAAAgKQ55uBu+tM5I7To6y265KGFqozUJLskAABSBsEfAAAAgKQ6cWh33XLmML2xfKMuf2yRIjW1yS4JAICUQPAHAAAAIOnOHNVTvzl1sOZ8sl4/eXyxooR/AADssVCyCwAAAAAASTr/sD6qqI7qf59fqvRgQLdNHKZAwJJdFgAAbVZCe/yZ2XFmtszMlpvZtDjrzzWzD/zPW2Y2LJH1AAAAAGjdLhl3oH76nQF66r3V+tnsD1Vb65JdEgAAbVbCevyZWVDS3ZK+I2mVpAVm9oxz7uOYzb6UNN45t8XMjpc0XdLYRNUEAAAAoPW74tv9VRWt1V2vLldaKKBfnXyozOj5BwBAcyXyUd8xkpY7576QJDObJekUSfXBn3PurZjt35HUM4H1AAAAAGgjfvrdAaquqdX0179QWjCgn594COEfAADNlMjgr4eklTHzq9R0b74LJb0Qb4WZXSLpEknq3bv33qoPAAAA2AHtztbDzHT98QerKlKj+9/4UhnhoK7+3sBklwUAQJuSyOAv3u24uAN0mNnR8oK/I+Otd85Nl/cYsAoLCxnkAwAAAAlBu7N1MTPd+P1DVV3jPfabHgroim/3T3ZZAAC0GYkM/lZJ6hUz31PSmoYbmdlQSfdLOt45tymB9QAAAABoYwIB082nDlFVtFZ/+M+nSgsF9KPxBya7LAAA2oREBn8LJPU3s36SVks6R9IPYjcws96SnpJ0vnPu0wTWAgAAAKCNCgRMt545TJEap9++sFRpoYCmHtEv2WUBANDqJSz4c85FzexySS9JCkp60Dm3xMwu9dffK+mXkjpLuscfqDfqnCtMVE0AAAAA2qZgwHT7WcNUHa3Rr579WGmhgM4d2yfZZQEA0KolssefnHPPS3q+wbJ7Y6YvknRRImsAAAAAkBrCwYD+PGmkLn1koX4++yOlh4I6c1TPZJcFAECrFUh2AQAAAACwu9JCAd1z7kgd1b9A1z7xvv65eHWySwIAoNUi+AMAAADQpmSEg5p+fqFG9+2kq/7xvl74cG2ySwIAoFUi+AMAAADQ5mSmBfXglNEa3itfV/z9Pc35eF2ySwIAoNUh+AMAAADQJmWnhzRj6mgdun+efvzoIr326YZklwQAQKtC8AcAAACgzcrLCOuhC8bqoK45uuShIr31+cZklwQAQKtB8AcAAACgTeuQFdbDF45Rn85ZunBmkRas2JzskgAAaBUI/gAAAAC0eZ1z0vXIRWPVvUOGps5YoMUri5NdEgAASUfwBwAAACAldM3N0GMXH6ZO2Wma/MB8LfyKnn8AgPaN4A8AAABAytivQ4Yeu3isOmWn6Zzp7+ix+V8nuyQAAJKG4A8AAABASunZMUv//K8jdfiBBfrZ7A/1s9kfqjpam+yyAADY5wj+AAAAAKScDllhPThltC6bcKAem/+1Jt33jtaXVCa7LAAA9imCPwAAAAApKRgwXXfcwbr7ByP18ZoSff+uN7To6y3JLgsAgH2G4A8AAABASjtxaHc99ePDlR4K6py/vqPHFzDuHwCgfSD4AwAAAJDyDumep2cuP0JjD+ik6578UDc8/RHj/gEAUh7BHwAAAIB2IT8rTTOnjtGPxh+gh9/5Sufe/442lFYluywAABKG4A8AAABAuxEMmK4//hDdOWmEPly9Vd//8xt6f2VxsssCACAhCP4AAAAAtDsnD9tfT112hEJB08S/vq3/K1qZ7JIAANjrCP4AAAAAtEuD9s/Ts5cfqdF9O+qaJz7QTc8sUaSGcf8AAKmD4A8AAABAu9UxO01/mzpGFx/VTzPfWqHz7p+vjdsY9w8AkBoI/gAAAAC0a6FgQD8/cZD+dM5wvb+qWCf/+Q19uGprsssCAGCPEfwBAAAAgKRThvfQE5ceLjPTGfe+pScXrkp2SQAA7BGCPwAAAADwDe7RQc9ecaRG9e6on/7f+7r+qQ+1rqQy2WUBANAiBH8AAAAAEKNTdpoevtAb9+8fRSt11C2v6oanP9Lq4opklwYAQLMQ/AEAAABAA3Xj/r360wk6Y2QPzVrwtSbc+qqmPfmBvt5UnuzyAADYLQR/AAAAANCI3p2z9NvTh2ruNUdr0pjeeuq91Tr6D3N11T8W6/MN25JdHgAATSL4AwAAAIBd6JGfqV+fMlhvXHu0ph7eVy98+I2Ovf01Xf7YIi39piTZ5QEAEBfBHwAAAADspq55GfrFSYP0xnVH69LxB+rVpet13B3zdMlDRfpo9dZklwcAwA5CyS4AAAAAANqazjnpuu64g/WjcQfowTdXaMabX+rfH6/T0QO76Ipv99fI3h2TXSIAAPT4AwAAAICWys9K01XfGaA3px2ja743UItXFuv0e97SeffP1/wvNiW7PABAO5fQ4M/MjjOzZWa23MymxVl/sJm9bWZVZnZ1ImsBAAAAgETJywjrv44+SG9cd4x+dsLBWvpNqc6e/o7Ouvdtzftsg5xzyS4RANAOJexRXzMLSrpb0nckrZK0wMyecc59HLPZZklXSjo1UXUAAAAAwL6SnR7SJeMO1ORv9dXf3/1af33tC53/wLs6qGuOzhndS6eP7KlO2WnJLhMA0E4kssffGEnLnXNfOOeqJc2SdErsBs659c65BZIiCawDAAAAAPapjHBQU4/op9eunaBbzhiqnPSQ/udfn+iw/31Zlz+2SG8u36jaWnoBAgASK5Ev9+ghaWXM/CpJY1tyIDO7RNIlktS7d+89rwwAAACIg3Yn9rb0UFBnje6ls0b30tJvSjTr3ZV6atEqPffBWvXpnKWzCntp4qie6pqXkexSAQApKJE9/izOshbd0nLOTXfOFTrnCrt06bKHZQEAAADx0e5EIh28X55uOvlQvfvzY/XHs4dpv7wM3frSMn3rd6/okoeK9OrS9aqhFyAAYC9KZI+/VZJ6xcz3lLQmgecDAAAAgFYvIxzUaSN66rQRPfXFhm16fMFKPbFwlf798Trt3yFDEwu9HoI98jOTXSoAoI1LZI+/BZL6m1k/M0uTdI6kZxJ4PgAAAABoUw7okqPrTzhEb1//bd1z7kgd2DVHd77ymY78/SuaMuNdvfjRWkVqapNdJgCgjUpYjz/nXNTMLpf0kqSgpAedc0vM7FJ//b1mtp+kIkl5kmrN7CeSBjnnShJVFwAAAAC0NmmhgE4Y0l0nDOmulZvL9Y+ilfpH0Upd+sgiFeSk68xRPXXqiP01oGuuAoF4oyoBALAzc65tjSFRWFjoioqKkl0GAADALpnZQudcYbLrQMvQ7kSyRWtqNXfZBs1asFKvLvPG/+uQGdbI3vka1aejRvXppGG9OigrLZEjOAEA2oLG2p38FwIAAAAAWqFQMKBjB3XTsYO6aV1JpV7/dIMWfb1FRSu26NVlGyRJwYDp0P3zNLJ3RxX27ahRfTqqewfGBgQAeAj+AAAAAKCV65bnvfRjYqH3/sTi8mq993Wxir7arIVfbdGsBV9r5lsrJEk98jM1sk9HFfbxgsCD98tVKJjI4d0BAK0VwR8AAAAAtDH5WWk6+uCuOvrgrpKkSE2tPllbooVfbVHRV1u04MvNevb9NZKkrLSghvfKV2Gfjhrph4G5GeFklg8A2EcI/gAAAACgjQsHAxraM19De+Zr6hH9JEmriyu08KstWrhisxZ+vUV3vbpctU76w8RhOmNUzyRXDADYFwj+AAAAACAF9cjPVI/8TJ08bH9JUllVVO+vLNbA/XKTXBkAYF8h+AMAAACAdiA7PaTDDypIdhkAgH2IEV4BAAAAAACAFETwBwAAAAAAAKQggj8AAAAAAAAgBRH8AQAAAAAAACmI4A8AAAAAAABIQQR/AAAAAAAAQAoi+AMAAAAAAABSEMEfAAAAAAAAkIII/gAAAAAAAIAURPAHAAAAAAAApCCCPwAAAAAAACAFmXMu2TU0i5ltkPTVPjhVgaSN++A87RHXNnG4tonF9U0crm1icX0TZ1fXto9zrsu+KgZ71z5qd/LvZ2JxfROHa5tYXN/E4domDtc2sVrU7mxzwd++YmZFzrnCZNeRiri2icO1TSyub+JwbROL65s4XFvsKf4ZSiyub+JwbROL65s4XNvE4domVkuvL4/6AgAAAAAAACmI4A8AAAAAAABIQQR/jZue7AJSGNc2cbi2icX1TRyubWJxfROHa4s9xT9DicX1TRyubWJxfROHa5s4XNvEatH1ZYw/AG2emdVI+jBm0Szn3O/20rH7SnrOOTd4bxwPAAAAbRftTgBtTSjZBQDAXlDhnBue7CIAAACQ8mh3AmhTeNQXQMoysxVm9nsze9f/HOQv72NmL5vZB/53b395NzObbWbv+5/D/UMFzew+M1tiZv82s0x/+yvN7GP/OLOS9DMBAACQZLQ7AbRWBH8AUkGmmS2O+Zwds67EOTdG0l2S7vCX3SXpIefcUEmPSrrTX36npNecc8MkjZS0xF/eX9LdzrlDJRVLOsNfPk3SCP84lybqxwEAAKDVoN0JoE1hjD8AbZ6ZbXPO5cRZvkLSMc65L8wsLOkb51xnM9soqbtzLuIvX+ucKzCzDZJ6OueqYo7RV9J/nHP9/fnrJIWdc/9jZi9K2ibpaUlPO+e2JfinAgAAIIlodwJoa+jxByDVuUamG9smnqqY6RptHx/1REl3SxolaaGZMW4qAABA+0W7E0CrQ/AHINWdHfP9tj/9lqRz/OlzJb3hT78s6TJJMrOgmeU1dlAzC0jq5Zx7VdK1kvIl7XT3FwAAAO0G7U4ArQ53CQCkgkwzWxwz/6Jzbpo/nW5m8+Xd6JjkL7tS0oNmdo2kDZKm+sv/W9J0M7tQ3h3WyyStbeScQUmPmFkHSSbpj8654r32iwAAANAa0e4E0KYwxh+AlOWPtVLonNuY7FoAAACQumh3AmiteNQXAAAAAAAASEH0+AMAAAAAAABSED3+AAAAAAAAgBRE8AcAAAAAAACkIII/AAAAAAAAIAUR/AEAAAAAAAApiOAPAAAAAAAASEEEfwAAAAAAAEAKIvgDAAAAAAAAUhDBHwAAAAAAAJCCCP4AAAAAAACAFETwBwAAAAAAAKQggj8AAAAAAAAgBRH8AQAAAAAAACmI4A8AAAAAAABIQQR/AAAAAAAAQAoi+AMAAAAAAABSEMEfAAAAAAAAkIII/gAAAAAAAIAURPAHAAAAAAAApCCCPwAAAAAAACAFEfwBAAAAAAAAKYjgDwAAAAAAAEhBBH8AAAAAAABACiL4AwAAAAAAAFIQwR8AAAAAAACQggj+AAAAAAAAgBRE8AcAAAAAAACkIII/AAAAAAAAIAUR/AEAAAAAAAApiOAPaOPMbKaZ/c9ubuvM7KAWnmeFmR3bkn1bCzObYmZvxMxvM7MDkllTLDMbZGZFMfPvmtmhyawJAAAAANB2EfwBrZyZnWNm882szMzW+9M/NjNLYk03+SHilQ2W/8RfftNeOMdMM6v2w7nNZvYfMzt4T48byzmX45z7Yk+PY2bdzewZM1vj//6+DdbPNbNKMys1sxIzW2hm08wsvcGhfiPptpj52yT9uonz/tPM3ojz2c//G8Vbd7yZndLIup/FOcfYRrb9s5mlNbLuDX/fvzayfkRLrzUAAMDeZGY/MLMiv8251sxeMLMjY9q7E2O2DcW29fz2qjOzMTHbHGRmronz7XAjusG6Q83s32a2xcyK/TbjCWZ2rl/fNjOrMLPamPlt/r4r/LZzQYNjLo7XPgXQfhD8Aa2Ymf1U0p8k3SppP0ndJF0q6QhJaUksTZI+lfTDBssm+8v3llucczmSekpaL2nmXjz23lQr6UVJZzSxzeXOuVxJ3SX9VNI5kp6vC3DNrLukoyU9HbPPM5KO9tfFE3HOHRn7kfSOpAxJB0ua0GDd7+T9M9Rd0k0N1h0naUCcc3SUNDPOebrL+2/IijjrvvH37Rxn3SxJHZq4TgAAAPuEmV0l6Q5J/yuvjdRb0j2STvE32Szp12YWbOIwmyXt1tM3u+FZSf/xa+kq6UpJJc65R/0b1jmSjpe0pm7eX1bnS0mT6mbMbIikzL1UG4A2iuAPaKXMrIO83l4/ds494ZwrdZ73nHPnOueqGtnvYjNb7veSe8bM9m+wyQlm9oWZbTSzW80s4O93oJm9Ymab/HWPmll+EyUukJRl/qOo/nemv7yulo5m9pyZbfDvXD5nZj39dZ3MbJWZfd+fz/HrntzwRM65ckmPSRrsb3uI34uu2MyWmNnJsdfNzB7yz/mVmf2i7jfGuVb1jz77d2zvNrN/mdczb76ZHRiz7XfNbJmZbTWze8zsNTO7yK9vnXPuntjf3hjnXJlzbq6kkyV9S9KJ/qrvSFrknKuM2bZS0kJJ393VcQEAALD7Ytra/+Wce8pvo0Wcc886567xN3tRUrWk85o41N8kDTWz8XtYT4GkfpLuc85V+583nXNxewc24mF5N+Lr/FDSQ3tSF4C2j+APaL2+JSld0j93dwczO0bSbyWdJa9H1lfyeljFOk1SoaSR8u5mXlC3u7/v/pIOkdRL0k27OGVs4yJewyIgaYakPvLuoFZIukuSnHOb/XPfZ2ZdJf1R0mLn3E6NEzPLkXSupPfMLCzvbui/5d0JvULSo2Y20N/8z/J6lB0gabxf39Rd/I46kyT9Sl4vt+WSbvbPXyDpCUnXS+osaZmkw3fzmHE5576WVCTpKH/REP+4DX0iadienAsAAAA7+Za8pyRmN7GNk3SDpBv9Nmg85fJ6DN68h/Vsktf+fMTMTjWzbi04xjuS8vyb5EFJZ0t6ZA/rAtDGEfwBrVeBpI3OuWjdAjN7y+/lVmFm4+Lsc66kB51zi/wegddL+laDMT1+75zb7AdPd8h/HMA5t9w59x/nXJVzboOk2+UFZ015RNIkvyF0jho0LJxzm5xzTzrnyp1zpfIaRONj1v9b0v9Jellez7cfNTj+1WZWLK8RlCNpiqTD/Onf+XdCX5H0nF9HXQPner+bjrOzAAAgAElEQVSH5ApJf5B0/i5+R52nnHPv+tf8UUnD/eUnSFri3w2OSrpT2x9n3RNrJHXyp/MllcbZptRfBwAAgL2nsxq0teNxzj0jaYOki5rY7K+SepvZ8S0txjnn5A37skJe+3Wtmb1uZv2beai6G/PfkbRU0uqW1gQgNRD8Aa3XJkkFZhaqW+CcO9w5l++vi/fv7/7yevnVbb/N37ZHzDYrY6a/8veRmXU1s1lmttrMSuSFeDsMDtyQHx4ul3eX8zPnXOyxZWZZ5r3g4Sv/mK9Lym8wTsp0eY/wznDObWpwitucc/nOuf2ccyc75z73613pnKtt8Dt6+PWmxV6DmHW7IzbMK5cXMKrunDG/20latZvHbEoPeePCSNIWSblxtsmVVLwXzgUAAIDtdmprN+EXkn4ur4fgTvwb7r/xP/Uv4DOzo2JewrFkVydxzq1yzl3unDtQ3hMzZWr+o7oPS/qBvBvmPOYLgOAPaMXellSl7YML74418hoJkiQzy5Z3NzP2Tl+vmOne/j6S95ivkzTUOZcnbyyT3Xlz8EPyXlYRr2HxU0kDJY31j1nXS7HuhRZBeXdIH5J0Wd14e7uwRlKvBuP29Zb3GzdKiijmGsSs2xNr5b1gRH7dFjvfEmbWS9IoSfP8RR8o/ss1DpH0/p6cCwAAADt5W1KlpFN3taFz7j/ybnb/uInNZsgbbua0mP3mxbyE49DmFOffUL9b/hjXzdjvK3kv+ThB0lPN2RdAaiL4A1op51yxvPHm7jGzM/2XXwTMbLik7EZ2e0zSVDMbbmbp8nrizfcfea1zjf/SjV6S/lvS4/7yXEnbJBWbWQ9J12j3PC7v5RP/iLMuV964fsVm1knSjQ3W/8z/vkDSbZIe2sVb0yRpvry7n9eaWdjMJkj6vqRZzrkav46bzSzXzPpIukp7PrbJvyQN8cdbCUn6L3lvWa5nZhnyxmSUpHR/fid+L8jx8sZufFfS8/6q/0gaGbuf/zcc5a8DAADAXuKc2yrpl5Lu9tt4WX7b8ngzuyXOLj+XdG0Tx4vKGx/7ut04vZlZRoNPRzP7lZkd5Lf5C+S1kd9p/q/ThZKOcc6VtWBfACmG4A9oxZxzt8gLrq6VtF7SOnk95K6T9Fac7V+WNwDxk/J6qR0ob+y9WP+U96bYxfICrQf85b+S98KPrf7y3bpD6JyrcM7Ncc5VxFl9h7w3/W6U12h5sW6FmY3yf9tkP7D7vbweh9N2cb5qeW/EPd4/7j3+MZb6m1whLxj8QtIb8sLQB3fntzRxzo2SJkq6Rd5jIYPkvZgj9s3KFfKCU8kbT6Xh9bjLzErl/Q3vkPc3Oq7ukWXn3DpJr2jHHp4nS5rrnFsjAAAA7FXOudvltUd/IW8cv5WSLpf0dJxt35R307Ypf5fXBt+Vw+W1FWM/tZL6SpojqUTSR/LamlN243gNa/3cOVfU3P0ApCbzhqoCAOwu/zHjVZLOdc69uhePO0jS3ySNcc45M5sv6ULn3EeNbP+Ec+7MBstuk/fm5N9JOq/By2FOkjcOYoak5c65OTHrciTd5Zyb0uB4x0nq6Zy7v+G55T0Ofr9z7rx4dTVS3+WSPnLOzd31FQEAAAAA7IndGcgUANo9M/uevMeMK+Q9Bm1q2aMXjXLOfSxpdMz82F3sMsTM5jZYdqC84E+SXjaz2Ls7neW9JU6S/mBmW2LWBSV93sh5rjGz8xosi/jf34lTQ90YNl3irOsh6eJGzgMAAAAA2Ivo8QcAu8HMbpL3GHGapI8lXemcm5/UogAAAAAAaALBHwAAAAAAAJCCeLkHAAAAAAAAkILa3Bh/BQUFrm/fvskuAwAAYJcWLly40TnXJdl1oGVodwIAgLaisXZnmwv++vbtq6Ii3kwOAABaPzP7Ktk1oOVodwIAgLaisXZnQh/1NbPjzGyZmS03s2lx1ncws2fN7H0zW2JmUxNZDwAAAAAAANBeJCz4M7OgpLslHS9pkKRJZjaowWb/Jelj59wwSRMk/cHM0hJVEwAAAAAAANBeJLLH3xhJy51zXzjnqiXNknRKg22cpFwzM0k5kjZLiiawJgAAAAAAAKBdSOQYfz0krYyZXyVpbINt7pL0jKQ1knIlne2cq214IDO7RNIlktS7d++EFAsAQGsTiUS0atUqVVZWJrsU7EJGRoZ69uypcDic7FKwh2h3AgDaI9qdbUdz252JDP4szjLXYP57khZLOkbSgZL+Y2bznHMlO+zk3HRJ0yWpsLCw4TEAAEhJq1atUm5urvr27SuvczxaI+ecNm3apFWrVqlfv37JLgd7iHYnAKA9ot3ZNrSk3ZnIR31XSeoVM99TXs++WFMlPeU8yyV9KengBNYEAECbUVlZqc6dO9P4auXMTJ07d+YOOQAAaLNod7YNLWl3JjL4WyCpv5n181/YcY68x3pjfS3p25JkZt0kDZT0RQJrAgCgTaHx1TbwdwIAAG0d7Zm2obl/p4Q96uuci5rZ5ZJekhSU9KBzbomZXeqvv1fSbyTNNLMP5T0afJ1zbmOiagIAAAAAAADai0T2+JNz7nnn3ADn3IHOuZv9Zff6oZ+cc2ucc991zg1xzg12zj2SyHoAAMDu27Rpk4YPH67hw4drv/32U48ePernq6urm9y3qKhIV155ZbPO17dvX23cyP0/AACA9oZ2Z+Ik8uUeAACgDevcubMWL14sSbrpppuUk5Ojq6++un59NBpVKBS/KVFYWKjCwsJ9UicAAADaNtqdiZPQHn8AACC1TJkyRVdddZWOPvpoXXfddXr33Xd1+OGHa8SIETr88MO1bNkySdLcuXN10kknSfIabxdccIEmTJigAw44QHfeeecuz3P77bdr8ODBGjx4sO644w5JUllZmU488UQNGzZMgwcP1uOPPy5JmjZtmgYNGqShQ4fu0EAEAABA20W7c++gxx8AAG3Ar55doo/XlOzVYw7aP083fv/QZu/36aefas6cOQoGgyopKdHrr7+uUCikOXPm6Gc/+5mefPLJnfZZunSpXn31VZWWlmrgwIG67LLLFA6H4x5/4cKFmjFjhubPny/nnMaOHavx48friy++0P77769//etfkqStW7dq8+bNmj17tpYuXSozU3FxcbN/DwAAALaj3Zla7U56/AEAgGaZOHGigsGgJK8RNHHiRA0ePFj/7//9Py1ZsiTuPieeeKLS09NVUFCgrl27at26dY0e/4033tBpp52m7Oxs5eTk6PTTT9e8efM0ZMgQzZkzR9ddd53mzZunDh06KC8vTxkZGbrooov01FNPKSsrKyG/GQAAAPse7c49R48/AADagJbcIU2U7Ozs+ukbbrhBRx99tGbPnq0VK1ZowoQJcfdJT0+vnw4Gg4pGo40e3zkXd/mAAQO0cOFCPf/887r++uv13e9+V7/85S/17rvv6uWXX9asWbN011136ZVXXmnZDwMAAADtTqVWu5MefwAAoMW2bt2qHj16SJJmzpy5V445btw4Pf300yovL1dZWZlmz56to446SmvWrFFWVpbOO+88XX311Vq0aJG2bdumrVu36oQTTtAdd9xRPyg0AAAAUgvtzpahxx8AAGixa6+9Vj/84Q91++2365hjjtkrxxw5cqSmTJmiMWPGSJIuuugijRgxQi+99JKuueYaBQIBhcNh/eUvf1FpaalOOeUUVVZWyjmnP/7xj3ulBgAAALQutDtbxhrr1thaFRYWuqKiomSXAQBAwn3yySc65JBDkl0GdlO8v5eZLXTOFSapJOwh2p0AgPaCdmfb0px2J4/6AgAAAAAAACmI4A8AAAAAAABIQQR/AAAAAAAAQAoi+AMAAAAAAABSEMEfAAAAAAAAkIII/gAAAAAAAIAURPAHAADimjBhgl566aUdlt1xxx368Y9/3OQ+RUVFkqQTTjhBxcXFO21z00036bbbbmvy3E8//bQ+/vjj+vlf/vKXmjNnTnPKj2vu3Lk66aST9vg4AAAA2HtodyYOwR8AAIhr0qRJmjVr1g7LZs2apUmTJu3W/s8//7zy8/NbdO6GDbBf//rXOvbYY1t0LAAAALRutDsTh+APAADEdeaZZ+q5555TVVWVJGnFihVas2aNjjzySF122WUqLCzUoYceqhtvvDHu/n379tXGjRslSTfffLMGDhyoY489VsuWLavf5r777tPo0aM1bNgwnXHGGSovL9dbb72lZ555Rtdcc42GDx+uzz//XFOmTNETTzwhSXr55Zc1YsQIDRkyRBdccEF9fX379tWNN96okSNHasiQIVq6dGmTv2/z5s069dRTNXToUB122GH64IMPJEmvvfaahg8fruHDh2vEiBEqLS3V2rVrNW7cOA0fPlyDBw/WvHnz9uziAgAAoB7tzsS1O0N7tDcAANg3XpgmffPh3j3mfkOk43/X6OrOnTtrzJgxevHFF3XKKado1qxZOvvss2Vmuvnmm9WpUyfV1NTo29/+tj744AMNHTo07nEWLlyoWbNm6b333lM0GtXIkSM1atQoSdLpp5+uiy++WJL0i1/8Qg888ICuuOIKnXzyyTrppJN05pln7nCsyspKTZkyRS+//LIGDBigyZMn6y9/+Yt+8pOfSJIKCgq0aNEi3XPPPbrtttt0//33N/r7brzxRo0YMUJPP/20XnnlFU2ePFmLFy/WbbfdprvvvltHHHGEtm3bpoyMDE2fPl3f+9739POf/1w1NTUqLy9v1qUGAABoM2h3Skqddic9/gAAQKNiH7uIfdziH//4h0aOHKkRI0ZoyZIlOzwe0dC8efN02mmnKSsrS3l5eTr55JPr13300Uc66qijNGTIED366KNasmRJk/UsW7ZM/fr104ABAyRJP/zhD/X666/Xrz/99NMlSaNGjdKKFSuaPNYbb7yh888/X5J0zDHHaNOmTdq6dauOOOIIXXXVVbrzzjtVXFysUCik0aNHa8aMGbrpppv04YcfKjc3t8ljAwAAoHlodyam3UmPPwAA2oIm7pAm0qmnnqqrrrpKixYtUkVFhUaOHKkvv/xSt912mxYsWKCOHTtqypQpqqysbPI4ZhZ3+ZQpU/T0009r2LBhmjlzpubOndvkcZxzTa5PT0+XJAWDQUWj0WYfy8w0bdo0nXjiiXr++ed12GGHac6cORo3bpxef/11/etf/9L555+va665RpMnT27y+AAAAG0S7U5JqdPupMcfAABoVE5OjiZMmKALLrig/q5rSUmJsrOz1aFDB61bt04vvPBCk8cYN26cZs+erYqKCpWWlurZZ5+tX1daWqru3bsrEono0UcfrV+em5ur0tLSnY518MEHa8WKFVq+fLkk6eGHH9b48eNb9NvGjRtXf865c+eqoKBAeXl5+vzzzzVkyBBdd911Kiws1NKlS/XVV1+pa9euuvjii3XhhRdq0aJFLTonAAAA4qPdmZh2Jz3+AABAkyZNmqTTTz+9/tGLYcOGacSIETr00EN1wAEH6Igjjmhy/5EjR+rss8/W8OHD1adPHx111FH1637zm99o7Nix6tOnj4YMGVLf6DrnnHN08cUX684776wfXFmSMjIyNGPGDE2cOFHRaFSjR4/WpZde2qLfddNNN2nq1KkaOnSosrKy9Le//U2SdMcdd+jVV19VMBjUoEGDdPzxx2vWrFm69dZbFQ6HlZOTo4ceeqhF5wQAAEDjaHfu/Xan7arrYmtTWFjoioqKkl0GAAAJ98knn+iQQw5JdhnYTfH+Xma20DlXmKSSsIdodwIA2gvanW1Lc9qdPOoLAAAAAAAApCCCPwAAAAAAACAFEfwBANCKtbUhOdor/k4AAKCtoz3TNjT370TwBwBAK5WRkaFNmzbRCGvlnHPatGmTMjIykl0KAABAi9DubBta0u7krb4AALRSPXv21KpVq7Rhw4Zkl4JdyMjIUM+ePZNdBgAAQIvQ7mw7mtvuJPgDAKCVCofD6tevX7LLAAAAQIqj3Zm6Evqor5kdZ2bLzGy5mU2Ls/4aM1vsfz4ysxoz65TImgAAAAAAAID2IGHBn5kFJd0t6XhJgyRNMrNBsds45251zg13zg2XdL2k15xzmxNVEwAAAAAAANBeJLLH3xhJy51zXzjnqiXNknRKE9tPkvT3BNYDAAAAAAAAtBuJDP56SFoZM7/KX7YTM8uSdJykJxNYDwAAAAAAANBuJDL4szjLGnsv9PclvdnYY75mdomZFZlZEW+YAQAAQKLQ7gQAAKkkkcHfKkm9YuZ7SlrTyLbnqInHfJ1z051zhc65wi5duuzFEgEAAIDtaHcCAIBUksjgb4Gk/mbWz8zS5IV7zzTcyMw6SBov6Z8JrAUAAAAAAABoV0KJOrBzLmpml0t6SVJQ0oPOuSVmdqm//l5/09Mk/ds5V5aoWgAAAAAAAID2JmHBnyQ5556X9HyDZfc2mJ8paWYi6wAAAAAAAADam0Q+6gsAAAAAAAAgSQj+AAAAAAAAgBRE8AcAAAAAAACkIII/AAAAAAAAIAUR/AEAAAAAAAApiOAPAAAAAAAASEEEfwAAAAAAAEAKIvgDAAAAAAAAUhDBHwAAAAAAAJCCCP4AAAAAAACAFETwBwAAAAAAAKQggj8AAAAAAAAgBRH8AQAAAAAAACmI4A8AAAAAAABIQQR/AAAAAAAAQAoi+AMAAAAAAABSEMEfAAAAAAAAkIII/gAAAAAAAIAURPAHAAAAAAAApCCCPwAAAAAAACAFEfw1UFIZ0dPvrdambVXJLgUAAAAAAABoMYK/Br7eVK6fPL5Yry7bkOxSAAAAAAAAgBYj+GtgUPc8FeSk67VPCf4AAAAAAADQdhH8NRAImMYNKNC8zzaoptYluxwAAAAAAACgRQj+4pgwsKuKyyNavLI42aUAAAAAAAAALULwF8dRBxUoYOJxXwAAAAAAALRZBH9xdMxO07Be+Xpt2fpklwIAAAAAAAC0CMFfIyYM6KoPVm/Vpm1VyS4FAAAAAAAAaDaCv0ZMGNhFzknzPtuY7FIAAAAAAACAZiP4a8SQHh3UKTtNc3ncFwAAAAAAAG1QQoM/MzvOzJaZ2XIzm9bINhPMbLGZLTGz1xJZT3MEAqZx/Qv0+mcbVVvrkl0OAAAAAAAA0CwJC/7MLCjpbknHSxokaZKZDWqwTb6keySd7Jw7VNLERNXTEhMGdtXmsmp9uHprsksBAAAAAAAAmiWRPf7GSFrunPvCOVctaZakUxps8wNJTznnvpYk51yreq72qP4FMpPmLtuQ7FIAAAAAAACAZklk8NdD0sqY+VX+slgDJHU0s7lmttDMJsc7kJldYmZFZla0YcO+C+E656RraI8Oeu3TVpVHAgAAIEGS1e4EAABIhEQGfxZnWcPB8kKSRkk6UdL3JN1gZgN22sm56c65QudcYZcuXfZ+pU0YP7CrFq8sVnF59T49LwAAAPa9ZLY7AQAA9rZEBn+rJPWKme8paU2cbV50zpU55zZKel3SsATW1GzjB3RRrZNe/2xjsksBAAAAAAAAdlsig78FkvqbWT8zS5N0jqRnGmzzT0lHmVnIzLIkjZX0SQJrarbhvfKVnxXWa4zzBwAAAAAAgDYklKgDO+eiZna5pJckBSU96JxbYmaX+uvvdc59YmYvSvpAUq2k+51zHyWqppYIBkxH9e+i1z7doNpap0Ag3hPMAAAAAAAAQOuSsOBPkpxzz0t6vsGyexvM3yrp1kTWsafGD+iiZ99fo4/Xlmhwjw7JLgcAAAAAAADYpUQ+6psyxg/wBnZ+7VMe9wUAAAAAAEDbQPC3G7rkpmtwjzzNXbY+2aUAAAAAAAAAu4XgbzeNH9BFi74u1taKSLJLAQAAAAAAAHaJ4G83TRjYVTW1Tm8u35jsUgAAAAAAAIBdIvjbTSN65Ss3I8TjvgAAAAD+P3v3HadXWef//3XNPX0mmZSZ9IT0QIAkwJAACSkIUgRBbKBfxIrs6opr13WLuvtTsCO4ioqCuouuCvZOEgg1AUIJENIr6X16uX5/nDvJJCQhZe7cc995PR+P8zjnPufMuT8cb2euvO/ruo4kSTnB4O8wFaYKOH9UNbNf2kiMMdvlSJIkSZIkSYdk8HcEpo/uw/odTby4bme2S5EkSZIkSZIOyeDvCEwdXQPArIUbs1yJJEmSJEmSdGgGf0egX1UpJ/frxuyXnOdPkiRJkiRJXZvB3xGaPqYP85ZvZWdjS7ZLkSRJkiRJkg7K4O8ITRtdQ2t75OElm7NdiiRJkiRJknRQBn9HqHZoTypLCp3nT5IkSZIkSV2awd8RKkoVMHlkb2Yv3ECMMdvlSJIkSZIkSQdk8HcUpo3uw9rtjSzesCvbpUiSJEmSJEkHZPB3FKaPqQFwuK8kSZIkSZK6LIO/ozCgRxmj+1Yy66UN2S5FkiRJkiRJOiCDv6M0bXQNc5dtpa6pNdulSJIkSZIkSa9g8HeUpo/pQ3NbO48s2ZztUiRJkiRJkqRXMPg7SrVDe1JenHK4ryRJkiRJkrokg7+jVFKY4rwRvZm1cCMxxmyXI0mSJEmSJO3D4O8YTBvTh9VbG1i6qS7bpUiSJCnHtLa1s2Kz7UhJkpQ5Bn/HYProGgBmL9yY5UokSZKUaz75y2d583cecfSIJEnKGIO/YzC4VznDayqY9ZLBnyRJko7MxGE92bCziUUbdmW7FEmSlKcM/o7R9NF9eHTpZhqa27JdiiRJknLI5JHVAMxZtCnLlUiSpHxl8HeMpo2pobm1nUeXbc52KZIkScohg3qWM6y6gjmLDf4kSVJmGPwdo0nDelFaVOA8f5IkSTpik0f25tGlm2lpa892KZIkKQ8Z/B2j0qIU5w7vzayFG7JdiiRJknLMlJE11De38dTKbdkuRZIk5SGDv04wbXQNyzfXs3xTXbZLkSRJUg45d0RvCgIO95UkSRlh8NcJpo/pA8Bsn+4rSZKkI1BVVsS4QT2Ys8h2pCRJ6nwZDf5CCJeEEBaGEBaHED51gOPTQwjbQwjz08u/ZbKeTBlaXcHQ3uUO95UkSdIRmzKymqdXb2dHY0u2S5EkSXkmY8FfCCEF3A5cCowFrg0hjD3AqQ/GGCekl89nqp5Mmza6hkeWbqaxpS3bpUiSJCmHTBlVTVt75NElm7NdiiRJyjOZ7PE3EVgcY1waY2wG7gGuzOD7ZdX0MX1obGnn8WVbsl2KJEmScsgZQ3pQVpTiIef5kyRJnSyTwd9AYFWH16vT+/Z3bgjh6RDCH0MIp2awnow6Z3hvigsLnOdPkiRJR6SkMMXEYb18wIckSep0mQz+wgH2xf1ePwmcFGMcD3wLuO+AFwrhhhDCvBDCvI0bu2awVlacYtKwXs7zJ0mSlMOy1e48f1Q1SzbW8fL2huP2npIkKf9lMvhbDQzu8HoQsLbjCTHGHTHGXentPwBFIYTq/S8UY7wjxlgbY6ytqanJYMnHZvqYPizZWMeqLfXZLkWSJElHIVvtzskjkybwnEX2+pMkSZ0nk8HfXGBUCGFYCKEYuAb4TccTQgj9QgghvT0xXU/Ozmo8fUzSOHS4ryRJko7Eyf26UV1Z7HBfSZLUqTIW/MUYW4EPAn8GXgB+HmNcEEK4MYRwY/q0NwHPhRCeBm4Frokx7j8cOGcMr65gUM8yZi00+JMkSdLhCyEweWQ1Dy3eRA43hyVJUhdTmMmLp4fv/mG/fd/psH0bcFsmazgqKx+DgWdB6shuTwiB6WNq+NWTa2hqbaOkMJWhAiVJkpRvpoys5tfz1/Liup2c0r97tsuRJEl5IJNDfXPT8jlw52vhuV8c1Y9PH92H+uY2nli+tZMLkyRJUj6bMiqZ5+8hh/tKkqROYvC3v5MmQ9/T4YEvQ3vbEf/4uSN6U5wqYJbz/EmSJOkI9K8qY0RNBQ/6gA9JktRJDP72FwJM+zhsXgwL7j3iH68oKeTsYT2ZtXBDBoqTJElSPpsysprHl22hqfXIv4CWJEnan8HfgZx8BdScArNvgfb2I/7x6aP78NL6Xazd1pCB4iRJkpSvpoyqoaGljSdXbMt2KZIkKQ8Y/B1IQUHS62/TQnjh10f849PG1AAw2+G+kiRJOgKThvciVRCc50+SJHUKg7+DGXsVVI8+ql5/o/pUMqCqlD8vWEeMMUMFSpIkKd90Ly1i/KAq5hj8SZKkTmDwdzAFKZj6cdjwPLz4uyP60RACbz17CLMWbuTbs5ZkqEBJkiTloymjanhm9Ta217dkuxRJkpTjDP4O5dSrodeIpNffEfbc+6cLRnLVhAF8+c8LuefxlRkqUJIkSflmyshq2iM8snRztkuRJEk5zuDvUFKFMPVjsP5ZWPjHI/rRgoLALW8az7TRNXzm3mf503PrMlSkJEmS8skZQ3pQUZxizmLni5YkScfG4O/VnP5m6DkUZt98xL3+igsL+O//dybjBvXgQ/c8xaN+aytJkqRXUZQqYNLw3jy02LajJEk6NgZ/ryZVBOd/FF6eD4v+esQ/Xl5cyA/feTZDepXzvrvmsWDt9gwUKUmSpHwyZWQ1yzbVsXprfbZLkSRJOczg73CMuwaqhhxVrz+AnhXF3P3uiVSWFnL9nXNZsbkuA0VKkiQpX0wZVQ3AQz7dV5IkHQODv8NRWAzn/zOsmQdL7j+qSwzoUcaP3zOR1vZ2rvvB42zY2djJRUqSJClfjOpTSZ9uJTy4yOBPkiQdPYO/wzXh7dB94FH3+gMY2acbP3zn2Wzc2cQ775zLjsaWTi5SkiRJ+SCEwJSR1Ty8ZDPt7UfX9pQkSTqs4C+EUBFCKEhvjw4hvD6EUJTZ0rqYwhKY8s+w6jFY9sBRX+aMIT35znVn8dL6nbzvrnk0trR1YpGSJEk6mFxr004ZVc2Wumaef3lHtkuRJEk56nB7/D0AlIYQBgJ/B94F/ChTRXVZZ1wH3frD7FuO6TLTRtfw1beM57FlW/jQ/z5Fa1t7JxUoSZKkQ8ipNu3kkc7zJ0mSjs3hBn8hxlgPXA18K+jkaB4AACAASURBVMb4BmBs5srqoopKYfKHYcUcWD7nmC515YSB/PsVY/nL8+v57H3PEY9y+LAkSZIOW061aft2L2VUn0rmGPxJkqSjdNjBXwjhXODtwO/T+wozU1IXd9b1UNHnmHv9Abxr8jA+OGMk98xdxVf/8lInFCdJkqRDyLk27ZRR1Ty+bIvTw0iSpKNyuMHfh4FPA/fGGBeEEIYDMzNXVhdWVAaTb4Jls2Hlo8d8uY++djTXThzMbTMXc+ecZZ1QoCRJkg4i59q0U0ZW09TazpMrtma7FEmSlIMOK/iLMc6OMb4+xnhzekLkTTHGD2W4tq6r9l1QXt0pvf5CCHzhytO4+NS+fP53z/Pr+Ws6oUBJkiTtLxfbtJOG96awIPCgw30lSdJRONyn+v5PCKF7CKECeB5YGEL4eGZL68KKK+C8f4Ilf4fV8475coWpAr55zRlMGtaLj/78aWYt3NAJRUqSJKmjXGzTVpYUcsaQHj7gQ5IkHZXDHeo7Nsa4A7gK+AMwBLguY1XlgrPfC2W9YPbNnXK50qIU37u+llF9u/EPP3mSp1Y6nEOSJKmT5WSbdsrIGp5ds52tdc3ZLkW5LEZYOgvuvBTWP5/taiRJx8nhBn9FIYQikkbSr2OMLcCJ/Rjakko49wOw6C+w5slOuWT30iLuevfZ1HQr4V0/msviDTs75bqSJEkCcrRNO2VUb2KER5ZuznYpykUxwtLZ8MPL4O4rYety2Lk221VJko6Tww3+vgssByqAB0IIJwE7MlVUzph4A5RWwQNf7rRL9ulWyo/fM5HCggKu+8HjrN3W0GnXliRJOsHlZJt2/KAeVJYU8uAih/vqCC17EH70Orj79bB1GVz6ZfjQUzDywmxXJkk6Tg734R63xhgHxhgvi4kVwIwM19b1lXaHcz4AC/8ALz/daZc9qXcFd737bHY1tvKOOx9nxea6Tru2JEnSiSpX27SFqQLOGd7bef50+JbPgR9dDnddDpuXwKW3wIfmw6QboKg029VJko6jw324R1UI4WshhHnp5ask35Rq0vuhpHN7/QGcOqCK711fy8vbGrjwa7P5wu+eZ3t9S6e+hyRJ0okkl9u054+qZuWWelZurs92KerKVjycBH4/eh1segku+RLcND/5N4uBnySdkA53qO+dwE7gLellB/DDTBWVU8p6wDk3wgu/hfULOvXS5wzvzcyPTeeNZw7ihw8tY+qXZ/KDOctobm3v1PeRJEk6QeRsm3byyGoA5tjrTwey4hG46wr44aWwcSFc/EW46Wk45x+gqCzb1UmSsuhwg78RMcZ/jzEuTS+fA4ZnsrCcMulGKO7W6b3+APp0L+VLbxzH7z90PuMGVfGF3z3Pa78+mz89t44Yu/xc1JIkSV1JzrZpR9RU0K97KXMWb8x2KepKVj6aPLDjh5fAhhfh4v8vCfzO/UcDP0kScPjBX0MIYcruFyGEyYBPnditvFcyX8aC+5I/uBlwSv/u3P3uifzwXWdTlCrgxp88wVu/+yjPrN6WkfeTJEnKQznbpg0hMGVUNQ8v2Uxbu1/+nvBWPgZ3XwV3XpyMOnrtf6UDvw9AcXm2q5MkdSGHG/zdCNweQlgeQlgO3Aa8P2NV5aJzPgBF5fDgVzL2FiEEZozpwx9vOp//esNpLN20i9ff9hAfvucp1vj0X0mSpFeT023aKSOr2VbfwvNru/yDiJUpqx6HH78B7nwtrHsWLvpCEvid90EDP0nSAR3uU32fjjGOB8YB42KMZwAXvNrPhRAuCSEsDCEsDiF86hDnnR1CaAshvOmwK+9qKnrDxPfCc7+ETYsy+laFqQLePukkZn5sOh+YMYI/PreOC74yi1v+9CI7G30AiCRJ0oEcbZu2q9g9z9+DDvc98aydDz95E/zgInj5abjo8/DhZ2Dyh6A4J55PI0nKksPt8QdAjHFHjHH3V4wfOdS5IYQUcDtwKTAWuDaEMPYg590M/PlIaumSzv0nSJXAg189Lm/XrbSIj198Mvd/bDqXnd6fb89awoyvzOInj66gtc0HgEiSJB3IkbRpu5KabiWc3K8bD/mAjxPHxoXw83fAHdNgzTy48D/gpmdg8k0GfpKkw3JEwd9+wqscnwgsTk+c3AzcA1x5gPP+CfglsOEYaukaKmvg7PfAMz+HzUuO29sO7FHG1986gd98cDLDayr57H3Pcek3H2Tmixt8AIgkSdKhvVqbtkuZMrKaucu30tjSlu1SlElbl8O9/wDfPgcW/x2mfTIZ0jvln6GkMtvVSZJyyLEEf6+WKA0EVnV4vTq9b48QwkDgDcB3DnWhEMINIYR5IYR5Gzd28aEN5/0TpIpgzteO+1uPG9SDn91wDt+97ixa2tp514/mct0PHueFl50HRpIk6SD2adN29Xbn5FHVNLe2M3f5lmyXokzYuQ5+/1H4Vi0s+BWc849J4DfjM1Bale3qJEk5qPBQB0MIOzlwwBeAV3s+/IG+Pd3/Wt8APhljbAvh4F+2xhjvAO4AqK2t7dpd2Lr1g7PeCXO/D1M/Dj2HHte3DyFw8an9mDGmDz95dAW33r+Iy259kMvHDeDqMwdy/shqClPHkvdKkiTlliNp03b1duekYb0oSgXmLNrE+aNqsl2OOkv9FpjzdXj8e9DeAme+I/m3RPcB2a5MkpTjDhn8xRi7HcO1VwODO7weBKzd75xa4J506FcNXBZCaI0x3ncM75t9k2+CeXfCHz4Br/sK9Bhy3EsoLizg3VOG8cYzB3H7rMXc8/hKfvv0WnpXFHP5uP5cdcZAJgzuwaECV0mSpHxwjG3aLqW8uJAzh/RkjvP85YfGHfDot+Hh26B5F4x7K0z/FPQalu3KJEl54pDB3zGaC4wKIQwD1gDXAG/reEKMcc9ftBDCj4Df5XzoB8k3c9M/Bff/F3xzPIy5DCbdCEOnwHEO2qrKi/jMZafw0deOZtbCjfx6/hr+d+4q7npkBSf1LufKCQO5asIAhtc4V4gkSVIumDKymq/+9SU272qid2VJtsvR0WhpSHr3zfk6NGyBU66AGf8CfU7JdmWSpDyTseAvxtgaQvggydN6U8CdMcYFIYQb08cPOa9fzjv/o3D6W2DeD+CJH8GLv4M+p8Kk98O4t0DRq42U7lwlhSkuPrUfF5/ajx2NLfzp2XXcN38N37p/Ebf+fRHjB1Vx5YSBXD6+P326lR7X2iRJknT4poxKgr+Hl2zmivEOBc0prc3w1N3wwFdg58sw4gK44LMw8KxsVyZJylMh1576WltbG+fNm5ftMo5MSwM8+3/w2Hdh/XNQ1jOZB/Ds90LVoKyWtm57I799ei33zV/DgrU7KAgweWQ1V00YyMWn9aOyJJOdQiVJym8hhCdijLXZrkNHp6u2O1vb2jnjC3/lstP6c/ObxmW7HB2O9jZ45ucw64uwbQUMPgde86/JiCBJkjrBwdqdBn/HU4yw4iF47Dvw4u+BAKdcngwDHnLucR8GvL9F63dy3/w1/Hr+WlZvbaC0qICLxvbjqgkDmDq6hiIfCiJJ0hEx+MttXbnd+f4fz+O5NTuY88kZztnclbW3wYJ74YEvw8YXod84eM2/wcgLs972lyTll4O1O+3OdTyFkHyrN3QKbFuZPPn3ibvg+V9Dv9OTAPC0N0FRdobajurbjY9ffDIfe+0YnlixlXufWsPvn32Z3z69lp7lRbxuXH8uGtuPScN6UVqUykqNkjKsvQ2adqaXHcm6ccfe7X32pV8PPAvO/0i2K5ekE8qUkdX8ecF6VmyuZ2h1RbbL0f7aWpIefg9+FbYsgZqT4c13wSmvhwK/TJckHT8Gf9nSYwhc9HmY9il45mfJMOBffwD++m9w1rvg7PckDwnJghACtUN7UTu0F/9+xak88NJG7pu/hl88sZqfPLqSsqIUk0f2ZvqYPsw4uQ8Dexzf+QqlE1aM0NqYhG4tddDSCK0N6XV6aWnosG7a9/j++1rqXxnyNe969TpCAZR0g5LuydJ7ZOb/2yVJ+5gyqgaABxdvMvjrSlqbYP5Pk4d2bFuZfLn/lrvh5CsM/CRJWWHwl23F5VD7rmTOv2UPJAHgg1+Fh76RfCM48QYYPBEKstPDrriwgAvH9uXCsX1paG7j0aWbmblwA/e/uIG/vbABgDF9uzHj5D7MGFPDmSf1dEiw1FGM0N4Kbc3p0K1pb9DWuD293nGQ9QGOt7ccRREheaBQYekr1yXdoGpgOsirStal3TsEe92gNL1/977iCocnSVKWDe1dzsAeZTy0aBPXnXNStstRSwM8eTc89E3YsSbpDX/pl2H0xf7NlCRllcFfVxECDJ+WLFuWJcOAn/wxLPgVFJZB37HJN4b9Tod+45PXxcf3292y4lQS8J3ch8+9PrJk4y5mvriRmQs38P0Hl/Kd2UvoVlrI1FE1zDi5D9NG11DTreS41qgTUGtzEpA1bkvWDdvS2+nXjduToK29Lf0DMQnj9mxzkP37b+8O8FqS8K6tee/S2gxtTR22m/cGfW3NdHiTVxH2hmul6d50lX2h96i9r3eviyuTaQEKSw8Q6JUkvzeKSpN1qsh/dEhSngkhMGVkNX987mXa2iOpAn/PZ0XTLph3Jzz8LajbAEPOgytvg+Ez/NsrSeoSDP66ol7D4OL/gumfhoV/hJfnw7pnYMF98MSP0ieFZHhdv9Oh/7h0IDgOKvsclxJDCIzs042RfbrxvqnD2dnYwkOLN+0JAn//7MsAjB9UtWdI8LiBVRTYKD1xtLUmYVhrUxKWtTV1CMUOtN3UIVTrsN1ct1+ot33foK+l/tB1pEqSMK0gBaQ/fyEcxjav3F9QCKliKCxO1qniJIBPdXi951jJvtupoiSQSxXvG+B1XBd3cxiQJOmwTR5Vzc/mreLZNduZMLhHtss5sTRuh8e/B4/cDg1bYPh0mPpDn9IrSepyDP66spJKGPfmZIGk19H21bDu2fTyDKyZl/QK3K2y794QcPe61/CMhwndSou45LT+XHJaf2KMLFi7g1kLNzBz4Ua+df8ivvn3RfSuKGbamBqmjKxmwuAeDKuu8Cl0uaClARq2HsGyLVkfzlxxhyUkQ01Lq6CsR7KuHrXfvt1Lh3NKq5J9WXpYjiRJmTZ5RG8A5izaaPB3vNRvgce+kyyN22HUxTD1Y8nUPJIkdUEGf7kkBOgxOFlOvmzv/oatsO65DoHgs7D01mRYIkBRBfQekfQGrOiTrCv7JCFhRc3e7bKenTIkIYTAaQOrOG1gFR+8YBRb65p5YNFGZr64gZkvbuBXT64BoEd5EeMH9WDC4B5MGNKDCYN60LOi+JjfP6e0tSY91loakt5vsf3gS3tbh9cRYtsBzmnd23tu93xyrY17e9G17re/rXnv8Y77mnbuDfJaGw9ef0FR8rnZvXQfBH1PT7ZLq5LQbZ/ebvv1fEsVH2J7d6+5UnvBSZJ0AL0rSxjbvztzFm/igxeMynY5+W3XRnjktmQ6nuZdcPLlMPXjMGBCtiuTJOmQDP7yQVlPGHZ+suzW2gQbX0xCwJefga3LYdd62PAC7Npw4AcEFBSmg8GadCjYcbsmWVJFEFLJUz1DQRIUFnR8XdDheIBQQM9QwJXDUlw5vC9tl/Zj2ZYmnl67i/lr63hq9U6+tWgD7TEJHIf2LueMIT2TMHBwD07p353iwgyHPjF2mI+t5ZXDUw82b1vH1y0N6aUuva7fu6+5rsPx+g5LOuw73naHaYXF6XU6kCss2TtHXEXNvoHewRYf8iBJUlZNGVXNDx9aRn1zK+XFNu07VYyweTHM+2Eyj19rI5x2NZz/sWS+bUmScoCtg3xVWAL9xyfLGfsdizHpyVW3MQkDd23osL17vT7pRVi3YW/PwU6QAkamlzfu3lkC7aGQtpCitb6QxhdSND9fQAuFvEyKgsJiiopLKC0poay0jOKSYkJBYfppqW1JfTG9bm/vsL37WPt+56WX2JaEe0f1lNSD/QeWJMFZUXnyxOaO2xXVyfbufUVlSXBWVJYsqeL9QtWCpKfbAUPVQwSvuwO8jmHe7pAvVWxQJ0lSV7F9dfK3+RjmaJ4yspo7HljKr+ev5dqJQzqxuBPU9jWw7AFYNjtZ71iTtL/GvRXO/0gy3YgkSTnE4O9EFAKU90qWmjGHPre9PXmIwq71ULdpb5B20KGmbR2Otx/4nLbWJGzbHbq1tVLQ1kxBewtFba2UtrVQ39jA1p117NxZz866eurqGynY1UohTZSn6qkqCZQUF1NSXERZcRGlpZUUFxYlIVhBKmmgFaSSXox7tnfvL9wblqWKXn0oasdhp/s/2GH38NTdYV5B6vj8byhJknLfg19NepL1PR1GzICRr4HB5xzR/LQTh/Xi1AHd+fSvnuWxpZv5tytOpdeJNnXKsajfkg760mHf5sXJ/rJeMGwqDP8YjLwomWpHkqQcZPCnQyso2BsSHicBqEgvg9L7WtraWbhuJ/NXbWP+qm08s3obyzfV09zWvufnepYXMbymkuHVFYzok6yH11RyUu9yilLOESdJkrqYs98HVYNhyf3w6H/Dw7dCYRkMnQwjLkiWmpMP2Vu/tCjFvf84mdtnLubbsxbzwKJN/MfrT+WKcf19iNqBNO2ClY/A0llJ0LfuOSBCcSWcNBnOehcMnwZ9TnWOYUlSXggxxmzXcERqa2vjvHnzsl2GuoC29sjqrfUs3VjHko27WLKxjqUbd7F0Ux0bdzbtOS9VEDipVznDa5IgcER6Pby6gl4VxTaKJUkZE0J4IsZYm+06dHSOa7uzaReseCgJARf/HTYvSvZ3G5AOAWfA8BlQ0fugl3hx3Q4++YtneHr1di48pS//edVp9Ks6wZ9u39oEq+cmPfqWzoY185IRLKliGDwJhk1LevYNPDMZ9SFJUo46WLvT4E95aUdjC0t3B4HpYHDpxjqWba6juXVvL8FuJYUM7FnGoJ5lDOpZzsAeyfbAnmUM7FFmMChJOiYGf7ktq+3ObSthycwkCFw6K5l6hZDM3zzyNUkYOGhiMgVJB23tkTvnLOOrf11IUaqAf7nsFN569uATpz3TuCMJ91Y9DisfTZbWhmSKlwFnJCHfsGkw5JxkqhZJkvKEwZ9E0hheu62BxekgcNWWelZvrWf11gbWbG1gZ9O+DzIpK0rtCQaTULB8Tyg4uGcZ1ZUlFBScIA1pSdIRM/jLbV2m3dneBmuf2tsbcPXcZB7logoYdn7SE7DXsGReuvJeUNaT5XVFfOre53h06RbOG9GbL109jiG9y7P9X9K5YoSty5KQb9VjyXr9AiACAfqMTe7PsKnJMN6yHtmuWJKkjDH4kw7D9oYWVm+tZ83WhiQM3NaQvN6WBINb6/d9AnBxqoABPUqpriyhV0UxvSuL6V2xd7tXRfK6d2UxPcuLKS50rhhJOpEY/OW2LtvubNwOyx5MgsAlf4ety195TigglvZgZ0F3lu4qZiuVDBwwkJEnDaFg9/zNZfuve3btXnAtjfDy/L0h36rHoG5jcqykOwyqTYbvDp4IA2uhtHt265Uk6Tg6WLvTh3tIHVSVFVFVVsWpA6oOeLyuqXVvGNghHNy8q5kVm+t5cuU2ttQ10X6QPL1baeGekLBXRTHV6XCwV0UJfbuXMKBH0puwxp6EkiTpYEqr4JTLkwVg+2rYuS55Qm3Dlj3rUL+F7g1bOGXHJtatX0vh2hU0v/wXSmk6+LVTJcn1S6uSHnK7t0t7HHxfaVUSGpZ0h1Qn/vNi57p9Q76186E9/SVsr+Ew8sIk5Bs8KXkISkGq895bkqQ8YfAnHYGKkkJG9+3G6L7dDnpOe3tke0MLm+ua2VLXzOZdTXu2t9Q1s2lXE1vqmlm1pZ6nVm5ja30zbfslhUWpQL+qUgb2KNsTBg7YZ7uU8mL/7ytJkoCqQclyECXAkBj5zdNr+dxvn6e5sY4Pn1fD9RMqKWra1iEs3Jr0JtyzbIP6zbBlKTRsS/bFtkPXUlwJBYVJCBcKIKTXBank6cT7vO5wPIR99+1al8xzCEkYOfBMOPcfk5Bv0ESorOm8+ydJUh4zOZA6WUFBoGdFMT0ril/9ZJKgcEdjC+t3NLF2W9KDcM22Btaml8eWbmHdjsZXhIM9y4v2CQN3h4NDq8sZVl1hMChJkvYIIXDlhIFMGVnN5377PP/54Fp+saiNm984nvHDD3PuuxihuS4JBHeHgw3b9gsLtye98mJ7MjdhbE/Cwhj3e93e4Zy4d9/ucwacCZNuTIK+fuNe8RATSZJ0eEwGpCwrKAj0KC+mR3kxY/oduCdha1s763c27QkD9waDjazcXM8jSzaza78Hk/TrXsqw6gqG1VQwrHfFnu3BPcuda1CSpBNU78oSbr32DF4/fgD/ct+zvOHbD/G+84fz4QtHU1b8KkNlQ4CSymQ5RA9DSZLUdRj8STmgMFWwp1ffwexobGH1lgaWb65j2aY6lm6sY/nmOv703Dq21DXvOS9VEBjcsywJAqsrGVZdnqxrKujfvdS5BSVJOgFcOLYvE4f34ot/eIHvPrCUPy9Yx+evPI3zR1UTgm0BSZLyhcGflCe6lxYxdkARYwe88gl22+qbWbapbs+ydFMdyzfV8diyLdQ3752rp6SwgGHVFdR0K6G8OEVZUYqy4kLKi1OUF6coLUrtt50cK0ufu+92ISlDREmSuqzupUV88epxXDFuAJ/61bO8487HGdmnkrdNHMIbzxxEVXlRtkuUJEnHKMR4kMePdlG1tbVx3rx52S5DygsxRjbsbGLpxt2h4C6Wbapj065mGlvaqG9OlobmVupb2jjSXxclhQXpoHBveLhnu6SQ8qIkKKwo2fecsuJCKtIhYs/yYvpXlVJVVmQPBEk5J4TwRIyxNtt16OicSO3OxpY2fvv0Wn762Ermr9pGSWEBl48bwNsmDeHMIT38GyxJUhd3sHanPf6kE1gIgb7dS+nbvZRzR/Q+5LkxRppa22lobqOhZXcguHu79RX765vbqG9J9tc1tdHQ0pqsm9tYt6Mx2d/cuidc3P/hJfsrKSygX1Up/bqXvmLdt6qU/lWl1FSWUJhy/kJJko5UaVGKN9cO5s21g1mwdjv/89hK7ntqDb98cjUn9+vG2885iasmDKBbqb0AJUnKJfb4k5R1MUaa29rTYWDSw7CuKQkGt9a1sG5HI+u2N7BuRxPrtzfy8o4G1m9vormtfZ/rFASoriyhf1USZvarSpY+3UqpLNk7PLks3dOwrDi1p9dhSWGBvRkkdTp7/OW2E73duaupld/MX8tPH1vBgrU7KC9OceWEAbxt4kmcPqgq2+VJkqQO7PEnqcsKIVBSmKKkMEWP8sP7mRgjW+tbeHl7A+t3NLJue1M6HGxk3Y4mlm+u49Glm9nR2PrqFyN5UGFZUWpvKFi077yGyb7dw5RTlHfcTh+r2G+7bPfQ5qKUD02RJOWcypJC3jZpCNdOHMzTq7fzP4+t4N6n1vC/j69i3KAq3j5pCFeMH0B5sf+kkCSpq7LHn6S8Vt/cysadTXuGFO+eu7ChJelZ2NDcRn1LG43NHfd3GLbcsnvociuNLe17hic3t7a/+pt3UFpUsGcew26lRXQvLaR7WRHdS4votme7w7q0iO5l6WPpcxzGLOUee/zlNtudr7S9oYX7nlrDTx9bwUvrd9GtpJA3nDmQt00awsn9XvmAMUmSdHzY40/SCam8uJCTenf+r7rWtnbqWzrMZ9hhvsKG9HZdh+09cxo2tbGjsZUdjS2s3trAjoYd7GhsYVdT66s+PKVid2hYVrhnyHJpUQGl6Z6KJenXyf7UnuMle7ZT+/xMaVEBxakURYWB4lQBRYUFFKeSxR6KkqQDqSor4vrzhvKOc0/iiRVb+eljK7ln7irufmQFZ53Uk7dNHMLrxvWntCiV7VIlSRL2+JOkLqG9PbKruZUdDS3saGhlZ2NLEhA2tLCjsYWdHbZ3NLTu6aXY2JqEism6naaWZLul7dh+t6cK0mFgKlCcDgSLCgsoShV0CAmTY+cO780HLxjVSXdCyi/2+MtttjsPz9a6Zn755Gr+57GVLN1UR7fSQt5wxkDeevZgTh3gXICSJB0PWenxF0K4BPgmkAK+H2P80n7HrwS+ALQDrcCHY4xzMlmTJHVFBQUhGd5bWgQ9j/16rW3tNKafwtzYsntp3xsUtiTDmFvaIi1t7bS0tdPc2k5zWzstrZHmtuTY3n3pdVs7za1xz76mlnYaW45s2LMkKb/0rCjmvecP5z1ThvHI0s38fO6qPb0ATx9YxVvPHsyVPhFYkqSsyFiPvxBCCngJuAhYDcwFro0xPt/hnEqgLsYYQwjjgJ/HGE8+1HX95lWSJOUKe/zlNtudR29bfTP3PbWGe+au4sV1OykrSvG6cf255uzBnHVST0JwSglJkjpTNnr8TQQWxxiXpgu4B7gS2BP8xRh3dTi/AsitcceSJEmSXqFHeTHvnDyM688byjOrt3PP3FX8Zv4afvHEakbUVHDN2UO4+syB9K4syXapkiTltUwGfwOBVR1erwYm7X9SCOENwBeBPsDrDnShEMINwA0AQ4YM6fRCJUmSJLDd2dlCCIwf3IPxg3vw2dedwu+ffZmfzV3Ff/3hBW7584tcNLYv15w9hCkjq32wlCRJGZDJ4O9Af7lf0aMvxngvcG8IYSrJfH8XHuCcO4A7IBly0cl1SpIkSYDtzkyqKCnkLbWDeUvtYBat38nP5q7il0+u5g/PrmNgjzLeUjuYN9cOYkCPsmyXKklS3ijI4LVXA4M7vB4ErD3YyTHGB4ARIYTqDNYkSZIkKctG9e3GZy8fy6OfeQ23ve0MhtdU8PW/vcTkm+/nnT98nD89t47WNh8eJUnSscpkj7+5wKgQwjBgDXAN8LaOJ4QQRgJL0g/3OBMoBjZnsCZJkiRJXURJYYrLxw3g8nEDWLWlnv+bt4qfz1vNjT95goE9ynj7OUO45uwh9KooznapFDiRuAAAE9VJREFUkiTlpIwFfzHG1hDCB4E/AyngzhjjghDCjenj3wHeCLwjhNACNABvjZl6zLAkSZKkLmtwr3I+8toxfOg1o/j7ixu46+Hl3PKnhXzjb4t4/fgBvPO8oZw2sCrbZUqSlFNCruVstbW1cd68edkuQ5Ik6VWFEJ6IMdZmuw4dHdud2bdo/U7uemQ5v3pyDfXNbZx1Uk/ece5JXHpaf4oLMzlrkSRJueVg7U7/WkqSJEnqkkb17cZ/XnU6j3z6Nfzr5WPZvKuJm+6Zz+Sb7+cbf3uJDTsas12iJEldWibn+JMkSZKkY1ZVVsR7pgzjXecNZfaijdz18HK+8bdF3D5zMZee1p/rzzuJM4f0JISQ7VIlSepSDP4kSZIk5YSCgsCMMX2YMaYPyzbV8eNHVvB/81bxm6fXctrA7lx/7lCuGD+A0qJUtkuVJKlLcKivJEmSpJwzrLqCf7tiLI9+5jV84arTaGpp5+O/eIZzv/h3bv7Ti6zZ1pDtEiVJyjp7/EmSJEnKWRUlhVx3zkn8v0lDeGTJZn708HK+O3sJ3529hMtO78/7p47g9EE+DViSdGIy+JMkSZKU80IInDeymvNGVrNqSz0/fnQF//PYSn73zMtMHtmbG6aOYOqoaucBlCSdUBzqK0mSJCmvDO5VzmcuO4WHP30Bn770ZBat38X1dz7OZbfO4b6n1tDS1p7tEiVJOi4M/iRJkiTlpe6lRbx/2gge/OQMbnnTOFra2vnwz+Yz/cuzuHPOMuqaWrNdoiRJGWXwJ0mSJCmvlRSmeEvtYP7y4al8/x21DOhRyud/9zznfel+vvqXhWza1ZTtEiVJygjn+JMkSZJ0QigoCFw4ti8Xju3LEyu2cscDS7ht5mK++8BS3nTWIN53/nCGVVdku0xJkjqNwZ8kSZKkE85ZJ/Xku9fVsmTjLr7/4FJ+8cRq/vfxlVxyaj/eP20EEwb3yHaJkiQdM4M/SZIkSSesETWVfPHqcfzzRaO56+Hl/PiRFfzxuXVMGtaLG6eNYPqYGp8ELEnKWc7xJ0mSJOmE16dbKR+/+GQe/vRr+OzrTmHVlnre9aO5XPrNB/nb8+uJMWa7REmSjpjBnyRJkiSlVZYU8t7zhzP7EzP42lvG09jSxnvvnscb//thHlmyOdvlSZJ0RAz+JEmSJGk/RakCrj5zEH/9yDS+ePXprN3WyLXfe5TrfvAYz67enu3yJEk6LAZ/kiRJknQQRakCrp04hFkfn86/XHYKz63ZzhW3zeEff/oEizfsynZ5kiQdksGfJEmSJL2K0qIU75s6nAc+MYObXjOK2Qs38tqvz+YTv3iaNdsasl2eJEkHZPAnSZIkSYepW2kR/3zRaB74xAzeNXkY981fy4wvz+Jzv13Apl1N2S5PkqR9GPxJkiRJ0hHqXVnCv14+llkfm84bzhjIXQ8vZ9otM/naXxayo7El2+VJkgQY/EmSJEnSURvQo4yb3zSOv35kGtPH9OHW+xcz9ZaZfHf2Ehpb2rJdniTpBGfwJ0mSJEnHaERNJbe//Ux+909TGD+oB1/844tM+/JMfvrYClra2rNdniTpBGXwJ0mSJEmd5LSBVdz17on87IZzGNSznH+59zku+tpsfj1/De3tMdvlSZJOMAZ/kiRJktTJJg3vzS9uPJc731lLaVGKm+6Zz2W3Psjfnl9PjAaAkqTjw+BPkiRJkjIghMAFJ/flDx86n1uvPYPGljbee/c8rv7vh3l4yaZslydJOgEY/EmSJElSBhUUBF4/fgB//cg0vnT16azb3sjbvvcY1/3gMZ5etS3b5UmS8pjBnyRJkiQdB0WpAq6ZOISZH5vOZ193CgvW7uDK2x/i/T+ex0vrd2a7PElSHjL4kyRJkqTjqLQoxXvPH84Dn5jBRy4azcOLN3PxNx7gIz+bz8rN9dkuT5KURwz+JEmSJCkLKksK+dBrRvHAJ2Zww9Th/P7Zl7ngq7P47H3PsmFHY7bLkyTlAYM/SZIkScqinhXFfPrSU3jgEzO4ZuJg7nl8FVO/PJMv/vEFttY1Z7s8SVIOM/iTJEmSpC6gb/dS/vOq07n/o9O57LT+3PHAUqbeMpNb/76IXU2t2S5PkpSDMhr8hRAuCSEsDCEsDiF86gDH3x5CeCa9PBxCGJ/JeiRJkiSpqxvSu5yvvXUCf7ppKueN7M3X/voSU2+ZyfcfXEpDc1u2y5Mk5ZCMBX8hhBRwO3ApMBa4NoQwdr/TlgHTYozjgC8Ad2SqHkmSJEnKJWP6deO719Vy3wcmM7Z/d/7z9y8w5eb7+e9ZS+wBKEk6LJns8TcRWBxjXBpjbAbuAa7seEKM8eEY49b0y0eBQRmsR5IkSZJyzoTBPfjJeyfxixvP5bSBVdz8pxeZ/KX7+ebfFrG9oSXb5UmSurBMBn8DgVUdXq9O7zuY9wB/PNCBEMINIYR5IYR5Gzdu7MQSJUmSpL1sd6orqx3ai7vePZFff2AyZw/txdf/9hJTvnQ/X/nzQh8CIkk6oEwGf+EA++IBTwxhBknw98kDHY8x3hFjrI0x1tbU1HRiiZIkSdJetjuVC8YP7sH3r6/l9x+awvmjq7l91mIm33w/X/zDC2zc2ZTt8iRJXUhhBq+9Ghjc4fUgYO3+J4UQxgHfBy6NMW7OYD2SJEmSlDdOHVDFt99+FovW7+S2mYv53oNLueuR5Vw7cQjvnzqCflWl2S5RkpRlmezxNxcYFUIYFkIoBq4BftPxhBDCEOBXwHUxxpcyWIskSZIk5aVRfbvxzWvO4G8fmcbl4wZw9yMrmHrLTD5737Os3lqf7fIkSVmUsR5/McbWEMIHgT8DKeDOGOOCEMKN6ePfAf4N6A18O4QA0BpjrM1UTZIkSZKUr4bXVPKVN4/npteM4tuzlvCzuau45/FVvPHMQfzD9BEMra7IdomSpOMsxHjAafe6rNra2jhv3rxslyFJkvSqQghP+KVm7rLdqVy3dlsD3529hP+du4rWtnaunDCQD8wYycg+ldkuTZLUyQ7W7szkUF9JkiRJUpYM6FHG5648jTmfmMG7Jw/jT8+t46Kvz+ZXT67OdmmSpOMkkw/3kCRJkiRlWZ/upXz28rH8w/QR/GDOMqaMqs52SZKk48TgT5IkSZJOAL0rS/jEJSdnuwxJ0nHkUF9JkiRJkiQpDxn8SZIkSZIkSXnI4E+SJEmSJEnKQwZ/kiRJkiRJUh4y+JMkSZIkSZLykMGfJEmSJEmSlIcM/iRJkiRJkqQ8ZPAnSZIkSZIk5SGDP0mSJEmSJCkPGfxJkiRJkiRJecjgT5IkSZIkScpDBn+SJEmSJElSHjL4kyRJkiRJkvKQwZ8kSZIkSZKUhwz+JEmSJEmSpDxk8CdJkiRJkiTlIYM/SZIkSZIkKQ8Z/EmSJEmSJEl5yOBPkiRJkiRJykMGf5IkSZIkSVIeMviTJEmSJEmS8pDBnyRJkiRJkpSHDP4kSZIkSZKkPGTwJ0mSJEmSJOUhgz9JkiRJkiQpDxn8SZIkSZIkSXkoo8FfCOGSEMLCEMLiEMKnDnD85BDCIyGEphDCxzJZiyRJkiRJknQiKczUhUMIKeB24CJgNTA3hPCbGOPzHU7bAnwIuCpTdUiSJEmSJEknokz2+JsILI4xLo0xNgP3AFd2PCHGuCHGOBdoyWAdkiRJkiRJ0gknk8HfQGBVh9er0/uOWAjhhhDCvBDCvI0bN3ZKcZIkSdL+bHdKkqR8ksngLxxgXzyaC8UY74gx1sYYa2tqao6xLEmSJOnAbHdKkqR8ksngbzUwuMPrQcDaDL6fJEmSJEmSpLRMBn9zgVEhhGEhhGLgGuA3GXw/SZIkSZIkSWkZe6pvjLE1hPBB4M9ACrgzxrgghHBj+vh3Qgj9gHlAd6A9hPBhYGyMcUem6pIkSZIkSZJOBBkL/gBijH8A/rDfvu902F5HMgRYkiRJkiRJUifK5FBfSZIkSZIkSVli8CdJkiRJkiTlIYM/SZIkSZIkKQ8Z/EmSJEmSJEl5yOBPkiRJkiRJykMGf5IkSZIkSVIeMviTJEmSJEmS8pDBnyRJkiRJkpSHDP4kSZIkSZKkPGTwJ0mSJEmSJOUhgz9JkiRJkiQpDxn8SZIkSZIkSXnI4E+SJEmSJEnKQwZ/kiRJkiRJUh4y+JMkSZIkSZLykMGfJEmSJEmSlIcM/iRJkiRJkqQ8FGKM2a7hiIQQNgIrjsNbVQObjsP7nIi8t5njvc0s72/meG8zy/ubOa92b0+KMdYcr2LUuY5Tu9P/f2aW9zdzvLeZ5f3NHO9t5nhvM+uo2p05F/wdLyGEeTHG2mzXkY+8t5njvc0s72/meG8zy/ubOd5bHSs/Q5nl/c0c721meX8zx3ubOd7bzDra++tQX0mSJEmSJCkPGfxJkiRJkiRJecjg7+DuyHYBecx7mzne28zy/maO9zazvL+Z473VsfIzlFne38zx3maW9zdzvLeZ473NrKO6v87xJ0mSJEmSJOUhe/xJkiRJkiRJecjgT5IkSZIkScpDBn/7CSFcEkJYGEJYHEL4VLbryTchhOUhhGdDCPNDCPOyXU8uCyHcGULYEEJ4rsO+XiGEv4YQFqXXPbNZYy47yP39jxDCmvTnd34I4bJs1pirQgiDQwgzQwgvhBAWhBBuSu/383uMDnFv/ex2ghBCaQjh8RDC0+n7+7n0fj+7Oiq2OzPHNmfnst2ZObY5M8c2Z2bZ7syczm5zOsdfByGEFPAScBGwGpgLXBtjfD6rheWREMJyoDbGuCnbteS6EMJUYBdwd4zxtPS+W4AtMcYvpf8B0TPG+Mls1pmrDnJ//wPYFWP8SjZry3UhhP5A/xjjkyGEbsATwFXAO/Hze0wOcW/fgp/dYxZCCEBFjHFXCKEImAPcBFyNn10dIdudmWWbs3PZ7swc25yZY5szs2x3Zk5ntznt8bevicDiGOPSGGMzcA9wZZZrkg4oxvgAsGW/3VcCd6W37yL5xaujcJD7q04QY3w5xvhkensn8AIwED+/x+wQ91adICZ2pV8WpZeIn10dHdudyhm2OzPHNmfm2ObMLNudmdPZbU6Dv30NBFZ1eL0aP7idLQJ/CSE8EUK4IdvF5KG+McaXIflFDPTJcj356IMhhGfSwzIcFnCMQghDgTOAx/Dz26n2u7fgZ7dThBBSIYT5wAbgrzFGP7s6WrY7M8s2Z+b5uy+z/LvdiWxzZpbtzs7XmW1Og799hQPscyx055ocYzwTuBT4QLpru5Qr/hsYAUwAXga+mt1yclsIoRL4JfDhGOOObNeTTw5wb/3sdpIYY1uMcQIwCJgYQjgt2zUpZ9nuzCzbnMpl/t3uRLY5M8t2Z2Z0ZpvT4G9fq4HBHV4PAtZmqZa8FGNcm15vAO4lGeaizrM+PdfC7jkXNmS5nrwSY1yf/gXcDnwPP79HLT1XxS+Bn8YYf5Xe7ee3Exzo3vrZ7Xwxxm3ALOAS/Ozq6NjuzCDbnMeFv/syxL/bncc2Z2bZ7sy8zmhzGvztay4wKoQwLIRQDFwD/CbLNeWNEEJFetJPQggVwGuB5w79UzpCvwGuT29fD/w6i7Xknd2/ZNPegJ/fo5KerPYHwAsxxq91OOTn9xgd7N762e0cIYSaEEKP9HYZcCHwIn52dXRsd2aIbc7jxt99GeLf7c5hmzOzbHdmTme3OX2q737Sj5r+BpAC7owx/leWS8obIYThJN+4AhQC/+P9PXohhP8FpgPVwHrg34H7gJ8DQ4CVwJtjjE4WfBQOcn+nk3RZj8By4P2751jQ4QshTAEeBJ4F2tO7P0MyJ4if32NwiHt7LX52j1kIYRzJRMopki9Pfx5j/HwIoTd+dnUUbHdmhm3Ozme7M3Nsc2aObc7Mst2ZOZ3d5jT4kyRJkiRJkvKQQ30lSZIkSZKkPGTwJ0mSJEmSJOUhgz9JkiRJkiQpDxn8SZIkSZIkSXnI4E+SJEmSJEnKQwZ/knJeCKEthDC/w/KpTrz20BDCc511PUmSJOUu252Sck1htguQpE7QEGOckO0iJEmSlPdsd0rKKfb4k5S3QgjLQwg3hxAeTy8j0/tPCiH8PYTwTHo9JL2/bwjh3hDC0+nlvPSlUiGE74UQFoQQ/hJCKEuf/6EQwvPp69yTpf9MSZIkZZntTkldlcGfpHxQtt+Qi7d2OLYjxjgRuA34RnrfbcDdMcZxwE+BW9P7bwVmxxjHA2cCC9L7RwG3xxhPBbYBb0zv/xRwRvo6N2bqP06SJEldhu1OSTklxBizXYMkHZMQwq4YY+UB9i8HLogxLg0hFAHrYoy9QwibgP4xxpb0/pdjjNUhhI3AoBhjU4drDAX+GmMclX79SaAoxvifIYQ/AbuA+4D7Yoy7MvyfKkmSpCyy3Skp19jjT1K+iwfZPtg5B9LUYbuNvfOjvg74/9u5Q5wIgiAKoL9YQTDABTgF3AUIiqDWgIJwCxQGgeIQGLKGQBAk3AIBghs0YkdsQtaRMPS+Z6amxUyPq1T11HWS3SSvVWVuKgDA6pJ3AqOj8Af0bn/h+jzET0kOhvgoyeMQPySZJklVTapqc9lDq2otyU5rbZbkIsl2kh/dXwAAVoa8ExgdXQKgBxtV9bZwf99auxzi9ap6ybzRcTisnSa5rarzJB9Jjof1syQ3VXWSeYd1muR9yTsnSe6qaitJJblqrX392hcBADBG8k7gXzHjD+jWMGtlr7X2+dd7AQCgX/JOYKz86gsAAAAAHXLiDwAAAAA65MQfAAAAAHRI4Q8AAAAAOqTwBwAAAAAdUvgDAAAAgA4p/AEAAABAh74BviJ4lGRZLqAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1584x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 2, sharex=True, sharey=True,figsize=(22,12))\n",
    "ax1, ax2 = axes[0]\n",
    "ax3, ax4 = axes[1]\n",
    "# ax5 = axes[2]\n",
    "\n",
    "ax1.plot(lstm_history.history['loss'], label='Train loss')\n",
    "ax1.plot(lstm_history.history['val_loss'], label='Validation loss')\n",
    "ax1.legend(loc='best')\n",
    "ax1.set_title('lstm')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "ax2.plot(cnn_history.history['loss'], label='Train loss')\n",
    "ax2.plot(cnn_history.history['val_loss'], label='Validation loss')\n",
    "ax2.legend(loc='best')\n",
    "ax2.set_title('CNN')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Loss')\n",
    "\n",
    "ax3.plot(global_l_history.history['loss'], label='Train loss')\n",
    "ax3.plot(global_l_history.history['val_loss'], label='Validation loss')\n",
    "ax3.legend(loc='best')\n",
    "ax3.set_title('GlobalMaxPooling1D() 레이어 하나만')\n",
    "ax3.set_xlabel('Epochs')\n",
    "ax3.set_ylabel('Loss')\n",
    "\n",
    "ax4.plot(cnn_lstm_history.history['loss'], label='Train loss')\n",
    "ax4.plot(cnn_lstm_history.history['val_loss'], label='Validation loss')\n",
    "ax4.legend(loc='best')\n",
    "ax4.set_title('CNN-LSTM')\n",
    "ax4.set_xlabel('Epochs')\n",
    "ax4.set_ylabel('Loss')\n",
    "\n",
    "# ax5.plot(gru_history.history['loss'], label='Train loss')\n",
    "# ax5.plot(gru_history.history['val_loss'], label='Validation loss')\n",
    "# ax5.legend(loc='best')\n",
    "# ax5.set_title('GRU')\n",
    "# ax5.set_xlabel('Epochs')\n",
    "# ax5.set_ylabel('Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습된 Embedding 레이어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = global_l_model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/word2vec_kor.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = global_l_model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.26964158, -0.2027828 , -0.29704815, -0.24656129, -0.24768768,\n",
       "       -0.15116838, -0.29230902, -0.22323614, -0.14989823, -0.2137274 ,\n",
       "       -0.2640676 , -0.12096033, -0.27374282, -0.27285323, -0.27633062,\n",
       "       -0.23739438], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding parameter 읽어서 word vector로 활용\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['영화']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('대충', 0.9705683588981628),\n",
       " ('못생겼', 0.9604666233062744),\n",
       " ('한심', 0.9544970393180847),\n",
       " ('시시', 0.9498728513717651),\n",
       " ('제멋대로', 0.9467077851295471),\n",
       " ('과분', 0.9401426315307617),\n",
       " ('평이', 0.9374074935913086),\n",
       " ('아베', 0.9369668364524841),\n",
       " ('글쎄', 0.9358007907867432),\n",
       " ('짐작', 0.931463897228241)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"재미없\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('뻔해', 0.9801760911941528),\n",
       " ('엥', 0.9689817428588867),\n",
       " ('꺼지', 0.9654102325439453),\n",
       " ('버려라', 0.9574466943740845),\n",
       " ('과분', 0.9530490040779114),\n",
       " ('빨', 0.9520505666732788),\n",
       " ('구려', 0.9422466158866882),\n",
       " ('시시', 0.9420030117034912),\n",
       " ('꺼라', 0.9374504089355469),\n",
       " ('건조', 0.9374461770057678)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"지루\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('죠', 0.9465866088867188),\n",
       " ('의상', 0.9463531374931335),\n",
       " ('~!!!', 0.9414889812469482),\n",
       " ('쉬', 0.9413456320762634),\n",
       " ('그리고', 0.9400491714477539),\n",
       " ('된다면', 0.936847448348999),\n",
       " ('전성기', 0.9286718368530273),\n",
       " ('풀', 0.9283691644668579),\n",
       " ('추억', 0.9278419017791748),\n",
       " ('던데', 0.9247300028800964)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"감동\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한국어 Word2Vec 임베딩 활용하여 성능개선\n",
    "[파일 링크](https://github.com/Kyubyong/wordvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0036/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.7577837 , -1.0874279 ,  1.5300866 , -0.1115231 , -0.37980682,\n",
       "        1.4828517 ,  1.3180419 ,  0.11094163,  0.7430535 , -0.45461136,\n",
       "        0.58841336,  0.5763913 ,  1.210707  ,  1.3132795 , -0.86962503,\n",
       "       -0.18507595, -0.47440064,  1.5100725 ,  1.0965794 ,  1.0600823 ,\n",
       "       -0.27457932, -0.70003706,  2.3117511 ,  1.4944884 ,  0.25560892,\n",
       "       -2.866659  , -0.28312334,  0.34263936, -0.67723423,  0.71714777,\n",
       "        0.25549442,  0.71732044, -0.13262457,  0.01792452, -0.3184774 ,\n",
       "        0.5271619 ,  0.7561084 , -2.1247065 ,  1.061429  , -0.21065854,\n",
       "        0.6877343 , -1.4956383 ,  0.60346967, -2.6955893 ,  0.37694618,\n",
       "       -1.0164185 ,  0.5430663 ,  0.1200121 , -2.6315718 ,  0.6216742 ,\n",
       "        1.1583976 , -2.5385962 ,  1.326312  , -0.10284371, -0.0286147 ,\n",
       "       -0.9132947 ,  0.7647564 ,  0.79202783, -1.8625957 , -0.7418395 ,\n",
       "        0.5884277 , -0.9917992 , -0.62114453,  1.5367815 , -0.6628939 ,\n",
       "        0.6712103 ,  0.12914915,  0.21228492,  0.9017655 , -0.25083402,\n",
       "        0.71500814,  0.08644514,  0.59993285,  0.5766137 ,  0.64095974,\n",
       "        0.47888306, -2.8426213 , -2.8502681 , -0.140544  , -1.5917364 ,\n",
       "        0.26691505,  0.59476066,  0.85868204,  1.0322351 ,  0.25671318,\n",
       "       -0.34831643,  1.752927  , -0.21967097, -0.77352476,  1.6995213 ,\n",
       "        1.3996491 , -0.9419836 ,  0.85996443, -1.8812876 , -2.5428605 ,\n",
       "        0.39351937, -1.2882805 ,  0.56548136,  1.006273  ,  1.2217585 ,\n",
       "        3.5744793 ,  1.717737  ,  1.6917158 , -2.2176905 , -0.3167447 ,\n",
       "        1.2449    , -1.255284  , -2.1539652 , -1.096709  , -0.74976933,\n",
       "       -0.16744931, -1.8507233 ,  2.1861036 , -0.05389732,  1.038033  ,\n",
       "        0.33730686, -1.4647075 , -1.264041  ,  0.25509247,  0.0622906 ,\n",
       "        0.27852032, -0.52661455,  0.8529616 ,  0.58257025, -0.57665855,\n",
       "        1.3990631 ,  0.28237963,  1.6566037 ,  1.9912103 ,  0.63888913,\n",
       "        0.7732426 , -1.3757724 ,  0.17209321, -0.2433672 ,  0.6328291 ,\n",
       "        1.486971  ,  2.3435354 , -1.7037928 ,  3.1944559 , -1.9049606 ,\n",
       "       -0.51309574,  0.79082954, -1.4480313 , -0.68631476,  0.62008876,\n",
       "       -2.3400223 , -0.5785594 ,  0.5270694 ,  3.0061607 , -1.3661511 ,\n",
       "       -2.7953272 , -1.1794031 , -0.27734265,  0.71130925, -0.06620383,\n",
       "        0.33663416,  0.7204997 , -0.923218  , -2.1603265 , -0.8904896 ,\n",
       "       -1.4137112 , -0.4189144 ,  0.42834592,  1.8104875 , -1.8274456 ,\n",
       "       -0.26700613,  0.7743727 ,  0.80048114,  1.1333636 ,  3.2746978 ,\n",
       "       -0.0188297 ,  0.9245737 , -0.1246058 , -0.5802861 , -0.01926111,\n",
       "        1.05892   , -1.4247856 ,  1.0689156 ,  2.5728712 , -1.294882  ,\n",
       "        0.74771804,  1.3066916 , -1.3213431 ,  1.6501019 , -0.12401557,\n",
       "        0.96340084,  0.26050946,  1.3826336 , -0.02877662,  2.3431563 ,\n",
       "       -0.26337367,  1.9162012 , -0.77454543,  1.7392642 ,  0.08038983,\n",
       "       -0.60325927,  0.29508227,  0.4812675 ,  0.5271086 ,  0.94171894],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/ko.bin'\n",
    "word2vec = gensim.models.Word2Vec.load(word2vec_path)\n",
    "vector = word2vec['영화']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0036/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('감명', 0.7177015542984009),\n",
       " ('감격', 0.6908232569694519),\n",
       " ('실망', 0.6267645359039307),\n",
       " ('감화', 0.6191877126693726),\n",
       " ('감탄', 0.6140127778053284),\n",
       " ('칭찬', 0.6059398055076599),\n",
       " ('존경', 0.6032299995422363),\n",
       " ('자극', 0.594598650932312),\n",
       " ('감복', 0.5902734994888306),\n",
       " ('호응', 0.5850393772125244)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.similar_by_word(\"감동\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0036/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('답답', 0.7367105484008789),\n",
       " ('편안', 0.7046725749969482),\n",
       " ('솔직', 0.6893644332885742),\n",
       " ('쓸쓸', 0.6880697011947632),\n",
       " ('차분', 0.6868932843208313),\n",
       " ('조용', 0.6765609979629517),\n",
       " ('냉정', 0.6706622838973999),\n",
       " ('자유분방', 0.6680829524993896),\n",
       " ('피곤', 0.6597293019294739),\n",
       " ('느긋', 0.659047544002533)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.similar_by_word(\"지루\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0036/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \n",
      "/home/aiffel0036/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 41, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 35, 16)            22416     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 1, 16)             1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,024,369\n",
      "Trainable params: 2,024,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 0.6565 - accuracy: 0.6195 - val_loss: 0.5676 - val_accuracy: 0.7556\n",
      "Epoch 2/10\n",
      "266/266 [==============================] - 5s 17ms/step - loss: 0.5176 - accuracy: 0.7714 - val_loss: 0.4017 - val_accuracy: 0.8246\n",
      "Epoch 3/10\n",
      "266/266 [==============================] - 4s 17ms/step - loss: 0.4217 - accuracy: 0.8127 - val_loss: 0.3625 - val_accuracy: 0.8417\n",
      "Epoch 4/10\n",
      "266/266 [==============================] - 4s 17ms/step - loss: 0.3877 - accuracy: 0.8312 - val_loss: 0.3660 - val_accuracy: 0.8444\n",
      "Epoch 5/10\n",
      "266/266 [==============================] - 5s 17ms/step - loss: 0.3518 - accuracy: 0.8628 - val_loss: 0.3547 - val_accuracy: 0.8488\n",
      "Epoch 6/10\n",
      "266/266 [==============================] - 5s 17ms/step - loss: 0.3281 - accuracy: 0.8733 - val_loss: 0.3562 - val_accuracy: 0.8466\n",
      "Epoch 7/10\n",
      "266/266 [==============================] - 5s 17ms/step - loss: 0.3071 - accuracy: 0.8840 - val_loss: 0.3732 - val_accuracy: 0.8486\n",
      "Epoch 8/10\n",
      "266/266 [==============================] - 5s 17ms/step - loss: 0.2910 - accuracy: 0.8919 - val_loss: 0.3731 - val_accuracy: 0.8321\n",
      "Epoch 9/10\n",
      "266/266 [==============================] - 4s 17ms/step - loss: 0.2719 - accuracy: 0.9002 - val_loss: 0.3885 - val_accuracy: 0.8427\n",
      "Epoch 10/10\n",
      "266/266 [==============================] - 5s 17ms/step - loss: 0.2567 - accuracy: 0.9072 - val_loss: 0.4182 - val_accuracy: 0.8422\n",
      "1537/1537 - 3s - loss: 0.4325 - accuracy: 0.8399\n",
      "[0.43247750401496887, 0.8399007320404053]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "cnn_model2 = keras.Sequential()\n",
    "cnn_model2.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "cnn_model2.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "cnn_model2.add(keras.layers.MaxPooling1D(5))\n",
    "cnn_model2.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "cnn_model2.add(keras.layers.GlobalMaxPooling1D())\n",
    "cnn_model2.add(keras.layers.Dense(8, activation='relu'))\n",
    "cnn_model2.add(keras.layers.Dropout(0.3))\n",
    "cnn_model2.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "print(cnn_model2.summary())\n",
    "\n",
    "# 학습의 진행\n",
    "cnn_model2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "cnn_history2 = cnn_model2.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "# 테스트셋을 통한 모델 평가\n",
    "results = cnn_model2.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 50)                37800     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 8)                 408       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,038,217\n",
      "Trainable params: 2,038,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "266/266 [==============================] - 5s 19ms/step - loss: 0.5475 - accuracy: 0.6793 - val_loss: 0.3532 - val_accuracy: 0.8478\n",
      "Epoch 2/20\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.3503 - accuracy: 0.8562 - val_loss: 0.3285 - val_accuracy: 0.8533\n",
      "Epoch 3/20\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.3104 - accuracy: 0.8740 - val_loss: 0.3174 - val_accuracy: 0.8601\n",
      "Epoch 4/20\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.2814 - accuracy: 0.8865 - val_loss: 0.3293 - val_accuracy: 0.8634\n",
      "Epoch 5/20\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.2560 - accuracy: 0.8975 - val_loss: 0.3336 - val_accuracy: 0.8608\n",
      "Epoch 6/20\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.2353 - accuracy: 0.9055 - val_loss: 0.3600 - val_accuracy: 0.8617\n",
      "Epoch 7/20\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.2134 - accuracy: 0.9152 - val_loss: 0.3932 - val_accuracy: 0.8580\n",
      "Epoch 8/20\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.1963 - accuracy: 0.9221 - val_loss: 0.4277 - val_accuracy: 0.8586\n",
      "Epoch 9/20\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.1799 - accuracy: 0.9282 - val_loss: 0.4713 - val_accuracy: 0.8515\n",
      "Epoch 10/20\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.1660 - accuracy: 0.9335 - val_loss: 0.5336 - val_accuracy: 0.8514\n",
      "Epoch 11/20\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.1519 - accuracy: 0.9387 - val_loss: 0.6060 - val_accuracy: 0.8459\n",
      "Epoch 12/20\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.1427 - accuracy: 0.9423 - val_loss: 0.5899 - val_accuracy: 0.8454\n",
      "Epoch 13/20\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.1313 - accuracy: 0.9469 - val_loss: 0.6860 - val_accuracy: 0.8412\n",
      "Epoch 14/20\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.1206 - accuracy: 0.9512 - val_loss: 0.7130 - val_accuracy: 0.8434\n",
      "Epoch 15/20\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.1127 - accuracy: 0.9536 - val_loss: 0.7617 - val_accuracy: 0.8488\n",
      "Epoch 16/20\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.1044 - accuracy: 0.9563 - val_loss: 0.7935 - val_accuracy: 0.8415\n",
      "Epoch 17/20\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.0971 - accuracy: 0.9596 - val_loss: 0.8652 - val_accuracy: 0.8433\n",
      "Epoch 18/20\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.0919 - accuracy: 0.9617 - val_loss: 0.9667 - val_accuracy: 0.8446\n",
      "Epoch 19/20\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.0848 - accuracy: 0.9634 - val_loss: 1.0293 - val_accuracy: 0.8392\n",
      "Epoch 20/20\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.0840 - accuracy: 0.9643 - val_loss: 0.9646 - val_accuracy: 0.8412\n",
      "1537/1537 - 2s - loss: 0.9796 - accuracy: 0.8379\n",
      "[0.9795548915863037, 0.8379071354866028]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "gru_model2 = keras.Sequential()\n",
    "gru_model2.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "gru_model2.add(keras.layers.GRU(50))   # 가장 널리 쓰이는 RNN인 gru 레이어를 사용하였습니다. 이때 gru state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "gru_model2.add(keras.layers.Dropout(0.3))\n",
    "gru_model2.add(keras.layers.Dense(8, activation='relu'))\n",
    "gru_model2.add(keras.layers.Dropout(0.3))\n",
    "gru_model2.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "print(gru_model2.summary())\n",
    "\n",
    "# 학습의 진행\n",
    "gru_model2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "gru_history2 = gru_model2.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "# 테스트셋을 통한 모델 평가\n",
    "results = gru_model2.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_5 (Spatial (None, None, 200)         0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 50)                50200     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 8)                 408       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,050,617\n",
      "Trainable params: 2,050,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "266/266 [==============================] - 24s 88ms/step - loss: 0.4839 - accuracy: 0.7401 - val_loss: 0.3523 - val_accuracy: 0.8481\n",
      "Epoch 2/20\n",
      "266/266 [==============================] - 24s 89ms/step - loss: 0.3398 - accuracy: 0.8547 - val_loss: 0.3306 - val_accuracy: 0.8541\n",
      "Epoch 3/20\n",
      "266/266 [==============================] - 24s 90ms/step - loss: 0.3110 - accuracy: 0.8673 - val_loss: 0.3338 - val_accuracy: 0.8592\n",
      "Epoch 4/20\n",
      "266/266 [==============================] - 23s 87ms/step - loss: 0.2896 - accuracy: 0.8768 - val_loss: 0.3263 - val_accuracy: 0.8585\n",
      "Epoch 5/20\n",
      "266/266 [==============================] - 23s 87ms/step - loss: 0.2711 - accuracy: 0.8856 - val_loss: 0.3329 - val_accuracy: 0.8589\n",
      "Epoch 6/20\n",
      "266/266 [==============================] - 23s 87ms/step - loss: 0.2560 - accuracy: 0.8914 - val_loss: 0.3488 - val_accuracy: 0.8568\n",
      "Epoch 7/20\n",
      "266/266 [==============================] - 23s 87ms/step - loss: 0.2420 - accuracy: 0.8993 - val_loss: 0.3496 - val_accuracy: 0.8565\n",
      "Epoch 8/20\n",
      "266/266 [==============================] - 23s 88ms/step - loss: 0.2309 - accuracy: 0.9034 - val_loss: 0.3805 - val_accuracy: 0.8564\n",
      "Epoch 9/20\n",
      "266/266 [==============================] - 23s 87ms/step - loss: 0.2216 - accuracy: 0.9074 - val_loss: 0.3508 - val_accuracy: 0.8589\n",
      "Epoch 10/20\n",
      "266/266 [==============================] - 23s 87ms/step - loss: 0.2120 - accuracy: 0.9124 - val_loss: 0.3977 - val_accuracy: 0.8583\n",
      "Epoch 11/20\n",
      "266/266 [==============================] - 24s 89ms/step - loss: 0.2031 - accuracy: 0.9164 - val_loss: 0.3798 - val_accuracy: 0.8572\n",
      "Epoch 12/20\n",
      "266/266 [==============================] - 23s 88ms/step - loss: 0.1961 - accuracy: 0.9198 - val_loss: 0.3933 - val_accuracy: 0.8601\n",
      "Epoch 13/20\n",
      "266/266 [==============================] - 25s 92ms/step - loss: 0.1868 - accuracy: 0.9237 - val_loss: 0.4086 - val_accuracy: 0.8555\n",
      "Epoch 14/20\n",
      "266/266 [==============================] - 24s 90ms/step - loss: 0.1820 - accuracy: 0.9263 - val_loss: 0.4334 - val_accuracy: 0.8555\n",
      "Epoch 15/20\n",
      "266/266 [==============================] - 23s 86ms/step - loss: 0.1748 - accuracy: 0.9291 - val_loss: 0.4337 - val_accuracy: 0.8550\n",
      "Epoch 16/20\n",
      "266/266 [==============================] - 23s 87ms/step - loss: 0.1693 - accuracy: 0.9312 - val_loss: 0.4433 - val_accuracy: 0.8547\n",
      "Epoch 17/20\n",
      "266/266 [==============================] - 23s 86ms/step - loss: 0.1645 - accuracy: 0.9336 - val_loss: 0.4566 - val_accuracy: 0.8524\n",
      "Epoch 18/20\n",
      "266/266 [==============================] - 22s 84ms/step - loss: 0.1584 - accuracy: 0.9355 - val_loss: 0.4730 - val_accuracy: 0.8543\n",
      "Epoch 19/20\n",
      "266/266 [==============================] - 22s 84ms/step - loss: 0.1558 - accuracy: 0.9376 - val_loss: 0.4647 - val_accuracy: 0.8533\n",
      "Epoch 20/20\n",
      "266/266 [==============================] - 23s 87ms/step - loss: 0.1499 - accuracy: 0.9398 - val_loss: 0.4896 - val_accuracy: 0.8526\n",
      "1537/1537 - 13s - loss: 0.4927 - accuracy: 0.8509\n",
      "[0.49267858266830444, 0.8509469628334045]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "lstm_model2 = keras.Sequential()\n",
    "lstm_model2.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "lstm_model2.add(keras.layers.SpatialDropout1D(0.4))\n",
    "lstm_model2.add(keras.layers.LSTM(50, dropout=0.2, recurrent_dropout=0.2))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "lstm_model2.add(keras.layers.Dense(8, activation='relu'))\n",
    "lstm_model2.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "print(lstm_model2.summary())\n",
    "\n",
    "# 학습의 진행\n",
    "lstm_model2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "lstm_history2 = lstm_model2.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "# 테스트셋을 통한 모델 평가\n",
    "results = lstm_model2.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, None, 16)          22416     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_4 (Spatial (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 15)                1920      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 8)                 128       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,026,281\n",
      "Trainable params: 2,026,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.4989 - accuracy: 0.7501 - val_loss: 0.3484 - val_accuracy: 0.8477\n",
      "Epoch 2/20\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.3373 - accuracy: 0.8608 - val_loss: 0.3378 - val_accuracy: 0.8478\n",
      "Epoch 3/20\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.2931 - accuracy: 0.8825 - val_loss: 0.3337 - val_accuracy: 0.8580\n",
      "Epoch 4/20\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.2505 - accuracy: 0.9031 - val_loss: 0.3422 - val_accuracy: 0.8579\n",
      "Epoch 5/20\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.2018 - accuracy: 0.9260 - val_loss: 0.3826 - val_accuracy: 0.8524\n",
      "Epoch 6/20\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.1584 - accuracy: 0.9449 - val_loss: 0.4103 - val_accuracy: 0.8495\n",
      "Epoch 7/20\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.1260 - accuracy: 0.9575 - val_loss: 0.4855 - val_accuracy: 0.8426\n",
      "Epoch 8/20\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.1024 - accuracy: 0.9670 - val_loss: 0.5175 - val_accuracy: 0.8444\n",
      "Epoch 9/20\n",
      "266/266 [==============================] - 6s 24ms/step - loss: 0.0864 - accuracy: 0.9729 - val_loss: 0.5571 - val_accuracy: 0.8423\n",
      "Epoch 10/20\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.0748 - accuracy: 0.9771 - val_loss: 0.5776 - val_accuracy: 0.8449\n",
      "Epoch 11/20\n",
      "266/266 [==============================] - 6s 24ms/step - loss: 0.0662 - accuracy: 0.9799 - val_loss: 0.6346 - val_accuracy: 0.8428\n",
      "Epoch 12/20\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.0605 - accuracy: 0.9817 - val_loss: 0.6249 - val_accuracy: 0.8381\n",
      "Epoch 13/20\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.0542 - accuracy: 0.9836 - val_loss: 0.6476 - val_accuracy: 0.8369\n",
      "Epoch 14/20\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0509 - accuracy: 0.9847 - val_loss: 0.6883 - val_accuracy: 0.8361\n",
      "Epoch 15/20\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0463 - accuracy: 0.9860 - val_loss: 0.6898 - val_accuracy: 0.8427\n",
      "Epoch 16/20\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0449 - accuracy: 0.9863 - val_loss: 0.7141 - val_accuracy: 0.8423\n",
      "Epoch 17/20\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0414 - accuracy: 0.9876 - val_loss: 0.7408 - val_accuracy: 0.8385\n",
      "Epoch 18/20\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0394 - accuracy: 0.9882 - val_loss: 0.7183 - val_accuracy: 0.8413\n",
      "Epoch 19/20\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0364 - accuracy: 0.9892 - val_loss: 0.7680 - val_accuracy: 0.8348\n",
      "Epoch 20/20\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0347 - accuracy: 0.9897 - val_loss: 0.7646 - val_accuracy: 0.8372\n",
      "1537/1537 - 2s - loss: 0.8031 - accuracy: 0.8332\n",
      "[0.8030838370323181, 0.833207905292511]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "cnn_lstm_model2 = keras.Sequential()\n",
    "cnn_lstm_model2.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "cnn_lstm_model2.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "cnn_lstm_model2.add(keras.layers.MaxPooling1D(5))\n",
    "cnn_lstm_model2.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "cnn_lstm_model2.add(keras.layers.SpatialDropout1D(0.4))\n",
    "cnn_lstm_model2.add(keras.layers.LSTM(15, dropout=0.2, recurrent_dropout=0.2))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "cnn_lstm_model2.add(keras.layers.Dense(8, activation='relu'))\n",
    "cnn_lstm_model2.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "print(cnn_lstm_model2.summary())\n",
    "\n",
    "# 학습의 진행\n",
    "cnn_lstm_model2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "cnn_lstm_history2 = cnn_lstm_model2.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "# 테스트셋을 통한 모델 평가\n",
    "results = cnn_lstm_model2.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

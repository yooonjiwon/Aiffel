{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Classification of hand writings\n",
    "\n",
    "Here, I am going to classify hand writings into 0 to 9, 10 categories in total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits, load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "# check the components of digits\n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0., 10., 14.,  8.,  1.,  0.,  0.,  0.,  2., 16., 14.,  6.,\n",
       "        1.,  0.,  0.,  0.,  0., 15., 15.,  8., 15.,  0.,  0.,  0.,  0.,\n",
       "        5., 16., 16., 10.,  0.,  0.,  0.,  0., 12., 15., 15., 12.,  0.,\n",
       "        0.,  0.,  4., 16.,  6.,  4., 16.,  6.,  0.,  0.,  8., 16., 10.,\n",
       "        8., 16.,  8.,  0.,  0.,  1.,  8., 12., 14., 12.,  1.,  0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_data = digits.data\n",
    "\n",
    "# shape\n",
    "print(digits_data.shape)\n",
    "\n",
    "# first one (8 x 8 -> 1 x 64)\n",
    "digits_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the images of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAADx0lEQVR4nO3dQVFraRRG0Z+uZyBIQALBQiSAFSxEAxISK0RCQEIk5BmgYNJ12J1ea5g7+FIFu24VA87d9XpdQM8/v/0FgK+JE6LECVHihChxQtSfH57f5J9yj8fj6N7r6+vY1m63G9va7/djW5vNZmzrF9x99aE3J0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6J+OsdwkybPI6y11ufn59jW5XIZ27q/vx/bOhwOY1trrfX8/Dy69xVvTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0RlzjGcTqexrcnzCGutdT6fx7YeHh7Gtna73djW5O/HWs4xAN8QJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6Iyt1Iul8vY1uPj49jWWrP3SyZtt9vf/go3zZsTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUf/Lcwy73W5s65ZN/sw2m83YVoU3J0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6Iy5xgm/93+6XQa25o2eSLh/f19bOvl5WVsq8KbE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVF31+v1u+ffPvw3fXx8TE2t7XY7trXWWm9vb2Nbx+NxbOt8Po9t3fIJjbXW3VcfenNClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQlbmVMmnydslaa+33+7Gtp6ensa3D4TC2dePcSoH/EnFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFC1E/nGIBf4s0JUeKEKHFClDghSpwQJU6I+gs3YFLOQbhmtQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rehape 1x63 formation into 8x8 to see the picture of hand writing\n",
    "# plt.imshow(digits_data[0].reshape(8,8),cmap='binary')\n",
    "plt.imshow(digits.images[0],cmap='binary')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# first ten data\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1) # grid 2 x 5\n",
    "    plt.imshow(digits.images[i],cmap='binary')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_label = digits.target\n",
    "print(digits_label.shape)\n",
    "# unique value of the label\n",
    "np.unique(digits_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:(1437, 64)\n",
      "y_train:(1437,)\n",
      "x_test:(360, 64)\n",
      "y_test:(360,)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(digits_data,digits_label, \n",
    "                                                 test_size=0.2,\n",
    "                                                shuffle = True,\n",
    "                                                random_state=34)\n",
    "\n",
    "\n",
    "print(\"x_train:{}\".format(x_train.shape))\n",
    "print(\"y_train:{}\".format(y_train.shape))\n",
    "print(\"x_test:{}\".format(x_test.shape))\n",
    "print(\"y_test:{}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Optimum Models\n",
    "\n",
    "- Stochastic Gradient Descent Classifier (SGD)\n",
    "- Support Vector Machine (SVM)\n",
    "- Random Forest: Multiple Decision Tree -> Ensemble\n",
    "- Decision Tree\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_accuracy(x_train,y_train,x_test,y_test,m_name,model):\n",
    "    # train(fit) the model\n",
    "    model.fit(x_train,y_train)\n",
    "    # predict with test data\n",
    "    y_pred = model.predict(x_test)\n",
    "    # Accuracy of predicted value\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    \n",
    "    print(m_name)\n",
    "    print(accuracy)\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD\n",
      "0.9166666666666666\n",
      "[[37  0  0  0  0  0  0  0  1  0]\n",
      " [ 0 27  0  0  1  0  0  0  9  0]\n",
      " [ 0  0 32  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 44  0  0  0  0  2  1]\n",
      " [ 0  0  0  0 38  0  0  0  1  0]\n",
      " [ 0  0  0  0  0 34  0  0  2  2]\n",
      " [ 0  0  0  0  0  0 32  0  2  0]\n",
      " [ 0  0  0  0  0  0  0 24  1  0]\n",
      " [ 0  1  0  0  0  0  0  0 41  0]\n",
      " [ 0  0  0  0  0  0  0  1  6 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        38\n",
      "           1       0.96      0.73      0.83        37\n",
      "           2       1.00      1.00      1.00        32\n",
      "           3       1.00      0.94      0.97        47\n",
      "           4       0.97      0.97      0.97        39\n",
      "           5       1.00      0.89      0.94        38\n",
      "           6       1.00      0.94      0.97        34\n",
      "           7       0.96      0.96      0.96        25\n",
      "           8       0.63      0.98      0.77        42\n",
      "           9       0.88      0.75      0.81        28\n",
      "\n",
      "    accuracy                           0.92       360\n",
      "   macro avg       0.94      0.91      0.92       360\n",
      "weighted avg       0.94      0.92      0.92       360\n",
      "\n",
      "SVM\n",
      "0.9861111111111112\n",
      "[[38  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 37  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 32  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 47  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 38  0  0  0  0  1]\n",
      " [ 0  0  0  0  0 35  1  0  0  2]\n",
      " [ 0  0  0  0  0  0 34  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 25  0  0]\n",
      " [ 0  1  0  0  0  0  0  0 41  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       0.97      1.00      0.99        37\n",
      "           2       1.00      1.00      1.00        32\n",
      "           3       1.00      1.00      1.00        47\n",
      "           4       1.00      0.97      0.99        39\n",
      "           5       1.00      0.92      0.96        38\n",
      "           6       0.97      1.00      0.99        34\n",
      "           7       1.00      1.00      1.00        25\n",
      "           8       1.00      0.98      0.99        42\n",
      "           9       0.90      1.00      0.95        28\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.98      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "Random Forest\n",
      "0.9722222222222222\n",
      "[[37  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 37  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 32  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 45  0  0  0  0  1  1]\n",
      " [ 0  0  0  0 39  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 35  1  0  0  2]\n",
      " [ 0  0  0  0  0  0 33  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 25  0  0]\n",
      " [ 0  1  0  0  1  0  0  0 40  0]\n",
      " [ 0  0  0  1  0  0  0  0  0 27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        38\n",
      "           1       0.97      1.00      0.99        37\n",
      "           2       1.00      1.00      1.00        32\n",
      "           3       0.98      0.96      0.97        47\n",
      "           4       0.95      1.00      0.97        39\n",
      "           5       1.00      0.92      0.96        38\n",
      "           6       0.97      0.97      0.97        34\n",
      "           7       1.00      1.00      1.00        25\n",
      "           8       0.95      0.95      0.95        42\n",
      "           9       0.90      0.96      0.93        28\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "Decision Tree\n",
      "0.8416666666666667\n",
      "[[36  0  1  0  0  0  0  0  1  0]\n",
      " [ 0 31  1  1  0  0  1  2  1  0]\n",
      " [ 0  0 29  0  0  0  1  1  1  0]\n",
      " [ 0  0  1 39  0  0  0  2  1  4]\n",
      " [ 2  2  0  2 30  0  0  3  0  0]\n",
      " [ 0  0  0  1  2 31  2  0  1  1]\n",
      " [ 0  1  0  1  0  0 32  0  0  0]\n",
      " [ 0  1  0  0  1  0  0 22  1  0]\n",
      " [ 1  2  1  0  2  3  0  1 31  1]\n",
      " [ 1  0  0  1  1  1  0  0  2 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92        38\n",
      "           1       0.84      0.84      0.84        37\n",
      "           2       0.88      0.91      0.89        32\n",
      "           3       0.87      0.83      0.85        47\n",
      "           4       0.83      0.77      0.80        39\n",
      "           5       0.89      0.82      0.85        38\n",
      "           6       0.89      0.94      0.91        34\n",
      "           7       0.71      0.88      0.79        25\n",
      "           8       0.79      0.74      0.77        42\n",
      "           9       0.79      0.79      0.79        28\n",
      "\n",
      "    accuracy                           0.84       360\n",
      "   macro avg       0.84      0.85      0.84       360\n",
      "weighted avg       0.84      0.84      0.84       360\n",
      "\n",
      "Logistic\n",
      "0.9611111111111111\n",
      "[[38  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 37  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 32  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 44  0  0  0  0  2  1]\n",
      " [ 0  1  0  0 37  0  0  0  0  1]\n",
      " [ 0  0  0  0  0 34  1  0  0  3]\n",
      " [ 0  0  0  0  0  0 33  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 25  0  0]\n",
      " [ 0  2  0  0  0  0  0  0 40  0]\n",
      " [ 1  0  0  0  1  0  0  0  0 26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        38\n",
      "           1       0.93      1.00      0.96        37\n",
      "           2       1.00      1.00      1.00        32\n",
      "           3       1.00      0.94      0.97        47\n",
      "           4       0.97      0.95      0.96        39\n",
      "           5       1.00      0.89      0.94        38\n",
      "           6       0.97      0.97      0.97        34\n",
      "           7       1.00      1.00      1.00        25\n",
      "           8       0.93      0.95      0.94        42\n",
      "           9       0.84      0.93      0.88        28\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0036/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "sgd_model = SGDClassifier()\n",
    "svm_model = svm.SVC()\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "set_model = [sgd_model,svm_model,random_forest,decision_tree,logistic_model]\n",
    "set_model_n = ['SGD','SVM','Random Forest','Decision Tree','Logistic']\n",
    "\n",
    "for i in range(0,len(set_model)):\n",
    "    pt_accuracy(x_train,y_train,x_test,y_test,set_model_n[i],set_model[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Score\n",
    "- SGD: 91.7\n",
    "- SVM: 98.6\n",
    "- Random Forest: 97.2\n",
    "- Decision Tree: 84.2\n",
    "- Logistic Regression: 96.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "1. Accuracy 자체는 SVM에서 가장 높았음.   \n",
    "2. SGD는 1에 대한 recall이 낮은 편이었음. -> 1과 8 헷갈려함\n",
    "3. Decision Tree는 전반적으로 Accuracy, precision, recall 낮은 편이었으며, 특히 8을 어려워한 것으로 보임.\n",
    "- Logistic Regression에서는 5와 9를 헷갈려함   \n",
    "=> 모델은 SVM이나 random forest 사용하면 될 것 같음.   \n",
    "=> 다른 모델 성능을 높이고 싶다면, 1과 8을 헷갈려하는 이유를 찾아서 개선하면 될 듯."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  count\n",
       "row_0       \n",
       "0        140\n",
       "1        145\n",
       "2        145\n",
       "3        136\n",
       "4        142\n",
       "5        144\n",
       "6        147\n",
       "7        154\n",
       "8        132\n",
       "9        152"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1과 8에 대한 비율 확인\n",
    "prop = pd.crosstab(y_train,columns=\"count\")\n",
    "prop\n",
    "# 8 이 count가 가장 적긴 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Wine Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_description(data):\n",
    "    \n",
    "\n",
    "    print(\"check the components of loaded data:\")\n",
    "    print(data.keys())\n",
    "    \n",
    "    print('\\n')\n",
    "\n",
    "    loaded_data = data.data\n",
    "\n",
    "    print(\"shape:\")\n",
    "    print(loaded_data.shape)\n",
    "    print('\\n')\n",
    "\n",
    "    print(\"first one:\")\n",
    "    print(loaded_data[0])\n",
    "    print('\\n')\n",
    "    \n",
    "    for key in data.keys():\n",
    "        if key in \"image\": \n",
    "    \n",
    "            plt.imshow(data.images[0],cmap='binary')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "            print(\"first ten data\")\n",
    "            for i in range(10):\n",
    "                plt.subplot(2,5,i+1) # grid 2 x 5\n",
    "                plt.imshow(data.images[i],cmap='binary')\n",
    "                plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "    data_label = data.target\n",
    "    print(\"label shape:\")\n",
    "    print(data_label.shape)\n",
    "    print('\\n')\n",
    "    print(\"unique value of the label:\")\n",
    "    print(np.unique(data_label))\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "    print(\"Splitting data:\")\n",
    "    x_train,x_test,y_train,y_test = train_test_split(loaded_data,data_label, \n",
    "                                                     test_size=0.2,\n",
    "                                                    shuffle = True,\n",
    "                                                    random_state=34)\n",
    "\n",
    "    print(\"x_train:{}\".format(x_train.shape))\n",
    "    print(\"y_train:{}\".format(y_train.shape))\n",
    "    print(\"x_test:{}\".format(x_test.shape))\n",
    "    print(\"y_test:{}\".format(y_test.shape))\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"check the label proportion:\")\n",
    "    prop = pd.crosstab(y_train,columns=\"count\")\n",
    "    print(prop)\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"Model Selection\")\n",
    "    print('\\n')\n",
    "\n",
    "    sgd_model = SGDClassifier(warm_start=True)\n",
    "    svm_model = svm.SVC()\n",
    "    random_forest = RandomForestClassifier(random_state=32,warm_start=True)\n",
    "    decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "    logistic_model = LogisticRegression(warm_start=True)\n",
    "\n",
    "    s_model = [sgd_model,svm_model,random_forest,decision_tree,logistic_model]\n",
    "    s_model_n = ['SGD','SVM','Random Forest','Decision Tree','Logistic']\n",
    "\n",
    "    for i in range(0,len(s_model)):\n",
    "        pt_accuracy(x_train,y_train,x_test,y_test,s_model_n[i],s_model[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check the components of loaded data:\n",
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])\n",
      "\n",
      "\n",
      "shape:\n",
      "(178, 13)\n",
      "\n",
      "\n",
      "first one:\n",
      "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      "\n",
      "\n",
      "label shape:\n",
      "(178,)\n",
      "\n",
      "\n",
      "unique value of the label:\n",
      "[0 1 2]\n",
      "\n",
      "\n",
      "Splitting data:\n",
      "x_train:(142, 13)\n",
      "y_train:(142,)\n",
      "x_test:(36, 13)\n",
      "y_test:(36,)\n",
      "\n",
      "\n",
      "check the label proportion:\n",
      "col_0  count\n",
      "row_0       \n",
      "0         46\n",
      "1         57\n",
      "2         39\n",
      "\n",
      "\n",
      "Model Selection\n",
      "\n",
      "\n",
      "SGD\n",
      "0.6388888888888888\n",
      "[[13  0  0]\n",
      " [ 4 10  0]\n",
      " [ 4  5  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.76        13\n",
      "           1       0.67      0.71      0.69        14\n",
      "           2       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.64        36\n",
      "   macro avg       0.43      0.57      0.48        36\n",
      "weighted avg       0.48      0.64      0.54        36\n",
      "\n",
      "SVM\n",
      "0.6666666666666666\n",
      "[[12  0  1]\n",
      " [ 2  8  4]\n",
      " [ 1  4  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.86        13\n",
      "           1       0.67      0.57      0.62        14\n",
      "           2       0.44      0.44      0.44         9\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.64      0.65      0.64        36\n",
      "weighted avg       0.66      0.67      0.66        36\n",
      "\n",
      "Random Forest\n",
      "1.0\n",
      "[[13  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "Decision Tree\n",
      "0.9166666666666666\n",
      "[[12  1  0]\n",
      " [ 2 12  0]\n",
      " [ 0  0  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89        13\n",
      "           1       0.92      0.86      0.89        14\n",
      "           2       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.93      0.93      0.93        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n",
      "Logistic\n",
      "0.9166666666666666\n",
      "[[12  1  0]\n",
      " [ 2 12  0]\n",
      " [ 0  0  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89        13\n",
      "           1       0.92      0.86      0.89        14\n",
      "           2       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.93      0.93      0.93        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0036/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel0036/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "data_description(wines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "1. Accuracy만 비교했을 때, Random Forest가 100%로 가장 컸고, 그다음으로 91.7%로 Decision Tree, Logistic이 가장 큼.   \n",
    "2. Proportion을 봤을 때 라벨 2가 가장 적음.   \n",
    "3. SGD는 label 2를 전혀 잡아내지 못함.   \n",
    "4. SVM 또한 label 2를 어려워함.   \n",
    "5. 데이터셋이 적어서 뭐가 성능이 좋다고 하기 좀 그렇지만 Random Forest/Decision Tree/Logistic Regression중 하나를 사용하면 될 것 같고, 데이터셋이 더 추가된다면 테스트를 추가로 해보고 결정하면 될 것 같음. (Random Forest는 오버피팅일수도 있어 의심스러움 => hyperparameter 조정 또는 샘플 추가)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Breast Cancer Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check the components of loaded data:\n",
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
      "\n",
      "\n",
      "shape:\n",
      "(569, 30)\n",
      "\n",
      "\n",
      "first one:\n",
      "[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01 1.189e-01]\n",
      "\n",
      "\n",
      "label shape:\n",
      "(569,)\n",
      "\n",
      "\n",
      "unique value of the label:\n",
      "[0 1]\n",
      "\n",
      "\n",
      "Splitting data:\n",
      "x_train:(455, 30)\n",
      "y_train:(455,)\n",
      "x_test:(114, 30)\n",
      "y_test:(114,)\n",
      "\n",
      "\n",
      "check the label proportion:\n",
      "col_0  count\n",
      "row_0       \n",
      "0        174\n",
      "1        281\n",
      "\n",
      "\n",
      "Model Selection\n",
      "\n",
      "\n",
      "SGD\n",
      "0.9298245614035088\n",
      "[[34  4]\n",
      " [ 4 72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        38\n",
      "           1       0.95      0.95      0.95        76\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "SVM\n",
      "0.9385964912280702\n",
      "[[31  7]\n",
      " [ 0 76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        38\n",
      "           1       0.92      1.00      0.96        76\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.96      0.91      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "Random Forest\n",
      "0.956140350877193\n",
      "[[35  3]\n",
      " [ 2 74]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93        38\n",
      "           1       0.96      0.97      0.97        76\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.95      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Decision Tree\n",
      "0.9385964912280702\n",
      "[[34  4]\n",
      " [ 3 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91        38\n",
      "           1       0.95      0.96      0.95        76\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.93      0.93      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "Logistic\n",
      "0.9736842105263158\n",
      "[[36  2]\n",
      " [ 1 75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96        38\n",
      "           1       0.97      0.99      0.98        76\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0036/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "data_description(bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "1. Accuracy만 보면 Logistic Regression이 97.4%로 가장 높음.\n",
    "2. 의료데이터는 특히 False Negative가 치명적이기 때문에 False Negative가 제일 적은 것을 주시해야 함.   \n",
    "=> 로지스틱이 False Negative도 가장 적은 편이고, 정확도도 높으므로 로지스틱 모델 선정"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

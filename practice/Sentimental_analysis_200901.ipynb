{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimental Analysis\n",
    "[감성분석](https://dbr.donga.com/article/view/1202/article_no/8891/ac/magazine)\n",
    "\n",
    "## 텍스트 데이터 분석 - 숫자로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 문장 단어로 쪼개고 dict 형태로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: 'UNK', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n",
      "{'<PAD>': 0, '<BOS>': 1, 'UNK': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "word_to_index={}\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <PAD> '패딩용단어', <BOS> '문장의 시작지점', <UNK> '사전에 없는 단어'는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "word_l = ['<PAD>', '<BOS>', 'UNK', 'i', 'feel', 'hungry', 'eat', 'lunch', 'now', 'happy']\n",
    "\n",
    "for i,j in enumerate(word_l):\n",
    "    index_to_word[i] = j\n",
    "    word_to_index[j] = i\n",
    "\n",
    "print(index_to_word)\n",
    "print(word_to_index)\n",
    "\n",
    "# test\n",
    "print(word_to_index['feel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 데이터 분석 - Embedding\n",
    "- 위에서는 단어에 순서대로 인덱스를 부여함.\n",
    "- 이번에는 의미벡터 parameter를 구현한 Embedding layer를 이용해 단어의 의미를 나타내는 벡터를 짝지을 것임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([1, 3, 4, 5]) list([1, 3, 6, 7]) list([1, 8, 3, 4, 9])]\n",
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "print(raw_inputs)\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n",
      "tf.Tensor(\n",
      "[[[-0.02166836  0.04680797 -0.03849097 -0.03165741]\n",
      "  [-0.04958533  0.02253053 -0.04979849 -0.00547876]\n",
      "  [ 0.02022501  0.02456844 -0.02439902 -0.03892244]\n",
      "  [ 0.00313057 -0.04939313 -0.03008283 -0.01817377]\n",
      "  [ 0.03449502 -0.00936124  0.02946566  0.02308482]]\n",
      "\n",
      " [[-0.02166836  0.04680797 -0.03849097 -0.03165741]\n",
      "  [-0.04958533  0.02253053 -0.04979849 -0.00547876]\n",
      "  [-0.03125738 -0.01085917  0.01913143 -0.02035373]\n",
      "  [ 0.0043713  -0.0023184   0.00947372 -0.01489558]\n",
      "  [ 0.03449502 -0.00936124  0.02946566  0.02308482]]\n",
      "\n",
      " [[-0.02166836  0.04680797 -0.03849097 -0.03165741]\n",
      "  [-0.02221857  0.04392323  0.02802937  0.00459473]\n",
      "  [-0.04958533  0.02253053 -0.04979849 -0.00547876]\n",
      "  [ 0.02022501  0.02456844 -0.02439902 -0.03892244]\n",
      "  [ 0.03655553 -0.02576383  0.04404214 -0.01549941]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# embedding\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "print(vocab_size)\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드벡터를 가정합니다.\n",
    "\n",
    "# input 단어갯수, output 가정한 벡터 차원수\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "# Embedding layer input 문장벡터는 길이 일정해야함.\n",
    "# 윗 예시의 경우 길이 4, 4, 5\n",
    "# keras.preprocessing.sequence.pad_sequences 이용하여 <PAD> 길이 맞춰주기 => 5,5,5\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)\n",
    "# shape=(a,b,c)\n",
    "# a = 입력 문장 갯수\n",
    "# b = 입력 문장 최대 길이\n",
    "# c = 워드 벡터 차원수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence 데이터 분석 - RNN\n",
    "- squence data: 입력이 시간축을 따라 발생하는 데이터\n",
    "- RNN은 t=x 시점의 state는 t=x 시점의 input vx와 t=(x-1)시점의 state hx가 결정.\n",
    "- LSTM: 가장 흔히 쓰이는 RNN의 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-D Convolution Neural Network(1-D CNN)을 사용하면 문장 전체를 한꺼번에 한 방향으로 7길이의 필터로 스캔.   \n",
    "그 7단어 내에서 발견 되는 특징을 추출해 분류.   \n",
    "병렬처리가 RNN보다 효율적이라 더 빠름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GlobalMaxPooling1D() 레이어 하나만 사용.   \n",
    "전체 문장 중에서 중요한 단어 한개만 피처로 추출하여 긍정/부정 평가."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN-LSTM 또는 FeedForward Network layer만으로 구성, 또는 Transformer layer 사용 가능."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 - IMDB 영화 리뷰 Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDB 데이터셋 다운로드 \n",
    "# num_words 10000 갯수만큼 단어 갯수 생성\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 데이터가 아닌 encoding된 데이터임을 확인\n",
    "# dictionary까지 제공됨.\n",
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word[0] = \"<PAD>\"\n",
    "index_to_word[1] = \"<BOS>\"\n",
    "index_to_word[2] = \"<UNK>\"\n",
    "index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "# 문장 최대 길이 설정.\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "# padding을 문장 뒤,앞 중 어디로 하느냐에 따라 RNN 성능 차이남.\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 163,761\n",
      "Trainable params: 163,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6929 - val_accuracy: 0.4948\n",
      "Epoch 2/5\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.6895 - accuracy: 0.6140 - val_loss: 0.6896 - val_accuracy: 0.6313\n",
      "Epoch 3/5\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.6698 - accuracy: 0.7793 - val_loss: 0.6315 - val_accuracy: 0.7842\n",
      "Epoch 4/5\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.4839 - accuracy: 0.8398 - val_loss: 0.3591 - val_accuracy: 0.8500\n",
      "Epoch 5/5\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.2634 - accuracy: 0.8966 - val_loss: 0.3141 - val_accuracy: 0.8715\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=5  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 1s - loss: 0.3212 - accuracy: 0.8632\n",
      "[0.32120996713638306, 0.8632400035858154]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embedding: 단어의 특성을 저차원 벡터값으로 표현   \n",
    "[한국어 임베딩 읽을거리](https://ratsgo.github.io/natural%20language%20processing/2019/09/12/embedding/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05039101, -0.05123914,  0.04391335, -0.01988915, -0.01148819,\n",
       "       -0.03600633,  0.04791187, -0.00722545, -0.00669135, -0.02231818,\n",
       "        0.03059721,  0.01437167, -0.04642817,  0.03620751,  0.02116725,\n",
       "        0.00316889], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding parameter 읽어서 word vector로 활용\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('deeply', 0.8718148469924927),\n",
       " ('mary', 0.8691411018371582),\n",
       " ('lumet', 0.8624722361564636),\n",
       " ('aunts', 0.8620066046714783),\n",
       " ('gothic', 0.8575439453125),\n",
       " ('glow', 0.8498092889785767),\n",
       " ('sox', 0.843052864074707),\n",
       " ('sarandon', 0.8339055776596069),\n",
       " ('simplicity', 0.8327934145927429),\n",
       " ('pleasantly', 0.8322052955627441)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# love과 유사한 단어\n",
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word2vec은 1억개의 단어로 구성된 googel news dataset 바탕으로 학습됨.\n",
    "# 총 300만개의 단어로 300차원 벡터로 표현.\n",
    "# https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "#word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 15s 502ms/step - loss: 0.6965 - accuracy: 0.5155 - val_loss: 0.6893 - val_accuracy: 0.5458\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 6s 215ms/step - loss: 0.6843 - accuracy: 0.5675 - val_loss: 0.6809 - val_accuracy: 0.5776\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 7s 217ms/step - loss: 0.6608 - accuracy: 0.6292 - val_loss: 0.6501 - val_accuracy: 0.6253\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 6s 216ms/step - loss: 0.5741 - accuracy: 0.7279 - val_loss: 0.4977 - val_accuracy: 0.7894\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 0.3805 - accuracy: 0.8517 - val_loss: 0.3386 - val_accuracy: 0.8583\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 6s 213ms/step - loss: 0.2602 - accuracy: 0.8973 - val_loss: 0.3054 - val_accuracy: 0.8713\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 6s 213ms/step - loss: 0.1937 - accuracy: 0.9281 - val_loss: 0.3165 - val_accuracy: 0.8697\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 6s 213ms/step - loss: 0.1461 - accuracy: 0.9509 - val_loss: 0.3045 - val_accuracy: 0.8771\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 0.1144 - accuracy: 0.9647 - val_loss: 0.3133 - val_accuracy: 0.8759\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 0.0791 - accuracy: 0.9815 - val_loss: 0.3328 - val_accuracy: 0.8764\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 6s 213ms/step - loss: 0.0573 - accuracy: 0.9897 - val_loss: 0.3511 - val_accuracy: 0.8736\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 6s 215ms/step - loss: 0.0391 - accuracy: 0.9949 - val_loss: 0.3695 - val_accuracy: 0.8742\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 0.0269 - accuracy: 0.9975 - val_loss: 0.3907 - val_accuracy: 0.8716\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 7s 217ms/step - loss: 0.0195 - accuracy: 0.9987 - val_loss: 0.4134 - val_accuracy: 0.8713\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 6s 216ms/step - loss: 0.0139 - accuracy: 0.9994 - val_loss: 0.4334 - val_accuracy: 0.8710\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 6s 215ms/step - loss: 0.0103 - accuracy: 0.9995 - val_loss: 0.4512 - val_accuracy: 0.8702\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 0.0080 - accuracy: 0.9996 - val_loss: 0.4724 - val_accuracy: 0.8697\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 0.0063 - accuracy: 0.9997 - val_loss: 0.4899 - val_accuracy: 0.8682\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 0.0048 - accuracy: 0.9997 - val_loss: 0.5005 - val_accuracy: 0.8690\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 6s 216ms/step - loss: 0.0039 - accuracy: 0.9998 - val_loss: 0.5169 - val_accuracy: 0.8690\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 7s - loss: 0.5502 - accuracy: 0.8606\n",
      "[0.5502118468284607, 0.8605999946594238]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
